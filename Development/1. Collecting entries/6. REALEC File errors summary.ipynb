{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Bk6rfUCw-i_5"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N9lmNsVo-00w"
   },
   "source": [
    "Now we fetch our tokens data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28208,
     "status": "ok",
     "timestamp": 1556557533727,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "PnHN2cBq-kyf",
    "outputId": "32395ce8-39a2-4045-fecf-187c61c53d48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AkQn6bJK_CIB"
   },
   "outputs": [],
   "source": [
    "filename = \"All_Entries.json\"\n",
    "shutil.copy2('/content/gdrive/My Drive/'+filename,'.')\n",
    "\n",
    "All_Entries = pd.read_json(filename).reset_index(drop=True)\n",
    "All_Entries.begin = All_Entries.begin.astype(int)\n",
    "All_Entries.end = All_Entries.end.astype(int)\n",
    "All_Entries.delete = All_Entries.delete.astype(bool)\n",
    "All_Entries.substr_words = All_Entries.substr_words.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2291,
     "status": "ok",
     "timestamp": 1556557585885,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "KKKLIi3_ny6j",
    "outputId": "ffe0fc3f-f21b-40cd-ee13-1b532e33107b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
      "[nltk_data]   Unzipping misc/perluniprops.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"perluniprops\")\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "from nltk.tokenize.moses import MosesDetokenizer\n",
    "detokenizer = MosesDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2215,
     "status": "ok",
     "timestamp": 1556557687808,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "IShMFLB9lUz5",
    "outputId": "611e8450-4b7e-4055-df11-7f7f0924d678"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./realec_110319_2315.tar.gz'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "drive_path = \"Clean REALEC dumps/\" #@param {type:\"string\"}\n",
    "filename = \"realec_110319_2315.tar.gz\" #@param {type:\"string\"}\n",
    "\n",
    "\n",
    "shutil.copy2('/content/gdrive/My Drive/'+drive_path+filename,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Ut242uEbmBCJ"
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "tar = tarfile.open(filename)\n",
    "tar.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rq10LXKPqb6i"
   },
   "source": [
    "Once again we'll just load all the content into a huge `dict` for hell sake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 986,
     "status": "ok",
     "timestamp": 1556557726141,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "4uwyBq5tqxo4",
    "outputId": "f04add77-5216-40ee-dbb9-75f271dc1f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 191 ms, sys: 82.1 ms, total: 273 ms\n",
      "Wall time: 281 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Texts = list(set([x[:-4]+'.txt' for x in list(All_Entries[\"path\"])]))\n",
    "Text_Dict = {path: open(path, 'r', encoding='utf-8-sig').read() for path in Texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1556557727321,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "cnmOdGWOrOM6",
    "outputId": "d9727a51-77bc-401f-dd11-bcb5488ba3e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5554\n"
     ]
    }
   ],
   "source": [
    "print(len(Text_Dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kgTSF6e6EZmh"
   },
   "source": [
    "# Creating a file-wise factsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLlMHiSfD0Go"
   },
   "source": [
    "Now let's rearrange this data into a DataFrame with info on number of errors in different files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vPH423bnLQay"
   },
   "source": [
    "## Full version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8700697,
     "status": "ok",
     "timestamp": 1556571771076,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "5snjVliSEipx",
    "outputId": "bc6f5377-bc75-474c-c845-4241017abbbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 24min 37s, sys: 1.72 s, total: 2h 24min 39s\n",
      "Wall time: 2h 25min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Tags = [\"Correction\", \"Punctuation\", \"Spelling\", \"Capitalisation\", \"Grammar\", \"Determiners\", \"Articles\", \"Quantifiers\", \"Verbs\", \"Tense\", \"Tense_choice\", \"Tense_form\", \"Voice\", \"Modals\", \"Verb_pattern\", \"Intransitive\", \"Transitive\", \"Reflexive_verb\", \"Presentation\", \"Ambitransitive\", \"Two_in_a_row\", \"Verb_Inf\", \"Verb_Gerund\", \"Verb_Inf_Gerund\", \"Verb_Bare_Inf\", \"Verb_object_bare\", \"Restoration_alter\", \"Verb_part\", \"Get_part\", \"Complex_obj\", \"Verbal_idiom\", \"Prepositional_verb\", \"Dative\", \"Followed_by_a_clause\", \"that_clause\", \"if_whether_clause\", \"that_subj_clause\", \"it_conj_clause\", \"Participial_constr\", \"Infinitive_constr\", \"Gerund_phrase\", \"Nouns\", \"Countable_uncountable\", \"Prepositional_noun\", \"Possessive\", \"Noun_attribute\", \"Noun_inf\", \"Noun_number\", \"Prepositions\", \"Conjunctions\", \"Adjectives\", \"Comparative_adj\", \"Superlative_adj\", \"Prepositional_adjective\", \"Adj_as_collective\", \"Adverbs\", \"Comparative_adv\", \"Superlative_adv\", \"Prepositional_adv\", \"Numerals\", \"Pronouns\", \"Agreement_errors\", \"Word_order\", \"Standard\", \"Emphatic\", \"Cleft\", \"Interrogative\", \"Abs_comp_clause\", \"Exclamation\", \"Title_structure\", \"Note_structure\", \"Conditionals\", \"Attributes\", \"Relative_clause\", \"Defining\", \"Non_defining\", \"Coordinate\", \"Attr_participial\", \"Lack_par_constr\", \"Negation\", \"Comparative_constr\", \"Numerical\", \"Confusion_of_structures\", \"Vocabulary\", \"Word_choice\", \"lex_item_choice\", \"Often_confused\", \"lex_part_choice\", \"Absence_comp_colloc\", \"Redundant\", \"Derivation\", \"Formational_affixes\", \"Suffix\", \"Prefix\", \"Category_confusion\", \"Compound_word\", \"Discourse\", \"Ref_device\", \"Coherence\", \"Linking_device\", \"Inappropriate_register\", \"Absence_comp_sent\", \"Redundant_comp\", \"Absence_explanation\", \"delete\"]\n",
    "\n",
    "Files_Errors = {\n",
    "  'path': Texts\n",
    "}\n",
    "\n",
    "for error in Tags:\n",
    "  if error == 'delete':\n",
    "    Files_Errors[error] = [np.sum((All_Entries['path'] == path[:-4]+'.ann') & (All_Entries['delete'] == True)) for path in Texts]\n",
    "  else:\n",
    "    Files_Errors[error] = [np.sum((All_Entries['path'] == path[:-4]+'.ann') & (All_Entries['type'] == error)) for path in Texts]\n",
    "\n",
    "Files_Errors[\"Words\"] = [len(tknzr.tokenize(Text_Dict[path])) for path in Texts]\n",
    "\n",
    "Files_Errors = pd.DataFrame(Files_Errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 898,
     "status": "ok",
     "timestamp": 1556571997489,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "DpzqEoojVtFK",
    "outputId": "3a826972-1002-4ec8-c94f-125bde093732"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>Correction</th>\n",
       "      <th>Punctuation</th>\n",
       "      <th>Spelling</th>\n",
       "      <th>Capitalisation</th>\n",
       "      <th>Grammar</th>\n",
       "      <th>Determiners</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Quantifiers</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>...</th>\n",
       "      <th>Discourse</th>\n",
       "      <th>Ref_device</th>\n",
       "      <th>Coherence</th>\n",
       "      <th>Linking_device</th>\n",
       "      <th>Inappropriate_register</th>\n",
       "      <th>Absence_comp_sent</th>\n",
       "      <th>Redundant_comp</th>\n",
       "      <th>Absence_explanation</th>\n",
       "      <th>delete</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>./data/old IELTS/IELTS2016/TSha_7_1.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5220</th>\n",
       "      <td>./data/exam/exam2014/AMe_17_2.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>./data/exam/exam2017/ABl_42_1.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>./data/old IELTS/IELTS2015/VKo_15_1.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>./data/2012-2014/esl_00322.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>./data/2012-2014/esl_01166.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>./data/exam/exam2017_2/ABl_18_2.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         path  Correction  Punctuation  \\\n",
       "83    ./data/old IELTS/IELTS2016/TSha_7_1.txt           0            0   \n",
       "5220        ./data/exam/exam2014/AMe_17_2.txt           0            7   \n",
       "3786        ./data/exam/exam2017/ABl_42_1.txt           0            1   \n",
       "1625  ./data/old IELTS/IELTS2015/VKo_15_1.txt           0            0   \n",
       "4988           ./data/2012-2014/esl_00322.txt           0            0   \n",
       "4438           ./data/2012-2014/esl_01166.txt           0            0   \n",
       "2507      ./data/exam/exam2017_2/ABl_18_2.txt           0            4   \n",
       "\n",
       "      Spelling  Capitalisation  Grammar  Determiners  Articles  Quantifiers  \\\n",
       "83           6               3        0            0         1            0   \n",
       "5220         8               0        0            0         2            0   \n",
       "3786         1               1        0            0         4            0   \n",
       "1625         0               0        0            0         0            0   \n",
       "4988         0               0        0            0         1            0   \n",
       "4438         1               0        0            0        14            0   \n",
       "2507         1               0        0            0         7            0   \n",
       "\n",
       "      Verbs  ...  Discourse  Ref_device  Coherence  Linking_device  \\\n",
       "83        0  ...          0           0          1               0   \n",
       "5220      0  ...          0           1          1               0   \n",
       "3786      0  ...          0           0          0               0   \n",
       "1625      0  ...          0           0          0               0   \n",
       "4988      0  ...          2           0          0               0   \n",
       "4438      0  ...          0           0          0               0   \n",
       "2507      0  ...          0           0          0               0   \n",
       "\n",
       "      Inappropriate_register  Absence_comp_sent  Redundant_comp  \\\n",
       "83                         0                  2               0   \n",
       "5220                       0                  5               4   \n",
       "3786                       0                  0               0   \n",
       "1625                       0                  0               0   \n",
       "4988                       0                  0               0   \n",
       "4438                       0                  0               0   \n",
       "2507                       0                  0               3   \n",
       "\n",
       "      Absence_explanation  delete  Words  \n",
       "83                      0       0    187  \n",
       "5220                    1       0    246  \n",
       "3786                    1       0    186  \n",
       "1625                    0       0    182  \n",
       "4988                    0       1    214  \n",
       "4438                    0       1    827  \n",
       "2507                    1       3    302  \n",
       "\n",
       "[7 rows x 107 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Files_Errors.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "usKe7ub0LUgs"
   },
   "source": [
    "## Time estimate for code to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8050,
     "status": "ok",
     "timestamp": 1556559205570,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "kb5wzDn9Jsgb",
    "outputId": "895031f1-e0d3-47cc-a7eb-80884d2f14cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.34 s, sys: 4.98 ms, total: 7.34 s\n",
      "Wall time: 7.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test = [np.sum((All_Entries['path'] == Texts[i][:-4]+'.ann') & (All_Entries['type'] == \"Spelling\")) for i in range(len(Texts)) if i < 556]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 936,
     "status": "ok",
     "timestamp": 1556559477634,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "jpbepuwfKOAR",
    "outputId": "0a8d2005-bf3e-4b76-8faa-92b8e0fe7137"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We expect the full code to run for 2.15 hours. So we'll stick to selected types of errors for now and then figure out the full summary.\n"
     ]
    }
   ],
   "source": [
    "print(\"We expect the full code to run for\",str(round((7.35*len(Tags)*(len(Texts)/555))/3600, 2)),\"hours. So we'll stick to selected types of errors for now and then figure out the full summary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PoqOOg4YLZNC"
   },
   "source": [
    "## Short version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 676303,
     "status": "ok",
     "timestamp": 1556561941745,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "6r4DE55sLd2u",
    "outputId": "a47aa387-8bb6-4a6e-910e-1546de3e0edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 15s, sys: 99 ms, total: 11min 15s\n",
      "Wall time: 11min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Conventional = [\"Generic correction\", \"Punctuation\", \"Spelling\", \"Capitalisation\", \"Grammar\", \"Determiners\", \"Articles\", \"Quantifiers\", \"Verbs\", \"Tense\", \"Choice of tense\", \"Tense form\", \"Voice\", \"Modals\", \"Verb pattern\", \"Intransitive verb\", \"Transitive verb\", \"Reflexive verb\", \"Verb with as\", \"Ambitransitive verb\", \"Two verbal forms in the predicate\", \"Verb + Infinitive\", \"Verb + Gerund\", \"Verb + Infinitive OR Gerund\", \"Verb + Bare Infinitive\", \"Verb + Object/Addressee + Bare Infinitive\", \"Infinitive Restoration Alternation\", \"Verb + Participle\", \"Get + participle\", \"Complex-object verb\", \"Verbal idiom\", \"Prepositional or phrasal verb\", \"Dative verb with alternation\", \"Verb followed by a clause\", \"Verb + that/WH + Clause\", \"Verb + if/whether + clause\", \"Verb + that + Subjunctive clause\", \"Verb + it + Conj + Clause\", \"Participial construction\", \"Infinitive construction\", \"Gerund phrase\", \"Nouns\", \"Countable/uncountable\", \"Prepositional noun\", \"Possessive form of a noun\", \"Noun as an attribute\", \"Noun + Infinitive\", \"Noun number\", \"Prepositions\", \"Conjunctions\", \"Adjectives\", \"Comparative degree of adjectives\", \"Superlative degree of adjectives\", \"Prepositional adjective\", \"Adjective as a collective noun\", \"Adverbs\", \"Comparative degree of adverbs\", \"Superlative degree of adverbs\", \"Prepositional adverb\", \"Numerals\", \"Pronouns\", \"Agreement\", \"Word order\", \"Standard word order\", \"Emphatic shift\", \"Cleft sentence\", \"Interrogative word order\", \"Incomplete sentence\", \"Exclamation\", \"Title structure\", \"Note structure\", \"Conditionals\", \"Attributes\", \"Relative clause\", \"Defining relative clause\", \"Non-defining relative clause\", \"Coordinate relative clause\", \"Attributive participial construction\", \"Parallel constructions\", \"Negation\", \"Comparative construction\", \"Numerical comparison\", \"Confusion of structures\", \"Vocabulary\", \"Word choice\", \"Choice of lexical item\", \"Words often confused\", \"Choice of a part of lexical item\", \"Absence of certain components of a collocation\", \"Redundant word(s)\", \"Word formation\", \"Derivational affixes\", \"Formational suffix\", \"Formational prefix\", \"Confusion of categories\", \"Compound word\", \"Discourse\", \"Referential device\", \"Coherence\", \"Linking device\", \"Inappropriate register\", \"Absence of a component in clause or sentence\", \"Redundant component in clause or sentence\", \"Absence of necessary explanation or detail\", \"Deletion\"]\n",
    "Tags = [\"Correction\", \"Punctuation\", \"Spelling\", \"Capitalisation\", \"Grammar\", \"Determiners\", \"Articles\", \"Quantifiers\", \"Verbs\", \"Tense\", \"Tense_choice\", \"Tense_form\", \"Voice\", \"Modals\", \"Verb_pattern\", \"Intransitive\", \"Transitive\", \"Reflexive_verb\", \"Presentation\", \"Ambitransitive\", \"Two_in_a_row\", \"Verb_Inf\", \"Verb_Gerund\", \"Verb_Inf_Gerund\", \"Verb_Bare_Inf\", \"Verb_object_bare\", \"Restoration_alter\", \"Verb_part\", \"Get_part\", \"Complex_obj\", \"Verbal_idiom\", \"Prepositional_verb\", \"Dative\", \"Followed_by_a_clause\", \"that_clause\", \"if_whether_clause\", \"that_subj_clause\", \"it_conj_clause\", \"Participial_constr\", \"Infinitive_constr\", \"Gerund_phrase\", \"Nouns\", \"Countable_uncountable\", \"Prepositional_noun\", \"Possessive\", \"Noun_attribute\", \"Noun_inf\", \"Noun_number\", \"Prepositions\", \"Conjunctions\", \"Adjectives\", \"Comparative_adj\", \"Superlative_adj\", \"Prepositional_adjective\", \"Adj_as_collective\", \"Adverbs\", \"Comparative_adv\", \"Superlative_adv\", \"Prepositional_adv\", \"Numerals\", \"Pronouns\", \"Agreement_errors\", \"Word_order\", \"Standard\", \"Emphatic\", \"Cleft\", \"Interrogative\", \"Abs_comp_clause\", \"Exclamation\", \"Title_structure\", \"Note_structure\", \"Conditionals\", \"Attributes\", \"Relative_clause\", \"Defining\", \"Non_defining\", \"Coordinate\", \"Attr_participial\", \"Lack_par_constr\", \"Negation\", \"Comparative_constr\", \"Numerical\", \"Confusion_of_structures\", \"Vocabulary\", \"Word_choice\", \"lex_item_choice\", \"Often_confused\", \"lex_part_choice\", \"Absence_comp_colloc\", \"Redundant\", \"Derivation\", \"Formational_affixes\", \"Suffix\", \"Prefix\", \"Category_confusion\", \"Compound_word\", \"Discourse\", \"Ref_device\", \"Coherence\", \"Linking_device\", \"Inappropriate_register\", \"Absence_comp_sent\", \"Redundant_comp\", \"Absence_explanation\", \"delete\"]\n",
    "translate_dict = {e[0]: e[1] for e in zip(Conventional, Tags)}\n",
    "\n",
    "Selected_Tags = [\"Spelling\", \"Choice of lexical item\", \"Deletion\", \"Prepositions\", \"Agreement\", \"Noun number\", \"Confusion of categories\", \"Referential device\", \"Capitalisation\", \"Words often confused\"]\n",
    "Selected_Tags = [translate_dict[error] for error in Selected_Tags]\n",
    "\n",
    "Files_Selected_Errors = {\n",
    "  'path': Texts\n",
    "}\n",
    "\n",
    "for error in Selected_Tags:\n",
    "  if error == 'delete':\n",
    "    Files_Selected_Errors[error] = [np.sum((All_Entries['path'] == path[:-4]+'.ann') & (All_Entries['delete'] == True)) for path in Texts]\n",
    "  else:\n",
    "    Files_Selected_Errors[error] = [np.sum((All_Entries['path'] == path[:-4]+'.ann') & (All_Entries['type'] == error)) for path in Texts]\n",
    "\n",
    "Files_Selected_Errors[\"Words\"] = [len(tknzr.tokenize(Text_Dict[path])) for path in Texts]\n",
    "\n",
    "Files_Selected_Errors = pd.DataFrame(Files_Selected_Errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 705,
     "status": "ok",
     "timestamp": 1556563050573,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "K2dx4XwPYxiW",
    "outputId": "f8f63232-a7ae-4e71-f0cd-cf8046c0764c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>Spelling</th>\n",
       "      <th>lex_item_choice</th>\n",
       "      <th>delete</th>\n",
       "      <th>Prepositions</th>\n",
       "      <th>Agreement_errors</th>\n",
       "      <th>Noun_number</th>\n",
       "      <th>Category_confusion</th>\n",
       "      <th>Ref_device</th>\n",
       "      <th>Capitalisation</th>\n",
       "      <th>Often_confused</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>./data/exam/exam2016/NMa_22_1.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>./data/exam/exam2017/OBy_90_2.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5334</th>\n",
       "      <td>./data/Exam_practice/OV201617/151-152/st_35_3.txt</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>./data/Exam_practice/OV_2_year/essays_fr/st_42...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>./data/exam/exam2014/2012-2014_4/esl_00858.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>./data/exam/exam2014/EPa_35_1.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>./data/exam/exam2016/OR_53_1.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  Spelling  \\\n",
       "1352                  ./data/exam/exam2016/NMa_22_1.txt         0   \n",
       "3002                  ./data/exam/exam2017/OBy_90_2.txt         1   \n",
       "5334  ./data/Exam_practice/OV201617/151-152/st_35_3.txt         3   \n",
       "188   ./data/Exam_practice/OV_2_year/essays_fr/st_42...         1   \n",
       "2783     ./data/exam/exam2014/2012-2014_4/esl_00858.txt         1   \n",
       "4264                  ./data/exam/exam2014/EPa_35_1.txt         2   \n",
       "1399                   ./data/exam/exam2016/OR_53_1.txt         0   \n",
       "\n",
       "      lex_item_choice  delete  Prepositions  Agreement_errors  Noun_number  \\\n",
       "1352                0       0             1                 0            0   \n",
       "3002                4       3             0                 0            2   \n",
       "5334                2       0             5                 0            0   \n",
       "188                 2       1             2                 0            0   \n",
       "2783                4       2             1                 1            0   \n",
       "4264                1       1             2                 0            0   \n",
       "1399                2       1             0                 1            1   \n",
       "\n",
       "      Category_confusion  Ref_device  Capitalisation  Often_confused  Words  \n",
       "1352                   0           0               0               0    148  \n",
       "3002                   0           0               0               0    299  \n",
       "5334                   0           0               0               0    207  \n",
       "188                    0           2               0               0    178  \n",
       "2783                   0           0               0               0    449  \n",
       "4264                   0           0               0               0    211  \n",
       "1399                   0           0               0               0    191  "
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Files_Selected_Errors.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1556562025630,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "-rffpneVPDDr",
    "outputId": "cab36b9d-53e2-4c82-df5d-a94c076a145f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1513087"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = Files_Selected_Errors.sum(numeric_only=True)\n",
    "total[\"Words\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zhfAT2FXSDtK"
   },
   "source": [
    "Let's count the overall percentage of each error type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 653,
     "status": "ok",
     "timestamp": 1556562028648,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "ln-OVvEEQJST",
    "outputId": "773011be-1cc5-4e00-b0c0-3b1e79df8bf5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Agreement_errors': 0.0028464985820379133,\n",
       " 'Capitalisation': 0.0007679664156786754,\n",
       " 'Category_confusion': 0.0015855003710956476,\n",
       " 'Noun_number': 0.0020732449621204863,\n",
       " 'Often_confused': 0.000760696509850392,\n",
       " 'Prepositions': 0.003476997687509046,\n",
       " 'Ref_device': 0.000993994396885308,\n",
       " 'Spelling': 0.009436337765111985,\n",
       " 'Words': 1.0,\n",
       " 'delete': 0.004556909153274068,\n",
       " 'lex_item_choice': 0.007345248488685713}"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage = {el: total[el]/total['Words'] for el in total.keys()}\n",
    "\n",
    "percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p8kNUnqdSLyC"
   },
   "source": [
    "As our previous research has shown that datasets with 1:15 erroneous to non-erroneous ratio yield the best results, let's try to scale all our error types to this ratio. The ratio for *Choice of lexical item* should remaing unchanged (around `0.6666667`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 730,
     "status": "ok",
     "timestamp": 1556562033110,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "-JEmZBv8Q2ox",
    "outputId": "21bf82bc-9a39-47da-bd63-0d15c9015b72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Agreement_errors': 0.02583528282646512,\n",
       " 'Capitalisation': 0.006970187751184692,\n",
       " 'Category_confusion': 0.014390258532781476,\n",
       " 'Noun_number': 0.01881710755203647,\n",
       " 'Often_confused': 0.006904204906724252,\n",
       " 'Prepositions': 0.03155779497330694,\n",
       " 'Ref_device': 0.009021654369863836,\n",
       " 'Spelling': 0.08564573210965148,\n",
       " 'Words': 9.076162197828564,\n",
       " 'delete': 0.04135924659588507,\n",
       " 'lex_item_choice': 0.06666666666666667}"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_ratio = {el: percentage[el]*((1/15)/percentage['lex_item_choice']) for el in percentage.keys()}\n",
    "\n",
    "augmented_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1556562034974,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "0BwPzWUHUDWf",
    "outputId": "157c9296-dd84-4d41-8a6c-f6095d04c402"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percentage</th>\n",
       "      <th>Augmented ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Words</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.076162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spelling</th>\n",
       "      <td>0.009436</td>\n",
       "      <td>0.085646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lex_item_choice</th>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delete</th>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.041359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prepositions</th>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.031558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agreement_errors</th>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.025835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Noun_number</th>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.018817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category_confusion</th>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.014390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref_device</th>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.009022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Capitalisation</th>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.006970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Often_confused</th>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.006904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Percentage  Augmented ratio\n",
       "Words                 1.000000         9.076162\n",
       "Spelling              0.009436         0.085646\n",
       "lex_item_choice       0.007345         0.066667\n",
       "delete                0.004557         0.041359\n",
       "Prepositions          0.003477         0.031558\n",
       "Agreement_errors      0.002846         0.025835\n",
       "Noun_number           0.002073         0.018817\n",
       "Category_confusion    0.001586         0.014390\n",
       "Ref_device            0.000994         0.009022\n",
       "Capitalisation        0.000768         0.006970\n",
       "Often_confused        0.000761         0.006904"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Summary = {\n",
    "    \"Percentage\": percentage,\n",
    "    \"Augmented ratio\": augmented_ratio\n",
    "}\n",
    "\n",
    "Summary = pd.DataFrame(Summary)\n",
    "\n",
    "Summary = Summary.sort_values('Percentage', ascending=0)\n",
    "\n",
    "Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 977,
     "status": "ok",
     "timestamp": 1556562092777,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "wEw1_9EaVGwc",
    "outputId": "9aff1eb9-e21d-4fbc-c02d-931519f692a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>Spelling</th>\n",
       "      <th>lex_item_choice</th>\n",
       "      <th>delete</th>\n",
       "      <th>Prepositions</th>\n",
       "      <th>Agreement_errors</th>\n",
       "      <th>Noun_number</th>\n",
       "      <th>Category_confusion</th>\n",
       "      <th>Ref_device</th>\n",
       "      <th>Capitalisation</th>\n",
       "      <th>Often_confused</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>./data/Academic_Writing/2_exercise/student7.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3642</th>\n",
       "      <td>./data/exam/exam2016/JSl_122_2.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>./data/old IELTS/IELTS2016/EKu_12_1.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4911</th>\n",
       "      <td>./data/exam/exam2017/OBy_138_2.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>./data/exam/exam2017/VSa_9_1.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692</th>\n",
       "      <td>./data/exam/exam2014/2012-2014_4/esl_00904.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>./data/old IELTS/IELTS2016/DZu_75_2.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path  Spelling  \\\n",
       "833   ./data/Academic_Writing/2_exercise/student7.txt         0   \n",
       "3642               ./data/exam/exam2016/JSl_122_2.txt         0   \n",
       "2253          ./data/old IELTS/IELTS2016/EKu_12_1.txt         0   \n",
       "4911               ./data/exam/exam2017/OBy_138_2.txt         2   \n",
       "1426                 ./data/exam/exam2017/VSa_9_1.txt         1   \n",
       "4692   ./data/exam/exam2014/2012-2014_4/esl_00904.txt         4   \n",
       "2698          ./data/old IELTS/IELTS2016/DZu_75_2.txt         4   \n",
       "\n",
       "      lex_item_choice  delete  Prepositions  Agreement_errors  Noun_number  \\\n",
       "833                 0       0             0                 1            0   \n",
       "3642                0       2             0                 0            0   \n",
       "2253                2       0             0                 1            0   \n",
       "4911                0       0             0                 0            0   \n",
       "1426                2       3             1                 0            0   \n",
       "4692                2       1             1                 1            0   \n",
       "2698                5       0             0                 0            0   \n",
       "\n",
       "      Category_confusion  Ref_device  Capitalisation  Often_confused  Words  \n",
       "833                    0           0               0               0    364  \n",
       "3642                   0           0               0               0    280  \n",
       "2253                   2           0               0               0    218  \n",
       "4911                   0           0               0               0    297  \n",
       "1426                   1           0               0               0    132  \n",
       "4692                   0           4               0               0    375  \n",
       "2698                   0           0               0               0    319  "
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Files_Selected_Errors.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G5wVxxclrGPy"
   },
   "source": [
    "## Uploading the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sWvWoj8DCgt1"
   },
   "source": [
    "Wow. That was epic and took a looong time. We'd better save it into a json file to accelerate future load-ups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 683,
     "status": "ok",
     "timestamp": 1556572018595,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "XSarzvO5DhNV",
    "outputId": "4d9827ee-add7-4ddf-9027-89de3bf740c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 119 ms, sys: 23 ms, total: 142 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "jsonname = \"Files_Errors.json\" #@param {type:\"string\"}\n",
    "with open(jsonname, 'w', encoding=\"utf-8\") as outie:\n",
    "    exec(\"outie.write(\"+jsonname[:-5]+\".to_json())\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eryvINGWEFBY"
   },
   "source": [
    "Whew, great! Let's upload this to Google Drive right now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AJh_36xcDDB2"
   },
   "outputs": [],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once in a notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2043,
     "status": "ok",
     "timestamp": 1556572039462,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "57ajXFuqDgYO",
    "outputId": "e85e9a62-48f9-41e4-95bb-0a7e9f489651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1K630IK8-sZ4DfjAUPqCNbJ_PU7Qc9Qdz\n"
     ]
    }
   ],
   "source": [
    "# Create & upload a file.\n",
    "uploaded = drive.CreateFile({'title': jsonname})\n",
    "uploaded.SetContentFile(jsonname)\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "REALEC File errors summary",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
