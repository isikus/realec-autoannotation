{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ev68vvyqZ0Cs"
   },
   "source": [
    "# Initial import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxj8VDAmXM-i"
   },
   "source": [
    "Let's import what we need for this part and also load all necessary datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SYGvTIr2Wh_C"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import re\n",
    "import nltk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1557420177531,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "v9gOMiCwt1cR",
    "outputId": "cbd0a189-2fe5-45dc-c40c-eb916d0702a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"perluniprops\")\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "from nltk.tokenize.moses import MosesDetokenizer\n",
    "detokenizer = MosesDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22446,
     "status": "ok",
     "timestamp": 1557420202606,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "PnHN2cBq-kyf",
    "outputId": "f1dd2fc3-470b-463b-cdb4-7b79b6163418"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1557420206797,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "IShMFLB9lUz5",
    "outputId": "86332a83-18d6-42b3-8236-8dc9e81827b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./realec_110319_2315.tar.gz'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "drive_path = \"Clean REALEC dumps/\" #@param {type:\"string\"}\n",
    "filename = \"realec_110319_2315.tar.gz\" #@param {type:\"string\"}\n",
    "\n",
    "\n",
    "shutil.copy2('/content/gdrive/My Drive/'+drive_path+filename,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Ut242uEbmBCJ"
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "tar = tarfile.open(filename)\n",
    "tar.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AkQn6bJK_CIB"
   },
   "outputs": [],
   "source": [
    "filename = \"All_Entries.json\"\n",
    "shutil.copy2('/content/gdrive/My Drive/'+filename,'.')\n",
    "\n",
    "All_Entries = pd.read_json(filename).reset_index(drop=True)\n",
    "All_Entries.begin = All_Entries.begin.astype(int)\n",
    "All_Entries.end = All_Entries.end.astype(int)\n",
    "All_Entries.delete = All_Entries.delete.astype(bool)\n",
    "All_Entries.substr_words = All_Entries.substr_words.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16149,
     "status": "ok",
     "timestamp": 1557420229920,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "4uwyBq5tqxo4",
    "outputId": "3f37797a-a0c3-42bc-f772-cbe283bde34a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 197 ms, sys: 80.6 ms, total: 278 ms\n",
      "Wall time: 284 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Texts = list(set([x[:-4]+'.txt' for x in list(All_Entries[\"path\"])]))\n",
    "Text_Dict = {path: open(path, 'r', encoding='utf-8-sig').read() for path in Texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16788,
     "status": "ok",
     "timestamp": 1557420231905,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "cnmOdGWOrOM6",
    "outputId": "445006d6-04ae-4b9b-f0c9-c2cd43d2dc02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5554\n"
     ]
    }
   ],
   "source": [
    "print(len(Text_Dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "enMMadugYaPK"
   },
   "outputs": [],
   "source": [
    "filename = \"Summary.json\"\n",
    "shutil.copy2('/content/gdrive/My Drive/'+filename,'.')\n",
    "\n",
    "Summary = pd.read_json(filename)\n",
    "Summary['Percentage'] = Summary['Percentage'].astype(float)\n",
    "Summary['Augmented ratio'] = Summary['Augmented ratio'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cuCZzis5YYQ0"
   },
   "outputs": [],
   "source": [
    "Conventional = [\"Generic correction\", \"Punctuation\", \"Spelling\", \"Capitalisation\", \"Grammar\", \"Determiners\", \"Articles\", \"Quantifiers\", \"Verbs\", \"Tense\", \"Choice of tense\", \"Tense form\", \"Voice\", \"Modals\", \"Verb pattern\", \"Intransitive verb\", \"Transitive verb\", \"Reflexive verb\", \"Verb with as\", \"Ambitransitive verb\", \"Two verbal forms in the predicate\", \"Verb + Infinitive\", \"Verb + Gerund\", \"Verb + Infinitive OR Gerund\", \"Verb + Bare Infinitive\", \"Verb + Object/Addressee + Bare Infinitive\", \"Infinitive Restoration Alternation\", \"Verb + Participle\", \"Get + participle\", \"Complex-object verb\", \"Verbal idiom\", \"Prepositional or phrasal verb\", \"Dative verb with alternation\", \"Verb followed by a clause\", \"Verb + that/WH + Clause\", \"Verb + if/whether + clause\", \"Verb + that + Subjunctive clause\", \"Verb + it + Conj + Clause\", \"Participial construction\", \"Infinitive construction\", \"Gerund phrase\", \"Nouns\", \"Countable/uncountable\", \"Prepositional noun\", \"Possessive form of a noun\", \"Noun as an attribute\", \"Noun + Infinitive\", \"Noun number\", \"Prepositions\", \"Conjunctions\", \"Adjectives\", \"Comparative degree of adjectives\", \"Superlative degree of adjectives\", \"Prepositional adjective\", \"Adjective as a collective noun\", \"Adverbs\", \"Comparative degree of adverbs\", \"Superlative degree of adverbs\", \"Prepositional adverb\", \"Numerals\", \"Pronouns\", \"Agreement\", \"Word order\", \"Standard word order\", \"Emphatic shift\", \"Cleft sentence\", \"Interrogative word order\", \"Incomplete sentence\", \"Exclamation\", \"Title structure\", \"Note structure\", \"Conditionals\", \"Attributes\", \"Relative clause\", \"Defining relative clause\", \"Non-defining relative clause\", \"Coordinate relative clause\", \"Attributive participial construction\", \"Parallel constructions\", \"Negation\", \"Comparative construction\", \"Numerical comparison\", \"Confusion of structures\", \"Vocabulary\", \"Word choice\", \"Choice of lexical item\", \"Words often confused\", \"Choice of a part of lexical item\", \"Absence of certain components of a collocation\", \"Redundant word(s)\", \"Word formation\", \"Derivational affixes\", \"Formational suffix\", \"Formational prefix\", \"Confusion of categories\", \"Compound word\", \"Discourse\", \"Referential device\", \"Coherence\", \"Linking device\", \"Inappropriate register\", \"Absence of a component in clause or sentence\", \"Redundant component in clause or sentence\", \"Absence of necessary explanation or detail\", \"Deletion\"]\n",
    "Tags = [\"Correction\", \"Punctuation\", \"Spelling\", \"Capitalisation\", \"Grammar\", \"Determiners\", \"Articles\", \"Quantifiers\", \"Verbs\", \"Tense\", \"Tense_choice\", \"Tense_form\", \"Voice\", \"Modals\", \"Verb_pattern\", \"Intransitive\", \"Transitive\", \"Reflexive_verb\", \"Presentation\", \"Ambitransitive\", \"Two_in_a_row\", \"Verb_Inf\", \"Verb_Gerund\", \"Verb_Inf_Gerund\", \"Verb_Bare_Inf\", \"Verb_object_bare\", \"Restoration_alter\", \"Verb_part\", \"Get_part\", \"Complex_obj\", \"Verbal_idiom\", \"Prepositional_verb\", \"Dative\", \"Followed_by_a_clause\", \"that_clause\", \"if_whether_clause\", \"that_subj_clause\", \"it_conj_clause\", \"Participial_constr\", \"Infinitive_constr\", \"Gerund_phrase\", \"Nouns\", \"Countable_uncountable\", \"Prepositional_noun\", \"Possessive\", \"Noun_attribute\", \"Noun_inf\", \"Noun_number\", \"Prepositions\", \"Conjunctions\", \"Adjectives\", \"Comparative_adj\", \"Superlative_adj\", \"Prepositional_adjective\", \"Adj_as_collective\", \"Adverbs\", \"Comparative_adv\", \"Superlative_adv\", \"Prepositional_adv\", \"Numerals\", \"Pronouns\", \"Agreement_errors\", \"Word_order\", \"Standard\", \"Emphatic\", \"Cleft\", \"Interrogative\", \"Abs_comp_clause\", \"Exclamation\", \"Title_structure\", \"Note_structure\", \"Conditionals\", \"Attributes\", \"Relative_clause\", \"Defining\", \"Non_defining\", \"Coordinate\", \"Attr_participial\", \"Lack_par_constr\", \"Negation\", \"Comparative_constr\", \"Numerical\", \"Confusion_of_structures\", \"Vocabulary\", \"Word_choice\", \"lex_item_choice\", \"Often_confused\", \"lex_part_choice\", \"Absence_comp_colloc\", \"Redundant\", \"Derivation\", \"Formational_affixes\", \"Suffix\", \"Prefix\", \"Category_confusion\", \"Compound_word\", \"Discourse\", \"Ref_device\", \"Coherence\", \"Linking_device\", \"Inappropriate_register\", \"Absence_comp_sent\", \"Redundant_comp\", \"Absence_explanation\", \"delete\"]\n",
    "translate_dict = {e[0]: e[1] for e in zip(Conventional, Tags)}\n",
    "\n",
    "Selected_Tags = [\"Spelling\", \"Choice of lexical item\", \"Deletion\", \"Prepositions\", \"Agreement\", \"Noun number\", \"Confusion of categories\", \"Referential device\", \"Capitalisation\", \"Words often confused\"]\n",
    "Selected_Tags = [translate_dict[error] for error in Selected_Tags]\n",
    "\n",
    "filename = \"Files_Selected_Errors.json\"\n",
    "shutil.copy2('/content/gdrive/My Drive/'+filename,'.')\n",
    "\n",
    "Files_Errors = pd.read_json(filename).reset_index(drop=True)\n",
    "\n",
    "for error in Selected_Tags:\n",
    "  Files_Errors[error] = Files_Errors[error].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G9O0k2-DZ4e3"
   },
   "source": [
    "# Reserve for final validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4SUIVSw5Wial"
   },
   "source": [
    "For each of selected types of errors we will reserve some 15 randomly selected texts which contain this specific error. These files are to be used in final validation and thus excerpts of them will not appear in training nor in validation entry subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "K4IYLervXF0a"
   },
   "outputs": [],
   "source": [
    "RESERVE = {Tag: list(Files_Errors['path'].loc[Files_Errors[Tag] > 0].sample(15)) for Tag in Selected_Tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 717,
     "status": "ok",
     "timestamp": 1556575730919,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "_zVpoh_0I_gt",
    "outputId": "edcb213e-5fea-4213-cb0f-58d2be9fc734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spelling: ['./data/exam/exam2014/EPa_38_1.txt', './data/exam/exam2017_4/DPe_83_1.txt', './data/Exam_practice/OV_2_year/essays_it/st_100_7.txt', './data/exam/exam2014/2012-2014_3/esl_00700.txt', './data/exam/exam2017/EGe_177_2.txt', './data/exam/undefined/EEm_151_1.txt', './data/exam/exam2017/DOv_32_1.txt', './data/2012-2014/esl_00016.txt', './data/old IELTS/IELTS2016/MTsy_40_2.txt', './data/exam/exam2017_2/ABl_18_2.txt', './data/old IELTS/IELTS2016/EEm_200_1.txt', './data/exam/exam2017_6/OBy_5_2.txt', './data/old IELTS/IELTS2015/ESha_49_2.txt', './data/2012-2014/esl_00749.txt', './data/exam/exam2016/JSl_87_1.txt']\n",
      "lex_item_choice: ['./data/2012-2014/esl_00382.txt', './data/exam/best_works/2_2.txt', './data/2012-2014/esl_01177.txt', './data/exam/exam2016/EKu_12_2.txt', './data/exam/exam2017/VSa_35_1.txt', './data/exam/exam2017_6/OBy_69_2.txt', './data/exam/exam2014/AAl_9_2.txt', './data/exam/exam2014/EEm_36_1.txt', './data/Exam_practice/OV_2_year/essays_fr/st_45_7.txt', './data/old IELTS/IELTS2016/OR_127_1.txt', './data/exam/exam2017_6/NMya_14_1.txt', './data/2012-2014/esl_00437.txt', './data/old IELTS/IELTS2016/JSl_124_1.txt', './data/old IELTS/IELTS2015/AKhr_31_2.txt', './data/exam/exam2014/2012-2014_3/esl_00583.txt']\n",
      "delete: ['./data/exam/exam2017/VSa_75_1.txt', './data/2012-2014/esl_00637.txt', './data/exam/exam2016/OR_108_2.txt', './data/exam/exam2014/2012-2014_2/esl_00445.txt', './data/exam/undefined/AKhr_16_2.txt', './data/exam/exam2017/OBy_101_2.txt', './data/exam/exam2017/OBy_74_2.txt', './data/exam/exam2017/EGe_111_1.txt', './data/2012-2014/esl_00950.txt', './data/exam/best_works/30_1.txt', './data/exam/exam2017_6/NMya_25_2.txt', './data/old IELTS/IELTS2015/MTsy_28_2.txt', './data/old IELTS/IELTS2016/JSl_67_2.txt', './data/old IELTS/IELTS2016/EKu_72_2.txt', './data/2012-2014/esl_00837.txt']\n",
      "Prepositions: ['./data/exam/exam2014/AMe_8_1.txt', './data/exam/exam2014/2012-2014_4/esl_00945.txt', './data/exam/exam2014/EPa_5_1.txt', './data/exam/exam2014/TSha_2_1.txt', './data/exam/exam2014/2012-2014_2/esl_00380.txt', './data/2012-2014/esl_00330.txt', './data/old IELTS/IELTS2016/JSl_95_1.txt', './data/old IELTS/IELTS2015/ADe_18_1.txt', './data/2012-2014/esl_00107.txt', './data/exam/exam2017/EGe_220_1.txt', './data/exam/exam2016/JSl_140_2.txt', './data/exam/exam2014/MTsy_34_2.txt', './data/old IELTS/IELTS2015/EEm_24_2.txt', './data/exam/exam2014/EPa_6_1.txt', './data/exam/exam2017_6/OBy_103_2.txt']\n",
      "Agreement_errors: ['./data/old IELTS/IELTS2016/OR_129_2.txt', './data/exam/exam2017_4/DPe_38_2.txt', './data/2012-2014/esl_00225.txt', './data/old IELTS/IELTS2016/EKu_6_1.txt', './data/exam/exam2017/EGe_190_2.txt', './data/old IELTS/IELTS2016/JSl_41_2.txt', './data/exam/exam2014/MGr_13_2.txt', './data/old IELTS/IELTS2015/EPa_31_1.txt', './data/exam/exam2017_6/OBy_112_1.txt', './data/exam/exam2014/ZEv_35_2.txt', './data/2012-2014/esl_00437.txt', './data/exam/exam2016/OR_48_2.txt', './data/exam/exam2014/EPa_7_2.txt', './data/exam/exam2016/EKu_25_1.txt', './data/exam/exam2017_2/ABl_27_2.txt']\n",
      "Noun_number: ['./data/old IELTS/IELTS2016/JSl_43_1.txt', './data/exam/exam2017/VSa_80_2.txt', './data/2012-2014/esl_00978.txt', './data/exam/exam2017_6/OBy_62_1.txt', './data/old IELTS/IELTS2015/EPa_6_2.txt', './data/exam/exam2014/2012-2014_4/esl_00808.txt', './data/exam/exam2014/VKo_1_2.txt', './data/exam/exam2016/JSl_50_2.txt', './data/exam/exam2014/MTsy_15_2.txt', './data/exam/exam2017/DOv_27_1.txt', './data/exam/exam2014/VKo_7_1.txt', './data/exam/exam2017/EGe_264_1.txt', './data/old IELTS/IELTS2015/EEm_29_2.txt', './data/exam/exam2017/OBy_75_2.txt', './data/exam/exam2017/OBy_179_1.txt']\n",
      "Category_confusion: ['./data/exam/exam2014/EEm_7_1.txt', './data/old IELTS/IELTS2016/EKu_145_1.txt', './data/exam/exam2016/best_works/ZEv_2_2.txt', './data/exam/exam2017_2/ABl_26_2.txt', './data/exam/exam2017/OBy_149_2.txt', './data/exam/exam2017_5_2/EGe_226_2.txt', './data/exam/exam2017_5_2/EGe_146_1.txt', './data/old IELTS/IELTS2016/EKu_61_1.txt', './data/exam/exam2014/AAl_24_2.txt', './data/exam/exam2016/ZEv_52_2.txt', './data/exam/exam2014/AAl_31_2.txt', './data/exam/exam2017_4/DPe_83_1.txt', './data/old IELTS/IELTS2016/EKu_132_1.txt', './data/old IELTS/IELTS2015/EEm_38_1.txt', './data/exam/exam2014/MBi_22_1.txt']\n",
      "Ref_device: ['./data/exam/exam2017_7/VSa_70_2.txt', './data/2012-2014/esl_01230.txt', './data/Exam_practice/OV201617/DIAG/st_29_11.txt', './data/2012-2014/esl_01206.txt', './data/exam/exam2016/OR_5_1.txt', './data/exam/exam2017/OBy_119_1.txt', './data/exam/exam2014/VKo_19_1.txt', './data/old IELTS/IELTS2015/EPa_9_2.txt', './data/exam/exam2017_7/OBy_193_1.txt', './data/2012-2014/esl_00209.txt', './data/exam/exam2017/OBy_181_2.txt', './data/old IELTS/IELTS2015/AKhr_18_2.txt', './data/exam/exam2017/NMya_24_1.txt', './data/exam/exam2017_7/VSa_58_2.txt', './data/exam/exam2014/EPa_41_2.txt']\n",
      "Capitalisation: ['./data/exam/exam2017_6/OBy_17_1.txt', './data/exam/exam2017_6/OBy_123_2.txt', './data/exam/exam2016/OR_55_1.txt', './data/exam/exam2014/EPa_38_2.txt', './data/exam/undefined/DZu_156_1.txt', './data/exam/exam2017/EGe_129_2.txt', './data/exam/exam2016/OR_19_1.txt', './data/exam/exam2017_7/VSa_23_1.txt', './data/exam/exam2017_7/VSa_3_1.txt', './data/old IELTS/IELTS2015/ASt_11_1.txt', './data/exam/exam2017/DPe_29_1.txt', './data/exam/exam2017/ABl_44_1.txt', './data/exam/exam2014/VPe_27_1.txt', './data/exam/exam2017_4/DPe_59_2.txt', './data/old IELTS/IELTS2015/AMe_7_1.txt']\n",
      "Often_confused: ['./data/old IELTS/IELTS2015/EEm_10_2.txt', './data/exam/exam2014/EPa_83_2.txt', './data/exam/exam2014/DAr_38_1.txt', './data/exam/exam2017_4/DPe_69_2.txt', './data/exam/exam2016/best_works/ZEv_10_2.txt', './data/exam/exam2017_5_1/EGe_16_2.txt', './data/exam/exam2014/MGr_6_2.txt', './data/exam/exam2017_4/DPe_59_2.txt', './data/Exam_practice/AV_1_year/Test_essays/student68_final.txt', './data/exam/exam2017/EGe_15_1.txt', './data/Exam_practice/OV_2_year/essays_fr/st_43_1.txt', './data/exam/exam2017/OBy_61_1.txt', './data/old IELTS/IELTS2016/JSl_3_1.txt', './data/exam/exam2014/DAr_11_1.txt', './data/exam/exam2014/EPa_4_2.txt']\n"
     ]
    }
   ],
   "source": [
    "for Tag in RESERVE:\n",
    "  print(Tag+\": \"+str(RESERVE[Tag]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bp8i2RhrdsFb"
   },
   "source": [
    "# Collecting erroneous entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1363,
     "status": "ok",
     "timestamp": 1556565491576,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "9aujtZ-6d0Wa",
    "outputId": "d142a5fe-5fa7-4ef3-a918-5251bc6d0280"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 655 ms, sys: 3.73 ms, total: 658 ms\n",
      "Wall time: 678 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ENTRIES_DATASETS = {}\n",
    "\n",
    "for Tag in Selected_Tags:\n",
    "  if Tag == \"delete\":\n",
    "    _entries = All_Entries.loc[(All_Entries['delete'] == True) & (All_Entries['substr_words'] == 1)]\n",
    "  else:\n",
    "    _entries = All_Entries.loc[(All_Entries['type'] == Tag) & (All_Entries['substr_words'] == 1)]\n",
    "  for path in RESERVE[Tag]:\n",
    "    _entries = _entries.loc[_entries['path'] != path[:-4]+\".ann\"]\n",
    "  ENTRIES_DATASETS[Tag] = _entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 678,
     "status": "ok",
     "timestamp": 1556565520824,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "p4kl0gnoeHEb",
    "outputId": "c87919af-afb6-4d0e-e385-0e83f070d90d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>substring</th>\n",
       "      <th>correction</th>\n",
       "      <th>delete</th>\n",
       "      <th>context</th>\n",
       "      <th>substr_words</th>\n",
       "      <th>unmasked_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42163</th>\n",
       "      <td>./data/exam/exam2016/OR_10_2.ann</td>\n",
       "      <td>T44</td>\n",
       "      <td>Redundant_comp</td>\n",
       "      <td>1605</td>\n",
       "      <td>1608</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>However; laws to reduce the amount of air trav...</td>\n",
       "      <td>1</td>\n",
       "      <td>However; laws to reduce the amount of air trav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23135</th>\n",
       "      <td>./data/exam/exam2017/OBy_134_2.ann</td>\n",
       "      <td>T6</td>\n",
       "      <td>Redundant_comp</td>\n",
       "      <td>203</td>\n",
       "      <td>207</td>\n",
       "      <td>only</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>Someone thinks that countries only need to pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>Someone thinks that countries only need to pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25539</th>\n",
       "      <td>./data/exam/exam2017/OBy_62_2.ann</td>\n",
       "      <td>T28</td>\n",
       "      <td>Redundant_comp</td>\n",
       "      <td>655</td>\n",
       "      <td>659</td>\n",
       "      <td>name</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>Machines analyzing our skin by the our past ex...</td>\n",
       "      <td>1</td>\n",
       "      <td>Machines analyzing our skin by the our past ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52799</th>\n",
       "      <td>./data/exam/exam2017_6/OBy_63_2.ann</td>\n",
       "      <td>T23</td>\n",
       "      <td>Redundant_comp</td>\n",
       "      <td>428</td>\n",
       "      <td>434</td>\n",
       "      <td>around</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>It is very big problem, that we can not marge ...</td>\n",
       "      <td>1</td>\n",
       "      <td>It is very big problem, that we can not marge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108062</th>\n",
       "      <td>./data/old IELTS/IELTS2015/EPa_19_2.ann</td>\n",
       "      <td>T7</td>\n",
       "      <td>Redundant_comp</td>\n",
       "      <td>399</td>\n",
       "      <td>402</td>\n",
       "      <td>who</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>For good understanding for this view I want to...</td>\n",
       "      <td>1</td>\n",
       "      <td>For good understanding for this view I want to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           path   id            type  begin  \\\n",
       "42163          ./data/exam/exam2016/OR_10_2.ann  T44  Redundant_comp   1605   \n",
       "23135        ./data/exam/exam2017/OBy_134_2.ann   T6  Redundant_comp    203   \n",
       "25539         ./data/exam/exam2017/OBy_62_2.ann  T28  Redundant_comp    655   \n",
       "52799       ./data/exam/exam2017_6/OBy_63_2.ann  T23  Redundant_comp    428   \n",
       "108062  ./data/old IELTS/IELTS2015/EPa_19_2.ann   T7  Redundant_comp    399   \n",
       "\n",
       "         end substring correction  delete  \\\n",
       "42163   1608       all               True   \n",
       "23135    207      only               True   \n",
       "25539    659      name               True   \n",
       "52799    434    around               True   \n",
       "108062   402       who               True   \n",
       "\n",
       "                                                  context  substr_words  \\\n",
       "42163   However; laws to reduce the amount of air trav...             1   \n",
       "23135   Someone thinks that countries only need to pro...             1   \n",
       "25539   Machines analyzing our skin by the our past ex...             1   \n",
       "52799   It is very big problem, that we can not marge ...             1   \n",
       "108062  For good understanding for this view I want to...             1   \n",
       "\n",
       "                                         unmasked_context  \n",
       "42163   However; laws to reduce the amount of air trav...  \n",
       "23135   Someone thinks that countries only need to pro...  \n",
       "25539   Machines analyzing our skin by the our past ex...  \n",
       "52799   It is very big problem, that we can not marge ...  \n",
       "108062  For good understanding for this view I want to...  "
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENTRIES_DATASETS[\"delete\"].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aGl0OgWzhi51"
   },
   "source": [
    "# Generating non-erroneous entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hp9K8MwDhodk"
   },
   "source": [
    "We'll create a bunch of non-erroneous entries for each type of error. The number of such entries will be the maximum of `15 * entries_of_this_error_type` and `1 / augmented_ratio_for_this_error_type * entries_of_this_error_type`, we'll just randomly select the lesser necessary amount later. To avoid the possibility of randomly encountering a word which actually is the error of our type we will check that our randomly generated entry does not appear in erroneous contexts. We will also check that our contexts don't match with any of non-one word contexts of the same error type, just for precaution sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PEWYtPq1rn4W"
   },
   "outputs": [],
   "source": [
    "def random_mask_one(intext):\n",
    "  tokenssoup = tknzr.tokenize(intext)\n",
    "  chosen = randint(0, len(tokenssoup)-1)\n",
    "  for i in range(chosen):\n",
    "    intext = intext.replace(tokenssoup[i], chr(8), 1)\n",
    "  intext = intext.replace(tokenssoup[chosen], chr(8), 1)\n",
    "  for i in range(chosen):\n",
    "    intext = intext.replace(chr(8), tokenssoup[i], 1)\n",
    "  spacechars = chr(9)+chr(10)+chr(160)+\" \"\n",
    "  if not re.search(r'['+spacechars+']'+chr(8), intext):\n",
    "    intext = intext.replace(chr(8), ' '+chr(8))\n",
    "  if not re.search(chr(8)+r'['+spacechars+']', intext):\n",
    "    intext = intext.replace(chr(8), chr(8)+' ')\n",
    "  intext = intext.replace(chr(8), \"[MASK]\")\n",
    "  sentences = nltk.sent_tokenize(intext)\n",
    "  for k in range(len(sentences)):\n",
    "    if '[MASK]' in sentences[k]:\n",
    "      if k < 1:\n",
    "        return ' '.join(sentences[0:k+2]), tokenssoup[chosen]\n",
    "      else:\n",
    "        return ' '.join(sentences[k-1:k+2]), tokenssoup[chosen]\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dl3t_RkOsKZV"
   },
   "outputs": [],
   "source": [
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3270522,
     "status": "ok",
     "timestamp": 1556572293899,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "OgR7XiZpnS5E",
    "outputId": "a045c051-405f-4550-a371-155d24365a84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54min 10s, sys: 2.25 s, total: 54min 12s\n",
      "Wall time: 54min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "NOERROR_DATASETS = {}\n",
    "\n",
    "for Tag in Selected_Tags:\n",
    "  _Path = []\n",
    "  _Context = []\n",
    "  _Substring = []\n",
    "  _err_contexts = set(ENTRIES_DATASETS[Tag][\"context\"])\n",
    "  if Tag == \"delete\":\n",
    "    _unmasked_contexts = set(All_Entries.loc[(All_Entries['delete'] == True) & (All_Entries['substr_words'] != 1)][\"unmasked_context\"])\n",
    "  else:\n",
    "    _unmasked_contexts = set(All_Entries.loc[(All_Entries['type'] == Tag) & (All_Entries['substr_words'] != 1)][\"unmasked_context\"])\n",
    "  \n",
    "  err_contexts = len(ENTRIES_DATASETS[Tag])\n",
    "  contexts_needed = max(err_contexts * 15, ceil(err_contexts * (1/Summary[\"Augmented ratio\"][Tag])))\n",
    "  \n",
    "  i = 0\n",
    "  while (i < contexts_needed):\n",
    "    _path = random.choice(Texts)\n",
    "    if _path in RESERVE[Tag]:\n",
    "      continue\n",
    "    context, substring = random_mask_one(Text_Dict[_path])\n",
    "    if context in _err_contexts:\n",
    "      continue\n",
    "    if context.replace(\"[MASK]\", substring) in _unmasked_contexts:\n",
    "      continue\n",
    "    _Path.append(_path)\n",
    "    _Context.append(context)\n",
    "    _Substring.append(substring)\n",
    "    i += 1\n",
    "  \n",
    "  NOERROR_DATASETS[Tag] = pd.DataFrame({\n",
    "      \"path\": _Path,\n",
    "      \"context\": _Context,\n",
    "      \"substring\": _Substring\n",
    "  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nsbl0BfG_fnJ"
   },
   "source": [
    "We better save it off the bat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5038,
     "status": "ok",
     "timestamp": 1556573377512,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "XSarzvO5DhNV",
    "outputId": "0f95a390-2adc-4645-aae1-176d9f2148a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.97 s, sys: 1.11 s, total: 4.08 s\n",
      "Wall time: 4.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for jsonname in Selected_Tags:\n",
    "  with open(jsonname+\".json\", 'w', encoding=\"utf-8\") as outie:\n",
    "    outie.write(NOERROR_DATASETS[jsonname].to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AJh_36xcDDB2"
   },
   "outputs": [],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once in a notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22704,
     "status": "ok",
     "timestamp": 1556573415221,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "57ajXFuqDgYO",
    "outputId": "b0be7fa6-e948-40a5-bacd-11b7f7664f2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1cFHqKQVBwsICImDLAExNiD1cIGW1Y1V2\n",
      "Uploaded file with ID 1TBcIrjzOvF5_dmxIkRmUuVFNzMuoI65i\n",
      "Uploaded file with ID 1yCWQSRutdo4eEmJcSgGno8r89CtPKZX1\n",
      "Uploaded file with ID 1sKi6SOnPncLgGTpSMsBSYrr4Ukua0m5x\n",
      "Uploaded file with ID 1cX8QHls87wPNgvPgqvV6KTNkE0gxIeBH\n",
      "Uploaded file with ID 17f9HF5fOfEep8rFjA05pqWqbOl8qaWa9\n",
      "Uploaded file with ID 1tRimxmFOm5xPz9sddjcTjdrjHGn4oRlL\n",
      "Uploaded file with ID 1c6lKEcYM-KVSf8HQvaIl3dPIbse35ATJ\n",
      "Uploaded file with ID 1kM2dUilTXes2P8kGWUSO9Vr5AaQoazx6\n",
      "Uploaded file with ID 16kEGsBzihQyE-cDPOc92Rl4ItJpEetAy\n"
     ]
    }
   ],
   "source": [
    "# Create & upload a file.\n",
    "\n",
    "for jsonname in Selected_Tags:\n",
    "  uploaded = drive.CreateFile({'title': jsonname+\".json\"})\n",
    "  uploaded.SetContentFile(jsonname+\".json\")\n",
    "  uploaded.Upload()\n",
    "  print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTiwskV4AqWg"
   },
   "source": [
    "# Preparing resulting files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fi0ehr8lA1hn"
   },
   "source": [
    "Around here we should get rid of unnecessary columns in erroneous datasets. We'll keep file paths for now just to keep track. At this point we also divide the data into training and test sets (80% and 20%, keeping the erroneous to non-erroneous ratio at constant in each subset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1BKzDnL4BhTJ"
   },
   "outputs": [],
   "source": [
    "for Tag in Selected_Tags:\n",
    "  ENTRIES_DATASETS[Tag].drop([\"id\", \"type\", \"begin\", \"end\", \"correction\", \"delete\", \"substr_words\", \"unmasked_context\"], axis=1, inplace=True)\n",
    "  ENTRIES_DATASETS[Tag][\"is_error\"] = 1\n",
    "  NOERROR_DATASETS[Tag][\"is_error\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "adTToX0EC020"
   },
   "outputs": [],
   "source": [
    "# This also randomizes them, so we can just divide them with slices next\n",
    "\n",
    "MainDatasets = {Tag: ENTRIES_DATASETS[Tag] for Tag in Selected_Tags}\n",
    "ToFifteen_Complements = {Tag: NOERROR_DATASETS[Tag].sample(len(ENTRIES_DATASETS[Tag])*15).reset_index(drop=True) for Tag in Selected_Tags}\n",
    "AugmentedRatio_Complements = {Tag: NOERROR_DATASETS[Tag].sample(ceil(len(ENTRIES_DATASETS[Tag]) * (1/Summary[\"Augmented ratio\"][Tag]))).reset_index(drop=True) for Tag in Selected_Tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2230,
     "status": "ok",
     "timestamp": 1556575010548,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "3-X8x2-YEth7",
    "outputId": "d23aff4e-1a84-4563-93bf-7873fb737594"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ToFifteen = {Tag: {\"train\": pd.concat([MainDatasets[Tag][:round(len(MainDatasets[Tag])*0.8)], ToFifteen_Complements[Tag][:round(len(ToFifteen_Complements[Tag])*0.8)]]).reset_index(drop=True), \"test\": pd.concat([MainDatasets[Tag][round(len(MainDatasets[Tag])*0.8):], ToFifteen_Complements[Tag][round(len(ToFifteen_Complements[Tag])*0.8):]]).reset_index(drop=True)} for Tag in Selected_Tags}\n",
    "AugmentedRatio = {Tag: {\"train\": pd.concat([MainDatasets[Tag][:round(len(MainDatasets[Tag])*0.8)], AugmentedRatio_Complements[Tag][:round(len(AugmentedRatio_Complements[Tag])*0.8)]]).reset_index(drop=True), \"test\": pd.concat([MainDatasets[Tag][round(len(MainDatasets[Tag])*0.8):], AugmentedRatio_Complements[Tag][round(len(AugmentedRatio_Complements[Tag])*0.8):]]).reset_index(drop=True)} for Tag in Selected_Tags}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IrriUjn8G4f6"
   },
   "source": [
    "Let's now save all our precious freshly-generated datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1769,
     "status": "ok",
     "timestamp": 1556575562489,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "SKgtPqTeHLRC",
    "outputId": "4b153423-9cb5-4f11-c82a-424112df21ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 657 ms, sys: 369 ms, total: 1.03 s\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for jsonname in Selected_Tags:\n",
    "  with open(jsonname+\".json\", 'w', encoding=\"utf-8\") as outie:\n",
    "    outie.write(AugmentedRatio[jsonname][\"test\"].to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "v9Ms2QBdZAsi"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "category_confusion_files = ['./data/exam/exam2014/EEm_7_1.txt', './data/old IELTS/IELTS2016/EKu_145_1.txt', './data/exam/exam2016/best_works/ZEv_2_2.txt', './data/exam/exam2017_2/ABl_26_2.txt', './data/exam/exam2017/OBy_149_2.txt', './data/exam/exam2017_5_2/EGe_226_2.txt', './data/exam/exam2017_5_2/EGe_146_1.txt', './data/old IELTS/IELTS2016/EKu_61_1.txt', './data/exam/exam2014/AAl_24_2.txt', './data/exam/exam2016/ZEv_52_2.txt', './data/exam/exam2014/AAl_31_2.txt', './data/exam/exam2017_4/DPe_83_1.txt', './data/old IELTS/IELTS2016/EKu_132_1.txt', './data/old IELTS/IELTS2015/EEm_38_1.txt', './data/exam/exam2014/MBi_22_1.txt']\n",
    "category_confusion_dict = {path: Text_Dict[path] for path in category_confusion_files}\n",
    "with open(\"category_confusion_dict.json\", \"w\") as outjson:\n",
    "  json.dump(category_confusion_dict, outjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32461,
     "status": "ok",
     "timestamp": 1557420347345,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "K4GRch4cHLRL",
    "outputId": "6376a0a3-b80d-4cdd-c003-d46b8be23e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |▎                               | 10kB 15.9MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 20kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 30kB 2.6MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 40kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 51kB 2.1MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 61kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 71kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 81kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 92kB 3.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 102kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 112kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 122kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 133kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 143kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 153kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 163kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 174kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 184kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 194kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 204kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 215kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 225kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 235kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 245kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 256kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 266kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 276kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 286kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 296kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 307kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 317kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 327kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 337kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 348kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 358kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 368kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 378kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 389kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 399kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 409kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 419kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 430kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 440kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 450kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 460kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 471kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 481kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 491kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 501kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 512kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 522kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 532kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 542kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 552kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 563kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 573kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 583kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 593kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 604kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 614kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 624kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 634kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 645kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 655kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 665kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 675kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 686kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 696kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 706kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 716kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 727kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 737kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 747kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 757kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 768kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 778kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 788kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 798kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 808kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 819kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 829kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 839kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 849kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 860kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 870kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 880kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 890kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 901kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 911kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 921kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 931kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 942kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 952kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 962kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 972kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 983kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 993kB 2.8MB/s \n",
      "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once in a notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1670,
     "status": "ok",
     "timestamp": 1557420352071,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "pf37U_SUHLRP",
    "outputId": "0f721e9d-f651-4b18-ff91-9783a7685387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1wS1SrvAOpE6TDl2pbWDDs1drYoOrDabH\n"
     ]
    }
   ],
   "source": [
    "# Create & upload a file.\n",
    "\n",
    "jsonname = \"category_confusion_dict\"\n",
    "uploaded = drive.CreateFile({'title': jsonname+\".json\"})\n",
    "uploaded.SetContentFile(jsonname+\".json\")\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13170,
     "status": "ok",
     "timestamp": 1556575582807,
     "user": {
      "displayName": "Ivan Torubarov",
      "photoUrl": "",
      "userId": "07481003931234110333"
     },
     "user_tz": -180
    },
    "id": "v__m5EZUZr9t",
    "outputId": "0c29308c-eff7-4631-b229-2f3437b6e209"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1a7ojnrobOMIBGiaiNH7IASDpu52XUg-2\n",
      "Uploaded file with ID 1WJq-oFRAizePrOtYYHp4MJn5ULcOGpff\n",
      "Uploaded file with ID 1imMW4-z_JONepWYCho1dlRQL6reSBOau\n",
      "Uploaded file with ID 1_BhAHeVBBgJqxHFSyZm-uPnv3j7n7Plo\n",
      "Uploaded file with ID 1HBsUINkt-wx5dvrWXjWSvaVo2f9lvK5s\n",
      "Uploaded file with ID 1_64bYqZTfCi1TRn7QmxSJKh-eaNtW0bd\n",
      "Uploaded file with ID 1psaSVmvO86QBEbhLNHk2N4iIRdg6Fysr\n",
      "Uploaded file with ID 11g3GtCdf9NRZXRNi3XohZjBscQ8BZUUo\n",
      "Uploaded file with ID 1xj6z47TrOrh8IOp-frKCXo7ed5ej6KDy\n",
      "Uploaded file with ID 1UANXhnjWyxrzil_h7EreKoj24EXLVnfx\n"
     ]
    }
   ],
   "source": [
    "# Create & upload a file.\n",
    "\n",
    "uploaded = drive.CreateFile({'title': jsonname+\".json\"})\n",
    "  uploaded.SetContentFile(jsonname+\".json\")\n",
    "  uploaded.Upload()\n",
    "  print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "REALEC AutoAnnotator Generating datasets",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
