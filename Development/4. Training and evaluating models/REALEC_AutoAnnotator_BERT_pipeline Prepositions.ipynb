{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "j0a4mTk9o1Qg"
   },
   "outputs": [],
   "source": [
    "# Copyright 2019 Google Inc.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCpvgG0vwXAZ"
   },
   "source": [
    "#Predicting Movie Review Sentiment with BERT on TF Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xiYrZKaHwV81"
   },
   "source": [
    "If you’ve been following Natural Language Processing over the past year, you’ve probably heard of BERT: Bidirectional Encoder Representations from Transformers. It’s a neural network architecture designed by Google researchers that’s totally transformed what’s state-of-the-art for NLP tasks, like text classification, translation, summarization, and question answering.\n",
    "\n",
    "Now that BERT's been added to [TF Hub](https://www.tensorflow.org/hub) as a loadable module, it's easy(ish) to add into existing Tensorflow text pipelines. In an existing pipeline, BERT can replace text embedding layers like ELMO and GloVE. Alternatively, [finetuning](http://wiki.fast.ai/index.php/Fine_tuning) BERT can provide both an accuracy boost and faster training time in many cases.\n",
    "\n",
    "Here, we'll train a model to predict whether an IMDB movie review is positive or negative using BERT in Tensorflow with tf hub. Some code was adapted from [this colab notebook](https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb). Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "hsZvic2YxnTz",
    "outputId": "8940fd81-1ce6-4fbd-a794-6651527a45d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0509 06:53:39.198721 140552650831616 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cp5wfXDx5SPH"
   },
   "source": [
    "In addition to the standard libraries we imported above, we'll need to install BERT's python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hhbGEfwgdEtw"
   },
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVB3eOcjxxm1"
   },
   "source": [
    "Below, we'll set an output directory location to store our model output and checkpoints. This can be a local directory, in which case you'd set OUTPUT_DIR to the name of the directory you'd like to create. If you're running this code in Google's hosted Colab, the directory won't persist after the Colab session ends.\n",
    "\n",
    "Alternatively, if you're a GCP user, you can store output in a GCP bucket. To do that, set a directory name in OUTPUT_DIR and the name of the GCP bucket in the BUCKET field.\n",
    "\n",
    "Set DO_DELETE to rewrite the OUTPUT_DIR if it exists. Otherwise, Tensorflow will load existing model checkpoints from that directory (if they exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir bert_new_prepositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"bert_new_prepositions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "US_EAnICvP7f",
    "outputId": "e0fd0d9f-3ef6-4367-9535-8ec4a95b831c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Model output directory: bert_new_prepositions *****\n"
     ]
    }
   ],
   "source": [
    "# Set the output directory for saving model file\n",
    "# Optionally, set a GCP bucket location\n",
    "\n",
    "OUTPUT_DIR = 'bert_new_prepositions'#@param {type:\"string\"}\n",
    "#@markdown Whether or not to clear/delete the directory and create a new one\n",
    "DO_DELETE = False #@param {type:\"boolean\"}\n",
    "#@markdown Set USE_BUCKET and BUCKET if you want to (optionally) store model output on GCP bucket.\n",
    "USE_BUCKET = False #@param {type:\"boolean\"}\n",
    "BUCKET = 'BUCKET_NAME' #@param {type:\"string\"}\n",
    "\n",
    "if USE_BUCKET:\n",
    "  OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET, OUTPUT_DIR)\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()\n",
    "\n",
    "if DO_DELETE:\n",
    "  try:\n",
    "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
    "  except:\n",
    "    # Doesn't matter if the directory didn't exist\n",
    "    pass\n",
    "# tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmFYvkylMwXn"
   },
   "source": [
    "#Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MC_w8SRqN0fr"
   },
   "source": [
    "First, let's download the dataset, hosted by Stanford. The code below, which downloads, extracts, and imports the IMDB Large Movie Review Dataset, is borrowed from [this Tensorflow tutorial](https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fom_ff20gyy6"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "QITjll8L1AnJ"
   },
   "outputs": [],
   "source": [
    "Conventional = [\"Generic correction\", \"Punctuation\", \"Spelling\", \"Capitalisation\", \"Grammar\", \"Determiners\", \"Articles\", \"Quantifiers\", \"Verbs\", \"Tense\", \"Choice of tense\", \"Tense form\", \"Voice\", \"Modals\", \"Verb pattern\", \"Intransitive verb\", \"Transitive verb\", \"Reflexive verb\", \"Verb with as\", \"Ambitransitive verb\", \"Two verbal forms in the predicate\", \"Verb + Infinitive\", \"Verb + Gerund\", \"Verb + Infinitive OR Gerund\", \"Verb + Bare Infinitive\", \"Verb + Object/Addressee + Bare Infinitive\", \"Infinitive Restoration Alternation\", \"Verb + Participle\", \"Get + participle\", \"Complex-object verb\", \"Verbal idiom\", \"Prepositional or phrasal verb\", \"Dative verb with alternation\", \"Verb followed by a clause\", \"Verb + that/WH + Clause\", \"Verb + if/whether + clause\", \"Verb + that + Subjunctive clause\", \"Verb + it + Conj + Clause\", \"Participial construction\", \"Infinitive construction\", \"Gerund phrase\", \"Nouns\", \"Countable/uncountable\", \"Prepositional noun\", \"Possessive form of a noun\", \"Noun as an attribute\", \"Noun + Infinitive\", \"Noun number\", \"Prepositions\", \"Conjunctions\", \"Adjectives\", \"Comparative degree of adjectives\", \"Superlative degree of adjectives\", \"Prepositional adjective\", \"Adjective as a collective noun\", \"Adverbs\", \"Comparative degree of adverbs\", \"Superlative degree of adverbs\", \"Prepositional adverb\", \"Numerals\", \"Pronouns\", \"Agreement\", \"Word order\", \"Standard word order\", \"Emphatic shift\", \"Cleft sentence\", \"Interrogative word order\", \"Incomplete sentence\", \"Exclamation\", \"Title structure\", \"Note structure\", \"Conditionals\", \"Attributes\", \"Relative clause\", \"Defining relative clause\", \"Non-defining relative clause\", \"Coordinate relative clause\", \"Attributive participial construction\", \"Parallel constructions\", \"Negation\", \"Comparative construction\", \"Numerical comparison\", \"Confusion of structures\", \"Vocabulary\", \"Word choice\", \"Choice of lexical item\", \"Words often confused\", \"Choice of a part of lexical item\", \"Absence of certain components of a collocation\", \"Redundant word(s)\", \"Word formation\", \"Derivational affixes\", \"Formational suffix\", \"Formational prefix\", \"Confusion of categories\", \"Compound word\", \"Discourse\", \"Referential device\", \"Coherence\", \"Linking device\", \"Inappropriate register\", \"Absence of a component in clause or sentence\", \"Redundant component in clause or sentence\", \"Absence of necessary explanation or detail\", \"Deletion\"]\n",
    "Tags = [\"Correction\", \"Punctuation\", \"Spelling\", \"Capitalisation\", \"Grammar\", \"Determiners\", \"Articles\", \"Quantifiers\", \"Verbs\", \"Tense\", \"Tense_choice\", \"Tense_form\", \"Voice\", \"Modals\", \"Verb_pattern\", \"Intransitive\", \"Transitive\", \"Reflexive_verb\", \"Presentation\", \"Ambitransitive\", \"Two_in_a_row\", \"Verb_Inf\", \"Verb_Gerund\", \"Verb_Inf_Gerund\", \"Verb_Bare_Inf\", \"Verb_object_bare\", \"Restoration_alter\", \"Verb_part\", \"Get_part\", \"Complex_obj\", \"Verbal_idiom\", \"Prepositional_verb\", \"Dative\", \"Followed_by_a_clause\", \"that_clause\", \"if_whether_clause\", \"that_subj_clause\", \"it_conj_clause\", \"Participial_constr\", \"Infinitive_constr\", \"Gerund_phrase\", \"Nouns\", \"Countable_uncountable\", \"Prepositional_noun\", \"Possessive\", \"Noun_attribute\", \"Noun_inf\", \"Noun_number\", \"Prepositions\", \"Conjunctions\", \"Adjectives\", \"Comparative_adj\", \"Superlative_adj\", \"Prepositional_adjective\", \"Adj_as_collective\", \"Adverbs\", \"Comparative_adv\", \"Superlative_adv\", \"Prepositional_adv\", \"Numerals\", \"Pronouns\", \"Agreement_errors\", \"Word_order\", \"Standard\", \"Emphatic\", \"Cleft\", \"Interrogative\", \"Abs_comp_clause\", \"Exclamation\", \"Title_structure\", \"Note_structure\", \"Conditionals\", \"Attributes\", \"Relative_clause\", \"Defining\", \"Non_defining\", \"Coordinate\", \"Attr_participial\", \"Lack_par_constr\", \"Negation\", \"Comparative_constr\", \"Numerical\", \"Confusion_of_structures\", \"Vocabulary\", \"Word_choice\", \"lex_item_choice\", \"Often_confused\", \"lex_part_choice\", \"Absence_comp_colloc\", \"Redundant\", \"Derivation\", \"Formational_affixes\", \"Suffix\", \"Prefix\", \"Category_confusion\", \"Compound_word\", \"Discourse\", \"Ref_device\", \"Coherence\", \"Linking_device\", \"Inappropriate_register\", \"Absence_comp_sent\", \"Redundant_comp\", \"Absence_explanation\", \"delete\"]\n",
    "translate_dict = {e[0]: e[1] for e in zip(Conventional, Tags)}\n",
    "\n",
    "error_type = \"Prepositions\" #@param [\"Spelling\", \"Choice of lexical item\", \"Deletion\", \"Prepositions\", \"Agreement\", \"Noun number\", \"Confusion of categories\", \"Referential device\", \"Capitalisation\", \"Words often confused\"]\n",
    "error_ratio = \"ToFifteen\" #@param [\"ToFifteen\", \"AugmentedRatio\"]\n",
    "\n",
    "error_type = translate_dict[error_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DHdoFRKc4cqQ"
   },
   "source": [
    "It's about time we named our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "OBrzdw7j4eer"
   },
   "outputs": [],
   "source": [
    "modelname = \"Prepositions_ToFifteen\" # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AkQn6bJK_CIB"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "filename = error_ratio+\"/train/\"+error_type+\".json\"\n",
    "shutil.copy2('./Datasets/'+filename,'.')\n",
    "trn = pd.read_json(error_type+\".json\").reset_index(drop=True)\n",
    "trn[\"is_error\"] = trn[\"is_error\"].astype(int)\n",
    "\n",
    "filename = error_ratio+\"/test/\"+error_type+\".json\"\n",
    "shutil.copy2('./Datasets/'+filename,'./'+error_type+'_test.json')\n",
    "tst = pd.read_json(error_type+\"_test.json\").reset_index(drop=True)\n",
    "tst[\"is_error\"] = tst[\"is_error\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wBe3GK5Rhja7",
    "outputId": "4044934a-db80-433d-ff53-7ee6f3dc1ae1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54054"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XA8WHJgzhIZf"
   },
   "source": [
    "To keep training fast, we'll take a sample of 5000 train and test examples, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Hqutj52z7yVP"
   },
   "outputs": [],
   "source": [
    "train = trn\n",
    "test = tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "prRQM8pDi8xI",
    "outputId": "3cd18af4-2210-468c-e3a1-1358628421ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['context', 'is_error', 'path', 'substring'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sfRnHSz3iSXz"
   },
   "source": [
    "For us, our input data is the 'sentence' column and our label is the 'polarity' column (0, 1 for negative and positive, respecitvely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IuMOGwFui4it"
   },
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'context'\n",
    "SUBSTR_COLUMN = 'substring'\n",
    "LABEL_COLUMN = 'is_error'\n",
    "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
    "label_list = [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V399W0rqNJ-Z"
   },
   "source": [
    "#Data Preprocessing\n",
    "We'll need to transform our data into a format BERT understands. This involves two steps. First, we create  `InputExample`'s using the constructor provided in the BERT library.\n",
    "\n",
    "- `text_a` is the text we want to classify, which in this case, is the `Request` field in our Dataframe. \n",
    "- `text_b` is used if we're training a model to understand the relationship between sentences (i.e. is `text_b` a translation of `text_a`? Is `text_b` an answer to the question asked by `text_a`?). This doesn't apply to our task, so we can leave `text_b` blank.\n",
    "- `label` is the label for our example, i.e. True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "p9gEt5SmM6i6"
   },
   "outputs": [],
   "source": [
    "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = x[SUBSTR_COLUMN], \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = x[SUBSTR_COLUMN], \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1156
    },
    "colab_type": "code",
    "id": "H7fHpWRZYZpp",
    "outputId": "6fbba759-ca5c-4c7a-94ad-2f0f327db16f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <bert.run_classifier.InputExample object at 0x...\n",
       "1        <bert.run_classifier.InputExample object at 0x...\n",
       "2        <bert.run_classifier.InputExample object at 0x...\n",
       "3        <bert.run_classifier.InputExample object at 0x...\n",
       "4        <bert.run_classifier.InputExample object at 0x...\n",
       "5        <bert.run_classifier.InputExample object at 0x...\n",
       "6        <bert.run_classifier.InputExample object at 0x...\n",
       "7        <bert.run_classifier.InputExample object at 0x...\n",
       "8        <bert.run_classifier.InputExample object at 0x...\n",
       "9        <bert.run_classifier.InputExample object at 0x...\n",
       "10       <bert.run_classifier.InputExample object at 0x...\n",
       "11       <bert.run_classifier.InputExample object at 0x...\n",
       "12       <bert.run_classifier.InputExample object at 0x...\n",
       "13       <bert.run_classifier.InputExample object at 0x...\n",
       "14       <bert.run_classifier.InputExample object at 0x...\n",
       "15       <bert.run_classifier.InputExample object at 0x...\n",
       "16       <bert.run_classifier.InputExample object at 0x...\n",
       "17       <bert.run_classifier.InputExample object at 0x...\n",
       "18       <bert.run_classifier.InputExample object at 0x...\n",
       "19       <bert.run_classifier.InputExample object at 0x...\n",
       "20       <bert.run_classifier.InputExample object at 0x...\n",
       "21       <bert.run_classifier.InputExample object at 0x...\n",
       "22       <bert.run_classifier.InputExample object at 0x...\n",
       "23       <bert.run_classifier.InputExample object at 0x...\n",
       "24       <bert.run_classifier.InputExample object at 0x...\n",
       "25       <bert.run_classifier.InputExample object at 0x...\n",
       "26       <bert.run_classifier.InputExample object at 0x...\n",
       "27       <bert.run_classifier.InputExample object at 0x...\n",
       "28       <bert.run_classifier.InputExample object at 0x...\n",
       "29       <bert.run_classifier.InputExample object at 0x...\n",
       "                               ...                        \n",
       "54024    <bert.run_classifier.InputExample object at 0x...\n",
       "54025    <bert.run_classifier.InputExample object at 0x...\n",
       "54026    <bert.run_classifier.InputExample object at 0x...\n",
       "54027    <bert.run_classifier.InputExample object at 0x...\n",
       "54028    <bert.run_classifier.InputExample object at 0x...\n",
       "54029    <bert.run_classifier.InputExample object at 0x...\n",
       "54030    <bert.run_classifier.InputExample object at 0x...\n",
       "54031    <bert.run_classifier.InputExample object at 0x...\n",
       "54032    <bert.run_classifier.InputExample object at 0x...\n",
       "54033    <bert.run_classifier.InputExample object at 0x...\n",
       "54034    <bert.run_classifier.InputExample object at 0x...\n",
       "54035    <bert.run_classifier.InputExample object at 0x...\n",
       "54036    <bert.run_classifier.InputExample object at 0x...\n",
       "54037    <bert.run_classifier.InputExample object at 0x...\n",
       "54038    <bert.run_classifier.InputExample object at 0x...\n",
       "54039    <bert.run_classifier.InputExample object at 0x...\n",
       "54040    <bert.run_classifier.InputExample object at 0x...\n",
       "54041    <bert.run_classifier.InputExample object at 0x...\n",
       "54042    <bert.run_classifier.InputExample object at 0x...\n",
       "54043    <bert.run_classifier.InputExample object at 0x...\n",
       "54044    <bert.run_classifier.InputExample object at 0x...\n",
       "54045    <bert.run_classifier.InputExample object at 0x...\n",
       "54046    <bert.run_classifier.InputExample object at 0x...\n",
       "54047    <bert.run_classifier.InputExample object at 0x...\n",
       "54048    <bert.run_classifier.InputExample object at 0x...\n",
       "54049    <bert.run_classifier.InputExample object at 0x...\n",
       "54050    <bert.run_classifier.InputExample object at 0x...\n",
       "54051    <bert.run_classifier.InputExample object at 0x...\n",
       "54052    <bert.run_classifier.InputExample object at 0x...\n",
       "54053    <bert.run_classifier.InputExample object at 0x...\n",
       "Length: 54054, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_InputExamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SCZWZtKxObjh"
   },
   "source": [
    "Next, we need to preprocess our data so that it matches the data BERT was trained on. For this, we'll need to do a couple of things (but don't worry--this is also included in the Python library):\n",
    "\n",
    "\n",
    "1. Lowercase our text (if we're using a BERT lowercase model)\n",
    "2. Tokenize it (i.e. \"sally says hi\" -> [\"sally\", \"says\", \"hi\"])\n",
    "3. Break words into WordPieces (i.e. \"calling\" -> [\"call\", \"##ing\"])\n",
    "4. Map our words to indexes using a vocab file that BERT provides\n",
    "5. Add special \"CLS\" and \"SEP\" tokens (see the [readme](https://github.com/google-research/bert))\n",
    "6. Append \"index\" and \"segment\" tokens to each input (see the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf))\n",
    "\n",
    "Happily, we don't have to worry about most of these details.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qMWiDtpyQSoU"
   },
   "source": [
    "To start, we'll need to load a vocabulary file and lowercasing information directly from the BERT tf hub module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "colab_type": "code",
    "id": "IhJSe0QHNG7U",
    "outputId": "03814c09-4cd1-4eea-8e14-e101ccd96920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:07.528349 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1\"\n",
    "\n",
    "class NonMaskOmittingTokenizer(bert.tokenization.FullTokenizer):\n",
    "  def tokenize(self, text):\n",
    "    split_tokens = []\n",
    "    for token in self.basic_tokenizer.tokenize(text):\n",
    "      for sub_token in self.wordpiece_tokenizer.tokenize(token):\n",
    "        split_tokens.append(sub_token)\n",
    "\n",
    "    for index, item in enumerate(split_tokens):\n",
    "      if index >= len(split_tokens)-2:\n",
    "        break\n",
    "      if item == '[' and split_tokens[index + 1] == 'MA' and split_tokens[index + 2] == '##S' and split_tokens[index + 3] == '##K' and split_tokens[index + 4] == ']':\n",
    "        split_tokens[index] = \"[MASK]\"\n",
    "        del split_tokens[index + 1]\n",
    "        del split_tokens[index + 1]\n",
    "        del split_tokens[index + 1]\n",
    "        del split_tokens[index + 1]\n",
    "\n",
    "    return split_tokens\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return NonMaskOmittingTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "dsBo6RCtQmwx",
    "outputId": "fee19669-f503-446b-ffd5-a03e2f19533e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'here',\n",
       " \"'\",\n",
       " 's',\n",
       " 'an',\n",
       " 'example',\n",
       " 'of',\n",
       " 'using',\n",
       " 'the',\n",
       " 'B',\n",
       " '##ER',\n",
       " '##T',\n",
       " '[MASK]',\n",
       " 'token',\n",
       " '##izer']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"This here's an example of using the BERT [MASK] tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0OEzfFIt6GIc"
   },
   "source": [
    "Using our tokenizer, we'll call `run_classifier.convert_examples_to_features` on our InputExamples to convert them into features BERT understands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3159
    },
    "colab_type": "code",
    "id": "LL5W8gEGRTAf",
    "outputId": "a4373d00-3f0d-4b4b-b00a-5f1e1f9e15d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 54054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.942858 140552650831616 tf_logging.py:115] Writing example 0 of 54054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.946878 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.948756 140552650831616 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] On the line chart we can see how online adults from the USA [MASK] different age groups use Facebook , In ##sta ##gram and Link ##ed ##I ##n . We can see that Facebook is the most popular social net ##wo ##r for all the groups , it is used by more than half people in any of them . [SEP] from [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.950554 140552650831616 tf_logging.py:115] tokens: [CLS] On the line chart we can see how online adults from the USA [MASK] different age groups use Facebook , In ##sta ##gram and Link ##ed ##I ##n . We can see that Facebook is the most popular social net ##wo ##r for all the groups , it is used by more than half people in any of them . [SEP] from [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1212 1103 1413 3481 1195 1169 1267 1293 3294 6323 1121 1103 3066 103 1472 1425 2114 1329 9078 117 1130 8419 12139 1105 11193 1174 2240 1179 119 1284 1169 1267 1115 9078 1110 1103 1211 1927 1934 5795 12821 1197 1111 1155 1103 2114 117 1122 1110 1215 1118 1167 1190 1544 1234 1107 1251 1104 1172 119 102 1121 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.952424 140552650831616 tf_logging.py:115] input_ids: 101 1212 1103 1413 3481 1195 1169 1267 1293 3294 6323 1121 1103 3066 103 1472 1425 2114 1329 9078 117 1130 8419 12139 1105 11193 1174 2240 1179 119 1284 1169 1267 1115 9078 1110 1103 1211 1927 1934 5795 12821 1197 1111 1155 1103 2114 117 1122 1110 1215 1118 1167 1190 1544 1234 1107 1251 1104 1172 119 102 1121 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.953851 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.955336 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.956699 140552650831616 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.959431 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.961011 140552650831616 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] These people put forward convincing arguments for the sa ##et is that sport develop not only physical skills , but mental too . Nowadays , sport and active life is a key [MASK] success . For example , in this year O ##lim ##pic Games encouraged people . [SEP] of [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.962526 140552650831616 tf_logging.py:115] tokens: [CLS] These people put forward convincing arguments for the sa ##et is that sport develop not only physical skills , but mental too . Nowadays , sport and active life is a key [MASK] success . For example , in this year O ##lim ##pic Games encouraged people . [SEP] of [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1636 1234 1508 1977 13870 9989 1111 1103 21718 2105 1110 1115 4799 3689 1136 1178 2952 4196 117 1133 4910 1315 119 25883 117 4799 1105 2327 1297 1110 170 2501 103 2244 119 1370 1859 117 1107 1142 1214 152 24891 20437 2957 6182 1234 119 102 1104 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.963922 140552650831616 tf_logging.py:115] input_ids: 101 1636 1234 1508 1977 13870 9989 1111 1103 21718 2105 1110 1115 4799 3689 1136 1178 2952 4196 117 1133 4910 1315 119 25883 117 4799 1105 2327 1297 1110 170 2501 103 2244 119 1370 1859 117 1107 1142 1214 152 24891 20437 2957 6182 1234 119 102 1104 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.965331 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.966829 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.968077 140552650831616 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.970305 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.971689 140552650831616 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] It reflects negatively not only on human beings but on native plants and creatures . The main reason [MASK] global warming is carbon dioxide emission which is caused by oil burning in di ##ff ##ire ##nt mechanical engines . These engines have planes , cars , motorcycles , rockets etc . [SEP] for [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.972820 140552650831616 tf_logging.py:115] tokens: [CLS] It reflects negatively not only on human beings but on native plants and creatures . The main reason [MASK] global warming is carbon dioxide emission which is caused by oil burning in di ##ff ##ire ##nt mechanical engines . These engines have planes , cars , motorcycles , rockets etc . [SEP] for [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1135 11363 21598 1136 1178 1113 1769 9476 1133 1113 2900 3546 1105 7207 119 1109 1514 2255 103 4265 14110 1110 6302 15163 17744 1134 1110 2416 1118 2949 4968 1107 4267 3101 5817 2227 6676 4540 119 1636 4540 1138 10025 117 3079 117 21552 117 18437 3576 119 102 1111 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.974241 140552650831616 tf_logging.py:115] input_ids: 101 1135 11363 21598 1136 1178 1113 1769 9476 1133 1113 2900 3546 1105 7207 119 1109 1514 2255 103 4265 14110 1110 6302 15163 17744 1134 1110 2416 1118 2949 4968 1107 4267 3101 5817 2227 6676 4540 119 1636 4540 1138 10025 117 3079 117 21552 117 18437 3576 119 102 1111 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.975594 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.976870 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.978170 140552650831616 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.980636 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.982703 140552650831616 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] In Italy group of this age ( 0 - 14 years ) took almost only a 1 / 7 of a chart , and the main position was given to middle - aged group which was four times larger than young - aged one . In Yemen people of 15 - 59 years were numerous , almost like young ##sters , but less [MASK] 4 per cents . So , the rest 3 , 6 % were residents older than 60 years . [SEP] for [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.984854 140552650831616 tf_logging.py:115] tokens: [CLS] In Italy group of this age ( 0 - 14 years ) took almost only a 1 / 7 of a chart , and the main position was given to middle - aged group which was four times larger than young - aged one . In Yemen people of 15 - 59 years were numerous , almost like young ##sters , but less [MASK] 4 per cents . So , the rest 3 , 6 % were residents older than 60 years . [SEP] for [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1130 2413 1372 1104 1142 1425 113 121 118 1489 1201 114 1261 1593 1178 170 122 120 128 1104 170 3481 117 1105 1103 1514 1700 1108 1549 1106 2243 118 4079 1372 1134 1108 1300 1551 2610 1190 1685 118 4079 1141 119 1130 14466 1234 1104 1405 118 4589 1201 1127 2567 117 1593 1176 1685 12429 117 1133 1750 103 125 1679 18748 119 1573 117 1103 1832 124 117 127 110 1127 3159 2214 1190 2539 1201 119 102 1111 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.987072 140552650831616 tf_logging.py:115] input_ids: 101 1130 2413 1372 1104 1142 1425 113 121 118 1489 1201 114 1261 1593 1178 170 122 120 128 1104 170 3481 117 1105 1103 1514 1700 1108 1549 1106 2243 118 4079 1372 1134 1108 1300 1551 2610 1190 1685 118 4079 1141 119 1130 14466 1234 1104 1405 118 4589 1201 1127 2567 117 1593 1176 1685 12429 117 1133 1750 103 125 1679 18748 119 1573 117 1103 1832 124 117 127 110 1127 3159 2214 1190 2539 1201 119 102 1111 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.989053 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.991138 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.993309 140552650831616 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:13.995661 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:14.003894 140552650831616 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] Others – decreasing movement . Leader , N . Africa , and country with lowest numbers of unemployed p ##eo ##p ##l , S . Asia , were at the same position [MASK] this period . [SEP] for [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:14.006021 140552650831616 tf_logging.py:115] tokens: [CLS] Others – decreasing movement . Leader , N . Africa , and country with lowest numbers of unemployed p ##eo ##p ##l , S . Asia , were at the same position [MASK] this period . [SEP] for [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 8452 782 18326 2230 119 7308 117 151 119 2201 117 1105 1583 1114 6905 2849 1104 21424 185 8209 1643 1233 117 156 119 3165 117 1127 1120 1103 1269 1700 103 1142 1669 119 102 1111 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:14.008482 140552650831616 tf_logging.py:115] input_ids: 101 8452 782 18326 2230 119 7308 117 151 119 2201 117 1105 1583 1114 6905 2849 1104 21424 185 8209 1643 1233 117 156 119 3165 117 1127 1120 1103 1269 1700 103 1142 1669 119 102 1111 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:14.010421 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:14.012402 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:14.014558 140552650831616 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 54054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:23.825080 140552650831616 tf_logging.py:115] Writing example 10000 of 54054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 20000 of 54054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:33.765534 140552650831616 tf_logging.py:115] Writing example 20000 of 54054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 30000 of 54054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:43.538981 140552650831616 tf_logging.py:115] Writing example 30000 of 54054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 40000 of 54054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:55:52.952299 140552650831616 tf_logging.py:115] Writing example 40000 of 54054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 50000 of 54054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:02.876031 140552650831616 tf_logging.py:115] Writing example 50000 of 54054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 13514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.108623 140552650831616 tf_logging.py:115] Writing example 0 of 13514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.113307 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.114876 140552650831616 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] Nowadays there are many scandal ##s in sport about illegal drug usage by at ##hh ##ete ##s . Some people are willing to solve this problem by prohibition [MASK] at ##hl ##ets to compete for some time while others do not tend to excuse such f ##roa ##d and the want these at ##hl ##ets to be banned from official sport competitions forever . On one hand , the main aim of actions taken towards the person who broke the law should be complete understanding by this person of his or her mistake . [SEP] for [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.116670 140552650831616 tf_logging.py:115] tokens: [CLS] Nowadays there are many scandal ##s in sport about illegal drug usage by at ##hh ##ete ##s . Some people are willing to solve this problem by prohibition [MASK] at ##hl ##ets to compete for some time while others do not tend to excuse such f ##roa ##d and the want these at ##hl ##ets to be banned from official sport competitions forever . On one hand , the main aim of actions taken towards the person who broke the law should be complete understanding by this person of his or her mistake . [SEP] for [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 25883 1175 1132 1242 10083 1116 1107 4799 1164 5696 3850 7991 1118 1120 23830 16618 1116 119 1789 1234 1132 4988 1106 9474 1142 2463 1118 19113 103 1120 8495 6248 1106 4845 1111 1199 1159 1229 1639 1202 1136 6613 1106 9107 1216 175 27380 1181 1105 1103 1328 1292 1120 8495 6248 1106 1129 7548 1121 2078 4799 6025 5221 119 1212 1141 1289 117 1103 1514 6457 1104 3721 1678 2019 1103 1825 1150 2795 1103 1644 1431 1129 2335 4287 1118 1142 1825 1104 1117 1137 1123 6223 119 102 1111 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.118131 140552650831616 tf_logging.py:115] input_ids: 101 25883 1175 1132 1242 10083 1116 1107 4799 1164 5696 3850 7991 1118 1120 23830 16618 1116 119 1789 1234 1132 4988 1106 9474 1142 2463 1118 19113 103 1120 8495 6248 1106 4845 1111 1199 1159 1229 1639 1202 1136 6613 1106 9107 1216 175 27380 1181 1105 1103 1328 1292 1120 8495 6248 1106 1129 7548 1121 2078 4799 6025 5221 119 1212 1141 1289 117 1103 1514 6457 1104 3721 1678 2019 1103 1825 1150 2795 1103 1644 1431 1129 2335 4287 1118 1142 1825 1104 1117 1137 1123 6223 119 102 1111 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.119615 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.121309 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.122996 140552650831616 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.126341 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.129013 140552650831616 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] It won ' t also inform us about something that we didn ' t know before . So , because of this , I think that people can do something more useful for them in [MASK] [MASK] at ##ching sport . Moreover , there are some sport fans who too keen on th ##air favour ##it team and it can lead to having an arguments with fans of another team . [SEP] instead [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.130620 140552650831616 tf_logging.py:115] tokens: [CLS] It won ' t also inform us about something that we didn ' t know before . So , because of this , I think that people can do something more useful for them in [MASK] [MASK] at ##ching sport . Moreover , there are some sport fans who too keen on th ##air favour ##it team and it can lead to having an arguments with fans of another team . [SEP] instead [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1135 1281 112 189 1145 12862 1366 1164 1380 1115 1195 1238 112 189 1221 1196 119 1573 117 1272 1104 1142 117 146 1341 1115 1234 1169 1202 1380 1167 5616 1111 1172 1107 103 103 1120 7520 4799 119 9841 117 1175 1132 1199 4799 3899 1150 1315 11367 1113 24438 8341 7511 2875 1264 1105 1122 1169 1730 1106 1515 1126 9989 1114 3899 1104 1330 1264 119 102 1939 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.132361 140552650831616 tf_logging.py:115] input_ids: 101 1135 1281 112 189 1145 12862 1366 1164 1380 1115 1195 1238 112 189 1221 1196 119 1573 117 1272 1104 1142 117 146 1341 1115 1234 1169 1202 1380 1167 5616 1111 1172 1107 103 103 1120 7520 4799 119 9841 117 1175 1132 1199 4799 3899 1150 1315 11367 1113 24438 8341 7511 2875 1264 1105 1122 1169 1730 1106 1515 1126 9989 1114 3899 1104 1330 1264 119 102 1939 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.134109 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.135679 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.137197 140552650831616 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.140689 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.142175 140552650831616 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] It ' s million dollars and many time . So if you ban ##n professional athletic [MASK] competition for all him life , you can destroy state Second ##ly , people who ate drugs can say that it was the biggest error in their life and they won ##t take drugs . So if sports ##men w ##han ##t begin their life without drugs we can help them . [SEP] in [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.143731 140552650831616 tf_logging.py:115] tokens: [CLS] It ' s million dollars and many time . So if you ban ##n professional athletic [MASK] competition for all him life , you can destroy state Second ##ly , people who ate drugs can say that it was the biggest error in their life and they won ##t take drugs . So if sports ##men w ##han ##t begin their life without drugs we can help them . [SEP] in [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1135 112 188 1550 5860 1105 1242 1159 119 1573 1191 1128 8214 1179 1848 8470 103 2208 1111 1155 1140 1297 117 1128 1169 5535 1352 2307 1193 117 1234 1150 8756 5557 1169 1474 1115 1122 1108 1103 4583 7353 1107 1147 1297 1105 1152 1281 1204 1321 5557 119 1573 1191 2865 2354 192 3822 1204 3295 1147 1297 1443 5557 1195 1169 1494 1172 119 102 1107 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.145437 140552650831616 tf_logging.py:115] input_ids: 101 1135 112 188 1550 5860 1105 1242 1159 119 1573 1191 1128 8214 1179 1848 8470 103 2208 1111 1155 1140 1297 117 1128 1169 5535 1352 2307 1193 117 1234 1150 8756 5557 1169 1474 1115 1122 1108 1103 4583 7353 1107 1147 1297 1105 1152 1281 1204 1321 5557 119 1573 1191 2865 2354 192 3822 1204 3295 1147 1297 1443 5557 1195 1169 1494 1172 119 102 1107 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.146811 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.148250 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.149531 140552650831616 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.152146 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.153511 140552650831616 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] Nowadays there are a lot of discussions about the problems wit student ’ s behaviour in schools . I an going to express my own opinion in this issue by thinking about the causes of these problems and suggesting so ##ll ##ution ##s [MASK] it . As far as I am concerned , problems with student behaviour appear when they do not have enough control . [SEP] of [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.154752 140552650831616 tf_logging.py:115] tokens: [CLS] Nowadays there are a lot of discussions about the problems wit student ’ s behaviour in schools . I an going to express my own opinion in this issue by thinking about the causes of these problems and suggesting so ##ll ##ution ##s [MASK] it . As far as I am concerned , problems with student behaviour appear when they do not have enough control . [SEP] of [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 25883 1175 1132 170 1974 1104 10508 1164 1103 2645 20787 2377 787 188 9151 1107 2126 119 146 1126 1280 1106 6848 1139 1319 4893 1107 1142 2486 1118 2422 1164 1103 4680 1104 1292 2645 1105 8783 1177 2339 12964 1116 103 1122 119 1249 1677 1112 146 1821 4264 117 2645 1114 2377 9151 2845 1165 1152 1202 1136 1138 1536 1654 119 102 1104 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.156295 140552650831616 tf_logging.py:115] input_ids: 101 25883 1175 1132 170 1974 1104 10508 1164 1103 2645 20787 2377 787 188 9151 1107 2126 119 146 1126 1280 1106 6848 1139 1319 4893 1107 1142 2486 1118 2422 1164 1103 4680 1104 1292 2645 1105 8783 1177 2339 12964 1116 103 1122 119 1249 1677 1112 146 1821 4264 117 2645 1114 2377 9151 2845 1165 1152 1202 1136 1138 1536 1654 119 102 1104 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.157565 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.158867 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.160258 140552650831616 tf_logging.py:115] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.162378 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.163808 140552650831616 tf_logging.py:115] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] It meant , that technologies makes humans add ##icted by them . It would grow in psychological problems and [MASK] need the doctor ’ s he ##lo ##ing . Second problem is wasting our planet . [SEP] will [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.165000 140552650831616 tf_logging.py:115] tokens: [CLS] It meant , that technologies makes humans add ##icted by them . It would grow in psychological problems and [MASK] need the doctor ’ s he ##lo ##ing . Second problem is wasting our planet . [SEP] will [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1135 2318 117 1115 7951 2228 3612 5194 27825 1118 1172 119 1135 1156 4328 1107 9189 2645 1105 103 1444 1103 3995 787 188 1119 2858 1158 119 2307 2463 1110 20930 1412 5015 119 102 1209 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.167464 140552650831616 tf_logging.py:115] input_ids: 101 1135 2318 117 1115 7951 2228 3612 5194 27825 1118 1172 119 1135 1156 4328 1107 9189 2645 1105 103 1444 1103 3995 787 188 1119 2858 1158 119 2307 2463 1110 20930 1412 5015 119 102 1209 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.169388 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.171310 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:07.173235 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 13514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:17.643501 140552650831616 tf_logging.py:115] Writing example 10000 of 13514\n"
     ]
    }
   ],
   "source": [
    "# We'll set sequences to be at most 128 tokens long.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ccp5trMwRtmr"
   },
   "source": [
    "#Creating a model\n",
    "\n",
    "Now that we've prepared our data, let's focus on building a model. `create_model` does just this below. First, it loads the BERT tf hub module again (this time to extract the computation graph). Next, it creates a single new layer that will be trained to adapt BERT to our sentiment task (i.e. classifying whether a movie review is positive or negative). This strategy of using a mostly trained model is called [fine-tuning](http://wiki.fast.ai/index.php/Fine_tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "6o2a5ZIvRcJq"
   },
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "  bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "  # Use \"sequence_outputs\" for token-level output.\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  # Create our own layer to tune for politeness data.\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qpE0ZIDOCQzE"
   },
   "source": [
    "Next we'll wrap our model function in a `model_fn_builder` function that adapts our model to work for training, evaluation, and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "FnH-AnOQ9KKW"
   },
   "outputs": [],
   "source": [
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        f1_score = tf.contrib.metrics.f1_score(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        auc = tf.metrics.auc(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        recall = tf.metrics.recall(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        precision = tf.metrics.precision(\n",
    "            label_ids,\n",
    "            predicted_labels) \n",
    "        true_pos = tf.metrics.true_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        true_neg = tf.metrics.true_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)   \n",
    "        false_pos = tf.metrics.false_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)  \n",
    "        false_neg = tf.metrics.false_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            \"f1_score\": f1_score,\n",
    "            \"auc\": auc,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"true_positives\": true_pos,\n",
    "            \"true_negatives\": true_neg,\n",
    "            \"false_positives\": false_pos,\n",
    "            \"false_negatives\": false_neg\n",
    "        }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "OjwJ4bTeWXD8"
   },
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 12.0\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "emHf9GhfWBZ_",
    "outputId": "70b58133-f3fa-4185-eb19-098b708bb203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40540\n"
     ]
    }
   ],
   "source": [
    "# Compute # train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS) * 2\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "print(num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "oEJldMr3WYZa"
   },
   "outputs": [],
   "source": [
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "q_WebpS1X97v",
    "outputId": "389bf349-9c1a-40ec-e342-e0f853f9774a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': 500, '_global_id_in_cluster': 0, '_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_service': None, '_evaluation_master': '', '_save_checkpoints_secs': None, '_eval_distribute': None, '_experimental_distribute': None, '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd45d6ae278>, '_num_worker_replicas': 1, '_protocol': None, '_keep_checkpoint_max': 5, '_is_chief': True, '_task_id': 0, '_num_ps_replicas': 0, '_model_dir': 'bert_new_prepositions', '_tf_random_seed': None, '_train_distribute': None, '_master': '', '_device_fn': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:56:35.578891 140552650831616 tf_logging.py:115] Using config: {'_save_checkpoints_steps': 500, '_global_id_in_cluster': 0, '_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_service': None, '_evaluation_master': '', '_save_checkpoints_secs': None, '_eval_distribute': None, '_experimental_distribute': None, '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd45d6ae278>, '_num_worker_replicas': 1, '_protocol': None, '_keep_checkpoint_max': 5, '_is_chief': True, '_task_id': 0, '_num_ps_replicas': 0, '_model_dir': 'bert_new_prepositions', '_tf_random_seed': None, '_train_distribute': None, '_master': '', '_device_fn': None}\n"
     ]
    }
   ],
   "source": [
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOO3RfG1DYLo"
   },
   "source": [
    "Next we create an input builder function that takes our training feature set (`train_features`) and produces a generator. This is a pretty standard design pattern for working with Tensorflow [Estimators](https://www.tensorflow.org/guide/estimators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1Pv2bAlOX_-K"
   },
   "outputs": [],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "colab_type": "code",
    "id": "nucD4gluYJmK",
    "outputId": "c65caf34-3810-4290-b43e-8007a424dbf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:20:57.239850 139883003524864 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:21:00.934807 139883003524864 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n",
      "/home/ivantorubarov/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:21:10.595345 139883003524864 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:21:10.598531 139883003524864 tf_logging.py:115] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:21:15.393337 139883003524864 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:21:22.623032 139883003524864 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:21:22.863699 139883003524864 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:21:47.849144 139883003524864 tf_logging.py:115] Saving checkpoints for 0 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.67568594, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:21:59.595597 139883003524864 tf_logging.py:115] loss = 0.67568594, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.77123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:22:56.052696 139883003524864 tf_logging.py:115] global_step/sec: 1.77123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.29941565, step = 100 (56.459 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:22:56.054631 139883003524864 tf_logging.py:115] loss = 0.29941565, step = 100 (56.459 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:23:33.430201 139883003524864 tf_logging.py:115] global_step/sec: 2.6754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.21219996, step = 200 (37.378 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:23:33.432352 139883003524864 tf_logging.py:115] loss = 0.21219996, step = 200 (37.378 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:24:10.913550 139883003524864 tf_logging.py:115] global_step/sec: 2.66785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.13956213, step = 300 (37.483 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:24:10.915838 139883003524864 tf_logging.py:115] loss = 0.13956213, step = 300 (37.483 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:24:48.271508 139883003524864 tf_logging.py:115] global_step/sec: 2.67681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.15898138, step = 400 (37.358 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:24:48.273722 139883003524864 tf_logging.py:115] loss = 0.15898138, step = 400 (37.358 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:25:25.279060 139883003524864 tf_logging.py:115] Saving checkpoints for 500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.47133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:25:28.735607 139883003524864 tf_logging.py:115] global_step/sec: 2.47133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3485068, step = 500 (40.464 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:25:28.737534 139883003524864 tf_logging.py:115] loss = 0.3485068, step = 500 (40.464 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:26:06.139993 139883003524864 tf_logging.py:115] global_step/sec: 2.67349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.24207345, step = 600 (37.405 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:26:06.142111 139883003524864 tf_logging.py:115] loss = 0.24207345, step = 600 (37.405 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:26:43.520195 139883003524864 tf_logging.py:115] global_step/sec: 2.67521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.09010193, step = 700 (37.380 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:26:43.522574 139883003524864 tf_logging.py:115] loss = 0.09010193, step = 700 (37.380 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:27:20.963552 139883003524864 tf_logging.py:115] global_step/sec: 2.6707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2654448, step = 800 (37.443 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:27:20.965686 139883003524864 tf_logging.py:115] loss = 0.2654448, step = 800 (37.443 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:27:58.239754 139883003524864 tf_logging.py:115] global_step/sec: 2.68268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2757919, step = 900 (37.277 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:27:58.242257 139883003524864 tf_logging.py:115] loss = 0.2757919, step = 900 (37.277 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:28:35.351368 139883003524864 tf_logging.py:115] Saving checkpoints for 1000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:28:39.018184 139883003524864 tf_logging.py:115] global_step/sec: 2.45228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.011269655, step = 1000 (40.778 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:28:39.020619 139883003524864 tf_logging.py:115] loss = 0.011269655, step = 1000 (40.778 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:29:16.376665 139883003524864 tf_logging.py:115] global_step/sec: 2.67677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.010886079, step = 1100 (37.358 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:29:16.378500 139883003524864 tf_logging.py:115] loss = 0.010886079, step = 1100 (37.358 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:29:53.732451 139883003524864 tf_logging.py:115] global_step/sec: 2.67697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.018133031, step = 1200 (37.357 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:29:53.735259 139883003524864 tf_logging.py:115] loss = 0.018133031, step = 1200 (37.357 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:30:31.099337 139883003524864 tf_logging.py:115] global_step/sec: 2.67616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.20896824, step = 1300 (37.366 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:30:31.101369 139883003524864 tf_logging.py:115] loss = 0.20896824, step = 1300 (37.366 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:31:08.547014 139883003524864 tf_logging.py:115] global_step/sec: 2.67039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04984522, step = 1400 (37.447 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:31:08.548867 139883003524864 tf_logging.py:115] loss = 0.04984522, step = 1400 (37.447 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:31:45.629630 139883003524864 tf_logging.py:115] Saving checkpoints for 1500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:31:49.255107 139883003524864 tf_logging.py:115] global_step/sec: 2.45652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.008110679, step = 1500 (40.709 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:31:49.257552 139883003524864 tf_logging.py:115] loss = 0.008110679, step = 1500 (40.709 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:32:26.543786 139883003524864 tf_logging.py:115] global_step/sec: 2.68178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.083670594, step = 1600 (37.288 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:32:26.545912 139883003524864 tf_logging.py:115] loss = 0.083670594, step = 1600 (37.288 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:33:03.866811 139883003524864 tf_logging.py:115] global_step/sec: 2.67931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.37795335, step = 1700 (37.323 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:33:03.868977 139883003524864 tf_logging.py:115] loss = 0.37795335, step = 1700 (37.323 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:33:41.196935 139883003524864 tf_logging.py:115] global_step/sec: 2.6788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.107004926, step = 1800 (37.330 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:33:41.199190 139883003524864 tf_logging.py:115] loss = 0.107004926, step = 1800 (37.330 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:34:18.436256 139883003524864 tf_logging.py:115] global_step/sec: 2.68533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.113132454, step = 1900 (37.240 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:34:18.439033 139883003524864 tf_logging.py:115] loss = 0.113132454, step = 1900 (37.240 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:34:55.361658 139883003524864 tf_logging.py:115] Saving checkpoints for 2000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:34:59.007770 139883003524864 tf_logging.py:115] global_step/sec: 2.46478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.10193525, step = 2000 (40.571 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:34:59.010200 139883003524864 tf_logging.py:115] loss = 0.10193525, step = 2000 (40.571 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:35:36.410944 139883003524864 tf_logging.py:115] global_step/sec: 2.67357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.12804751, step = 2100 (37.403 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:35:36.412971 139883003524864 tf_logging.py:115] loss = 0.12804751, step = 2100 (37.403 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:36:13.797072 139883003524864 tf_logging.py:115] global_step/sec: 2.67479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.14717242, step = 2200 (37.386 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:36:13.799174 139883003524864 tf_logging.py:115] loss = 0.14717242, step = 2200 (37.386 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:36:51.157761 139883003524864 tf_logging.py:115] global_step/sec: 2.67661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.12213455, step = 2300 (37.361 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:36:51.159760 139883003524864 tf_logging.py:115] loss = 0.12213455, step = 2300 (37.361 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:37:28.524916 139883003524864 tf_logging.py:115] global_step/sec: 2.67615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.35185918, step = 2400 (37.368 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:37:28.527277 139883003524864 tf_logging.py:115] loss = 0.35185918, step = 2400 (37.368 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:38:05.533281 139883003524864 tf_logging.py:115] Saving checkpoints for 2500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:38:09.229677 139883003524864 tf_logging.py:115] global_step/sec: 2.45671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.08913372, step = 2500 (40.704 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:38:09.231602 139883003524864 tf_logging.py:115] loss = 0.08913372, step = 2500 (40.704 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:38:46.601452 139883003524864 tf_logging.py:115] global_step/sec: 2.67581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0015291014, step = 2600 (37.372 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:38:46.603424 139883003524864 tf_logging.py:115] loss = 0.0015291014, step = 2600 (37.372 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:39:23.973917 139883003524864 tf_logging.py:115] global_step/sec: 2.67577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0021016658, step = 2700 (37.373 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:39:23.976105 139883003524864 tf_logging.py:115] loss = 0.0021016658, step = 2700 (37.373 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:40:01.337904 139883003524864 tf_logging.py:115] global_step/sec: 2.67638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.027505545, step = 2800 (37.365 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:40:01.341047 139883003524864 tf_logging.py:115] loss = 0.027505545, step = 2800 (37.365 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:40:38.705911 139883003524864 tf_logging.py:115] global_step/sec: 2.67609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.18077461, step = 2900 (37.367 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:40:38.708162 139883003524864 tf_logging.py:115] loss = 0.18077461, step = 2900 (37.367 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 3000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:41:15.688643 139883003524864 tf_logging.py:115] Saving checkpoints for 3000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:41:19.399762 139883003524864 tf_logging.py:115] global_step/sec: 2.45737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.008112177, step = 3000 (40.694 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:41:19.401702 139883003524864 tf_logging.py:115] loss = 0.008112177, step = 3000 (40.694 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:41:56.787436 139883003524864 tf_logging.py:115] global_step/sec: 2.67468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0011591688, step = 3100 (37.388 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:41:56.789674 139883003524864 tf_logging.py:115] loss = 0.0011591688, step = 3100 (37.388 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:42:34.121237 139883003524864 tf_logging.py:115] global_step/sec: 2.67853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.018478537, step = 3200 (37.334 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:42:34.123425 139883003524864 tf_logging.py:115] loss = 0.018478537, step = 3200 (37.334 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:43:11.605822 139883003524864 tf_logging.py:115] global_step/sec: 2.66776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.16853738, step = 3300 (37.484 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:43:11.607804 139883003524864 tf_logging.py:115] loss = 0.16853738, step = 3300 (37.484 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:43:48.989756 139883003524864 tf_logging.py:115] global_step/sec: 2.67495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.15718918, step = 3400 (37.384 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:43:48.992194 139883003524864 tf_logging.py:115] loss = 0.15718918, step = 3400 (37.384 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 3500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:44:26.089533 139883003524864 tf_logging.py:115] Saving checkpoints for 3500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:44:29.893350 139883003524864 tf_logging.py:115] global_step/sec: 2.44477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.08196017, step = 3500 (40.904 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:44:29.895725 139883003524864 tf_logging.py:115] loss = 0.08196017, step = 3500 (40.904 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:45:07.353652 139883003524864 tf_logging.py:115] global_step/sec: 2.66949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.22051427, step = 3600 (37.460 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:45:07.355936 139883003524864 tf_logging.py:115] loss = 0.22051427, step = 3600 (37.460 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:45:44.688245 139883003524864 tf_logging.py:115] global_step/sec: 2.67848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.26395246, step = 3700 (37.335 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:45:44.690758 139883003524864 tf_logging.py:115] loss = 0.26395246, step = 3700 (37.335 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:46:21.993254 139883003524864 tf_logging.py:115] global_step/sec: 2.68061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.041715033, step = 3800 (37.305 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:46:21.995826 139883003524864 tf_logging.py:115] loss = 0.041715033, step = 3800 (37.305 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:46:59.283091 139883003524864 tf_logging.py:115] global_step/sec: 2.6817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2911805, step = 3900 (37.290 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:46:59.285536 139883003524864 tf_logging.py:115] loss = 0.2911805, step = 3900 (37.290 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:47:36.294245 139883003524864 tf_logging.py:115] Saving checkpoints for 4000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:47:40.089533 139883003524864 tf_logging.py:115] global_step/sec: 2.45059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.27390453, step = 4000 (40.806 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:47:40.091605 139883003524864 tf_logging.py:115] loss = 0.27390453, step = 4000 (40.806 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:48:17.521365 139883003524864 tf_logging.py:115] global_step/sec: 2.67152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.010972985, step = 4100 (37.432 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:48:17.523238 139883003524864 tf_logging.py:115] loss = 0.010972985, step = 4100 (37.432 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:48:54.940355 139883003524864 tf_logging.py:115] global_step/sec: 2.67244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.015817864, step = 4200 (37.419 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:48:54.942497 139883003524864 tf_logging.py:115] loss = 0.015817864, step = 4200 (37.419 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:49:32.356095 139883003524864 tf_logging.py:115] global_step/sec: 2.67267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00050562626, step = 4300 (37.416 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:49:32.358329 139883003524864 tf_logging.py:115] loss = 0.00050562626, step = 4300 (37.416 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:50:09.679946 139883003524864 tf_logging.py:115] global_step/sec: 2.67925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0014394191, step = 4400 (37.324 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:50:09.682273 139883003524864 tf_logging.py:115] loss = 0.0014394191, step = 4400 (37.324 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:50:46.677291 139883003524864 tf_logging.py:115] Saving checkpoints for 4500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:50:50.522826 139883003524864 tf_logging.py:115] global_step/sec: 2.44841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.028850805, step = 4500 (40.843 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:50:50.525104 139883003524864 tf_logging.py:115] loss = 0.028850805, step = 4500 (40.843 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:51:27.874818 139883003524864 tf_logging.py:115] global_step/sec: 2.67723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0011297225, step = 4600 (37.352 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:51:27.876673 139883003524864 tf_logging.py:115] loss = 0.0011297225, step = 4600 (37.352 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:52:05.200114 139883003524864 tf_logging.py:115] global_step/sec: 2.67915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0004612513, step = 4700 (37.326 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:52:05.202740 139883003524864 tf_logging.py:115] loss = 0.0004612513, step = 4700 (37.326 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:52:42.554538 139883003524864 tf_logging.py:115] global_step/sec: 2.67706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00036212514, step = 4800 (37.354 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:52:42.556532 139883003524864 tf_logging.py:115] loss = 0.00036212514, step = 4800 (37.354 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:53:19.962045 139883003524864 tf_logging.py:115] global_step/sec: 2.67326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0074883294, step = 4900 (37.408 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:53:19.964432 139883003524864 tf_logging.py:115] loss = 0.0074883294, step = 4900 (37.408 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 5000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:53:56.980444 139883003524864 tf_logging.py:115] Saving checkpoints for 5000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:54:00.818271 139883003524864 tf_logging.py:115] global_step/sec: 2.44761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04338872, step = 5000 (40.856 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:54:00.820438 139883003524864 tf_logging.py:115] loss = 0.04338872, step = 5000 (40.856 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:54:38.213784 139883003524864 tf_logging.py:115] global_step/sec: 2.67412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0119202165, step = 5100 (37.395 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:54:38.215777 139883003524864 tf_logging.py:115] loss = 0.0119202165, step = 5100 (37.395 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:55:15.632648 139883003524864 tf_logging.py:115] global_step/sec: 2.67245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.049884655, step = 5200 (37.419 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:55:15.635108 139883003524864 tf_logging.py:115] loss = 0.049884655, step = 5200 (37.419 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:55:53.014162 139883003524864 tf_logging.py:115] global_step/sec: 2.67512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.02618958, step = 5300 (37.381 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:55:53.016573 139883003524864 tf_logging.py:115] loss = 0.02618958, step = 5300 (37.381 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:56:30.304986 139883003524864 tf_logging.py:115] global_step/sec: 2.68162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0073449183, step = 5400 (37.290 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:56:30.307042 139883003524864 tf_logging.py:115] loss = 0.0073449183, step = 5400 (37.290 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 5500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:57:07.327127 139883003524864 tf_logging.py:115] Saving checkpoints for 5500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:57:11.051922 139883003524864 tf_logging.py:115] global_step/sec: 2.45417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0068985373, step = 5500 (40.747 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:57:11.053858 139883003524864 tf_logging.py:115] loss = 0.0068985373, step = 5500 (40.747 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:57:48.451847 139883003524864 tf_logging.py:115] global_step/sec: 2.67381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.007872553, step = 5600 (37.401 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:57:48.454554 139883003524864 tf_logging.py:115] loss = 0.007872553, step = 5600 (37.401 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:58:25.758682 139883003524864 tf_logging.py:115] global_step/sec: 2.68047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.003915505, step = 5700 (37.307 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:58:25.761256 139883003524864 tf_logging.py:115] loss = 0.003915505, step = 5700 (37.307 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:59:03.060777 139883003524864 tf_logging.py:115] global_step/sec: 2.68082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.26217026, step = 5800 (37.301 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:59:03.062669 139883003524864 tf_logging.py:115] loss = 0.26217026, step = 5800 (37.301 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:59:40.349381 139883003524864 tf_logging.py:115] global_step/sec: 2.68178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.118021704, step = 5900 (37.289 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 22:59:40.351438 139883003524864 tf_logging.py:115] loss = 0.118021704, step = 5900 (37.289 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 6000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:00:17.301723 139883003524864 tf_logging.py:115] Saving checkpoints for 6000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.47219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:00:20.799322 139883003524864 tf_logging.py:115] global_step/sec: 2.47219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0011801902, step = 6000 (40.450 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:00:20.801627 139883003524864 tf_logging.py:115] loss = 0.0011801902, step = 6000 (40.450 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:00:58.164808 139883003524864 tf_logging.py:115] global_step/sec: 2.67626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00028981734, step = 6100 (37.365 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:00:58.166936 139883003524864 tf_logging.py:115] loss = 0.00028981734, step = 6100 (37.365 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:01:35.497065 139883003524864 tf_logging.py:115] global_step/sec: 2.67865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0003285855, step = 6200 (37.332 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:01:35.498940 139883003524864 tf_logging.py:115] loss = 0.0003285855, step = 6200 (37.332 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:02:12.802970 139883003524864 tf_logging.py:115] global_step/sec: 2.68054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00047054878, step = 6300 (37.307 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:02:12.805716 139883003524864 tf_logging.py:115] loss = 0.00047054878, step = 6300 (37.307 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:02:50.111153 139883003524864 tf_logging.py:115] global_step/sec: 2.68037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00024931197, step = 6400 (37.307 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:02:50.113049 139883003524864 tf_logging.py:115] loss = 0.00024931197, step = 6400 (37.307 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 6500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:03:27.016606 139883003524864 tf_logging.py:115] Saving checkpoints for 6500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:03:30.818651 139883003524864 tf_logging.py:115] global_step/sec: 2.45655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.000103868355, step = 6500 (40.707 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:03:30.820488 139883003524864 tf_logging.py:115] loss = 0.000103868355, step = 6500 (40.707 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:04:08.198582 139883003524864 tf_logging.py:115] global_step/sec: 2.67524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.013665069, step = 6600 (37.381 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:04:08.201140 139883003524864 tf_logging.py:115] loss = 0.013665069, step = 6600 (37.381 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:04:45.483120 139883003524864 tf_logging.py:115] global_step/sec: 2.68207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.001845356, step = 6700 (37.284 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:04:45.485384 139883003524864 tf_logging.py:115] loss = 0.001845356, step = 6700 (37.284 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:05:22.825723 139883003524864 tf_logging.py:115] global_step/sec: 2.67791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.14024043, step = 6800 (37.343 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:05:22.828031 139883003524864 tf_logging.py:115] loss = 0.14024043, step = 6800 (37.343 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:06:00.234070 139883003524864 tf_logging.py:115] global_step/sec: 2.67321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00080827356, step = 6900 (37.408 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:06:00.236380 139883003524864 tf_logging.py:115] loss = 0.00080827356, step = 6900 (37.408 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 7000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:06:37.176282 139883003524864 tf_logging.py:115] Saving checkpoints for 7000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:06:41.030892 139883003524864 tf_logging.py:115] global_step/sec: 2.45117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0016380062, step = 7000 (40.796 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:06:41.032873 139883003524864 tf_logging.py:115] loss = 0.0016380062, step = 7000 (40.796 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:07:18.366208 139883003524864 tf_logging.py:115] global_step/sec: 2.67843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0019232295, step = 7100 (37.335 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:07:18.368251 139883003524864 tf_logging.py:115] loss = 0.0019232295, step = 7100 (37.335 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:07:55.772100 139883003524864 tf_logging.py:115] global_step/sec: 2.67338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.060731623, step = 7200 (37.406 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:07:55.774188 139883003524864 tf_logging.py:115] loss = 0.060731623, step = 7200 (37.406 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:08:33.034225 139883003524864 tf_logging.py:115] global_step/sec: 2.68369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0012462777, step = 7300 (37.262 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:08:33.036314 139883003524864 tf_logging.py:115] loss = 0.0012462777, step = 7300 (37.262 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:09:10.428283 139883003524864 tf_logging.py:115] global_step/sec: 2.67422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.001798603, step = 7400 (37.394 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:09:10.430253 139883003524864 tf_logging.py:115] loss = 0.001798603, step = 7400 (37.394 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 7500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:09:47.383372 139883003524864 tf_logging.py:115] Saving checkpoints for 7500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:09:51.082718 139883003524864 tf_logging.py:115] global_step/sec: 2.45976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0034534344, step = 7500 (40.655 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:09:51.084987 139883003524864 tf_logging.py:115] loss = 0.0034534344, step = 7500 (40.655 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:10:28.437399 139883003524864 tf_logging.py:115] global_step/sec: 2.67704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.055879086, step = 7600 (37.354 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:10:28.439419 139883003524864 tf_logging.py:115] loss = 0.055879086, step = 7600 (37.354 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:11:05.762498 139883003524864 tf_logging.py:115] global_step/sec: 2.67916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0002523132, step = 7700 (37.326 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:11:05.764924 139883003524864 tf_logging.py:115] loss = 0.0002523132, step = 7700 (37.326 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:11:43.032046 139883003524864 tf_logging.py:115] global_step/sec: 2.68315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00042671617, step = 7800 (37.269 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:11:43.033953 139883003524864 tf_logging.py:115] loss = 0.00042671617, step = 7800 (37.269 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:12:20.307864 139883003524864 tf_logging.py:115] global_step/sec: 2.68271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00011691061, step = 7900 (37.276 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:12:20.309831 139883003524864 tf_logging.py:115] loss = 0.00011691061, step = 7900 (37.276 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 8000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:12:57.319809 139883003524864 tf_logging.py:115] Saving checkpoints for 8000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:13:01.183228 139883003524864 tf_logging.py:115] global_step/sec: 2.44646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.965337e-05, step = 8000 (40.875 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:13:01.185196 139883003524864 tf_logging.py:115] loss = 7.965337e-05, step = 8000 (40.875 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:13:38.701964 139883003524864 tf_logging.py:115] global_step/sec: 2.66534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00024564675, step = 8100 (37.519 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:13:38.704015 139883003524864 tf_logging.py:115] loss = 0.00024564675, step = 8100 (37.519 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:14:16.054452 139883003524864 tf_logging.py:115] global_step/sec: 2.6772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0010089705, step = 8200 (37.353 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:14:16.056909 139883003524864 tf_logging.py:115] loss = 0.0010089705, step = 8200 (37.353 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:14:53.346917 139883003524864 tf_logging.py:115] global_step/sec: 2.6815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.055828582, step = 8300 (37.292 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:14:53.348939 139883003524864 tf_logging.py:115] loss = 0.055828582, step = 8300 (37.292 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:15:30.619222 139883003524864 tf_logging.py:115] global_step/sec: 2.68296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.012999853, step = 8400 (37.272 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:15:30.621434 139883003524864 tf_logging.py:115] loss = 0.012999853, step = 8400 (37.272 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 8500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:16:07.584260 139883003524864 tf_logging.py:115] Saving checkpoints for 8500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:16:11.448515 139883003524864 tf_logging.py:115] global_step/sec: 2.44922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0020762146, step = 8500 (40.829 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:16:11.450752 139883003524864 tf_logging.py:115] loss = 0.0020762146, step = 8500 (40.829 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:16:48.917900 139883003524864 tf_logging.py:115] global_step/sec: 2.66885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0020491828, step = 8600 (37.469 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:16:48.920273 139883003524864 tf_logging.py:115] loss = 0.0020491828, step = 8600 (37.469 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:17:26.178338 139883003524864 tf_logging.py:115] global_step/sec: 2.6838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.28323066, step = 8700 (37.260 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:17:26.180522 139883003524864 tf_logging.py:115] loss = 0.28323066, step = 8700 (37.260 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:18:03.454133 139883003524864 tf_logging.py:115] global_step/sec: 2.68271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.1007783, step = 8800 (37.276 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:18:03.456209 139883003524864 tf_logging.py:115] loss = 0.1007783, step = 8800 (37.276 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:18:40.864645 139883003524864 tf_logging.py:115] global_step/sec: 2.67305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00085395575, step = 8900 (37.411 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:18:40.867444 139883003524864 tf_logging.py:115] loss = 0.00085395575, step = 8900 (37.411 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 9000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:19:17.854247 139883003524864 tf_logging.py:115] Saving checkpoints for 9000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:19:21.598745 139883003524864 tf_logging.py:115] global_step/sec: 2.45494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0018241403, step = 9000 (40.734 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:19:21.601255 139883003524864 tf_logging.py:115] loss = 0.0018241403, step = 9000 (40.734 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:19:58.982942 139883003524864 tf_logging.py:115] global_step/sec: 2.67493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.001728249, step = 9100 (37.386 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:19:58.987074 139883003524864 tf_logging.py:115] loss = 0.001728249, step = 9100 (37.386 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:20:36.330094 139883003524864 tf_logging.py:115] global_step/sec: 2.67758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.14982502, step = 9200 (37.345 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:20:36.332278 139883003524864 tf_logging.py:115] loss = 0.14982502, step = 9200 (37.345 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:21:13.601127 139883003524864 tf_logging.py:115] global_step/sec: 2.68305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.032487e-05, step = 9300 (37.271 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:21:13.603394 139883003524864 tf_logging.py:115] loss = 6.032487e-05, step = 9300 (37.271 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:21:50.915851 139883003524864 tf_logging.py:115] global_step/sec: 2.67991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00050909544, step = 9400 (37.315 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:21:50.917968 139883003524864 tf_logging.py:115] loss = 0.00050909544, step = 9400 (37.315 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 9500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:22:27.959656 139883003524864 tf_logging.py:115] Saving checkpoints for 9500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:22:31.625370 139883003524864 tf_logging.py:115] global_step/sec: 2.45642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.1908602e-05, step = 9500 (40.710 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:22:31.627967 139883003524864 tf_logging.py:115] loss = 5.1908602e-05, step = 9500 (40.710 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:23:08.968641 139883003524864 tf_logging.py:115] global_step/sec: 2.67786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00010061483, step = 9600 (37.343 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:23:08.970773 139883003524864 tf_logging.py:115] loss = 0.00010061483, step = 9600 (37.343 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:23:46.292574 139883003524864 tf_logging.py:115] global_step/sec: 2.67924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00047470536, step = 9700 (37.324 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:23:46.295121 139883003524864 tf_logging.py:115] loss = 0.00047470536, step = 9700 (37.324 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:24:23.596024 139883003524864 tf_logging.py:115] global_step/sec: 2.68072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.000172986, step = 9800 (37.303 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:24:23.598428 139883003524864 tf_logging.py:115] loss = 0.000172986, step = 9800 (37.303 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:25:00.885567 139883003524864 tf_logging.py:115] global_step/sec: 2.68171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.472812e-05, step = 9900 (37.292 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:25:00.890407 139883003524864 tf_logging.py:115] loss = 2.472812e-05, step = 9900 (37.292 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 10000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:25:37.859289 139883003524864 tf_logging.py:115] Saving checkpoints for 10000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:25:41.670737 139883003524864 tf_logging.py:115] global_step/sec: 2.45188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0010210853, step = 10000 (40.783 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:25:41.673200 139883003524864 tf_logging.py:115] loss = 0.0010210853, step = 10000 (40.783 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:26:19.027132 139883003524864 tf_logging.py:115] global_step/sec: 2.67691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00048652536, step = 10100 (37.356 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:26:19.029342 139883003524864 tf_logging.py:115] loss = 0.00048652536, step = 10100 (37.356 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:26:56.343311 139883003524864 tf_logging.py:115] global_step/sec: 2.6798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.002012899, step = 10200 (37.316 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:26:56.345684 139883003524864 tf_logging.py:115] loss = 0.002012899, step = 10200 (37.316 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:27:33.703900 139883003524864 tf_logging.py:115] global_step/sec: 2.67662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0017078995, step = 10300 (37.360 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:27:33.705904 139883003524864 tf_logging.py:115] loss = 0.0017078995, step = 10300 (37.360 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:28:11.078089 139883003524864 tf_logging.py:115] global_step/sec: 2.67564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00067466876, step = 10400 (37.375 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:28:11.080535 139883003524864 tf_logging.py:115] loss = 0.00067466876, step = 10400 (37.375 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 10500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:28:47.999966 139883003524864 tf_logging.py:115] Saving checkpoints for 10500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:28:51.780428 139883003524864 tf_logging.py:115] global_step/sec: 2.45686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00043239357, step = 10500 (40.702 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:28:51.782545 139883003524864 tf_logging.py:115] loss = 0.00043239357, step = 10500 (40.702 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:29:29.128015 139883003524864 tf_logging.py:115] global_step/sec: 2.67755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.5109376e-05, step = 10600 (37.348 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:29:29.130338 139883003524864 tf_logging.py:115] loss = 7.5109376e-05, step = 10600 (37.348 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:30:06.391429 139883003524864 tf_logging.py:115] global_step/sec: 2.68359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.06513595, step = 10700 (37.264 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:30:06.393950 139883003524864 tf_logging.py:115] loss = 0.06513595, step = 10700 (37.264 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:30:43.779331 139883003524864 tf_logging.py:115] global_step/sec: 2.67466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0011425661, step = 10800 (37.387 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:30:43.781385 139883003524864 tf_logging.py:115] loss = 0.0011425661, step = 10800 (37.387 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:31:21.060591 139883003524864 tf_logging.py:115] global_step/sec: 2.68231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0014161417, step = 10900 (37.281 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:31:21.062616 139883003524864 tf_logging.py:115] loss = 0.0014161417, step = 10900 (37.281 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 11000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:31:57.964186 139883003524864 tf_logging.py:115] Saving checkpoints for 11000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:32:01.758800 139883003524864 tf_logging.py:115] global_step/sec: 2.45711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00029855059, step = 11000 (40.698 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:32:01.761024 139883003524864 tf_logging.py:115] loss = 0.00029855059, step = 11000 (40.698 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:32:39.064811 139883003524864 tf_logging.py:115] global_step/sec: 2.68053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.4752324e-05, step = 11100 (37.306 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:32:39.067092 139883003524864 tf_logging.py:115] loss = 3.4752324e-05, step = 11100 (37.306 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:33:16.462856 139883003524864 tf_logging.py:115] global_step/sec: 2.67394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.9392033e-05, step = 11200 (37.398 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:33:16.464868 139883003524864 tf_logging.py:115] loss = 2.9392033e-05, step = 11200 (37.398 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:33:53.857629 139883003524864 tf_logging.py:115] global_step/sec: 2.67417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.7220216e-05, step = 11300 (37.395 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:33:53.859763 139883003524864 tf_logging.py:115] loss = 2.7220216e-05, step = 11300 (37.395 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:34:31.222520 139883003524864 tf_logging.py:115] global_step/sec: 2.67631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.1960313e-05, step = 11400 (37.365 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:34:31.224475 139883003524864 tf_logging.py:115] loss = 2.1960313e-05, step = 11400 (37.365 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 11500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:35:08.230537 139883003524864 tf_logging.py:115] Saving checkpoints for 11500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:35:11.959472 139883003524864 tf_logging.py:115] global_step/sec: 2.45477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.2662207e-05, step = 11500 (40.737 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:35:11.961638 139883003524864 tf_logging.py:115] loss = 3.2662207e-05, step = 11500 (40.737 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:35:49.265319 139883003524864 tf_logging.py:115] global_step/sec: 2.68055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.18714795, step = 11600 (37.306 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:35:49.267343 139883003524864 tf_logging.py:115] loss = 0.18714795, step = 11600 (37.306 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:36:26.622565 139883003524864 tf_logging.py:115] global_step/sec: 2.67686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0005775011, step = 11700 (37.358 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:36:26.625138 139883003524864 tf_logging.py:115] loss = 0.0005775011, step = 11700 (37.358 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:37:03.876492 139883003524864 tf_logging.py:115] global_step/sec: 2.68428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00055893254, step = 11800 (37.254 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:37:03.879236 139883003524864 tf_logging.py:115] loss = 0.00055893254, step = 11800 (37.254 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:37:41.193103 139883003524864 tf_logging.py:115] global_step/sec: 2.67977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0007509321, step = 11900 (37.316 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:37:41.195285 139883003524864 tf_logging.py:115] loss = 0.0007509321, step = 11900 (37.316 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 12000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:38:18.274577 139883003524864 tf_logging.py:115] Saving checkpoints for 12000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:38:22.072188 139883003524864 tf_logging.py:115] global_step/sec: 2.44624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0015007786, step = 12000 (40.879 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:38:22.074438 139883003524864 tf_logging.py:115] loss = 0.0015007786, step = 12000 (40.879 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:38:59.481118 139883003524864 tf_logging.py:115] global_step/sec: 2.67316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.1154304, step = 12100 (37.409 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:38:59.483758 139883003524864 tf_logging.py:115] loss = 0.1154304, step = 12100 (37.409 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:39:36.787906 139883003524864 tf_logging.py:115] global_step/sec: 2.68048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.19736005, step = 12200 (37.306 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:39:36.790171 139883003524864 tf_logging.py:115] loss = 0.19736005, step = 12200 (37.306 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:40:14.166526 139883003524864 tf_logging.py:115] global_step/sec: 2.67533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00025230105, step = 12300 (37.379 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:40:14.168738 139883003524864 tf_logging.py:115] loss = 0.00025230105, step = 12300 (37.379 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:40:51.620177 139883003524864 tf_logging.py:115] global_step/sec: 2.66996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00028270125, step = 12400 (37.453 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:40:51.622220 139883003524864 tf_logging.py:115] loss = 0.00028270125, step = 12400 (37.453 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 12500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:41:28.515991 139883003524864 tf_logging.py:115] Saving checkpoints for 12500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:41:32.277523 139883003524864 tf_logging.py:115] global_step/sec: 2.45958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00085237157, step = 12500 (40.657 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:41:32.279563 139883003524864 tf_logging.py:115] loss = 0.00085237157, step = 12500 (40.657 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:42:09.689152 139883003524864 tf_logging.py:115] global_step/sec: 2.67297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00019033962, step = 12600 (37.412 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:42:09.691832 139883003524864 tf_logging.py:115] loss = 0.00019033962, step = 12600 (37.412 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:42:47.077386 139883003524864 tf_logging.py:115] global_step/sec: 2.67464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00018353041, step = 12700 (37.387 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:42:47.079305 139883003524864 tf_logging.py:115] loss = 0.00018353041, step = 12700 (37.387 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:43:24.522997 139883003524864 tf_logging.py:115] global_step/sec: 2.67054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.620731e-05, step = 12800 (37.446 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:43:24.524936 139883003524864 tf_logging.py:115] loss = 3.620731e-05, step = 12800 (37.446 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:44:01.939056 139883003524864 tf_logging.py:115] global_step/sec: 2.67265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.0900533e-05, step = 12900 (37.416 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:44:01.941018 139883003524864 tf_logging.py:115] loss = 4.0900533e-05, step = 12900 (37.416 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 13000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:44:38.817636 139883003524864 tf_logging.py:115] Saving checkpoints for 13000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:44:42.578313 139883003524864 tf_logging.py:115] global_step/sec: 2.46067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.510076e-05, step = 13000 (40.639 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:44:42.580365 139883003524864 tf_logging.py:115] loss = 6.510076e-05, step = 13000 (40.639 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:45:19.910631 139883003524864 tf_logging.py:115] global_step/sec: 2.67864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.2783228e-05, step = 13100 (37.333 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:45:19.912922 139883003524864 tf_logging.py:115] loss = 2.2783228e-05, step = 13100 (37.333 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:45:57.252710 139883003524864 tf_logging.py:115] global_step/sec: 2.67795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.72293e-05, step = 13200 (37.342 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:45:57.255108 139883003524864 tf_logging.py:115] loss = 1.72293e-05, step = 13200 (37.342 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:46:34.586941 139883003524864 tf_logging.py:115] global_step/sec: 2.67851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.662338e-05, step = 13300 (37.334 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:46:34.588917 139883003524864 tf_logging.py:115] loss = 2.662338e-05, step = 13300 (37.334 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:47:11.921205 139883003524864 tf_logging.py:115] global_step/sec: 2.6785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0006004806, step = 13400 (37.334 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:47:11.923140 139883003524864 tf_logging.py:115] loss = 0.0006004806, step = 13400 (37.334 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 13500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:47:48.880672 139883003524864 tf_logging.py:115] Saving checkpoints for 13500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:47:52.705814 139883003524864 tf_logging.py:115] global_step/sec: 2.45191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0001163354, step = 13500 (40.785 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:47:52.707964 139883003524864 tf_logging.py:115] loss = 0.0001163354, step = 13500 (40.785 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:48:29.979496 139883003524864 tf_logging.py:115] global_step/sec: 2.68286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00013956722, step = 13600 (37.274 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:48:29.981789 139883003524864 tf_logging.py:115] loss = 0.00013956722, step = 13600 (37.274 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:49:07.292972 139883003524864 tf_logging.py:115] global_step/sec: 2.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00027598234, step = 13700 (37.313 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:49:07.295351 139883003524864 tf_logging.py:115] loss = 0.00027598234, step = 13700 (37.313 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:49:44.606282 139883003524864 tf_logging.py:115] global_step/sec: 2.68001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00031434998, step = 13800 (37.314 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:49:44.609238 139883003524864 tf_logging.py:115] loss = 0.00031434998, step = 13800 (37.314 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:50:21.925709 139883003524864 tf_logging.py:115] global_step/sec: 2.67957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0013316098, step = 13900 (37.319 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:50:21.927841 139883003524864 tf_logging.py:115] loss = 0.0013316098, step = 13900 (37.319 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 14000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:50:58.878691 139883003524864 tf_logging.py:115] Saving checkpoints for 14000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:51:02.638411 139883003524864 tf_logging.py:115] global_step/sec: 2.45624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.07608806, step = 14000 (40.713 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:51:02.640790 139883003524864 tf_logging.py:115] loss = 0.07608806, step = 14000 (40.713 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:51:40.074219 139883003524864 tf_logging.py:115] global_step/sec: 2.67124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00013421575, step = 14100 (37.436 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:51:40.076397 139883003524864 tf_logging.py:115] loss = 0.00013421575, step = 14100 (37.436 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:52:17.407020 139883003524864 tf_logging.py:115] global_step/sec: 2.67861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0001248175, step = 14200 (37.333 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:52:17.409412 139883003524864 tf_logging.py:115] loss = 0.0001248175, step = 14200 (37.333 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:52:54.775527 139883003524864 tf_logging.py:115] global_step/sec: 2.67605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0721951, step = 14300 (37.368 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:52:54.777544 139883003524864 tf_logging.py:115] loss = 0.0721951, step = 14300 (37.368 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:53:32.230151 139883003524864 tf_logging.py:115] global_step/sec: 2.6699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.008213264, step = 14400 (37.454 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:53:32.231976 139883003524864 tf_logging.py:115] loss = 0.008213264, step = 14400 (37.454 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 14500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:54:09.130222 139883003524864 tf_logging.py:115] Saving checkpoints for 14500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:54:12.915991 139883003524864 tf_logging.py:115] global_step/sec: 2.45786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.697588e-05, step = 14500 (40.686 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:54:12.918338 139883003524864 tf_logging.py:115] loss = 1.697588e-05, step = 14500 (40.686 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:54:50.334686 139883003524864 tf_logging.py:115] global_step/sec: 2.67246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4457728e-05, step = 14600 (37.419 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:54:50.337220 139883003524864 tf_logging.py:115] loss = 1.4457728e-05, step = 14600 (37.419 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:55:27.636117 139883003524864 tf_logging.py:115] global_step/sec: 2.68086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.4338133e-05, step = 14700 (37.301 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:55:27.638123 139883003524864 tf_logging.py:115] loss = 3.4338133e-05, step = 14700 (37.301 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:56:05.005923 139883003524864 tf_logging.py:115] global_step/sec: 2.67596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.3567393e-05, step = 14800 (37.370 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:56:05.008063 139883003524864 tf_logging.py:115] loss = 1.3567393e-05, step = 14800 (37.370 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:56:42.353127 139883003524864 tf_logging.py:115] global_step/sec: 2.67758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.1950641e-05, step = 14900 (37.347 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:56:42.355306 139883003524864 tf_logging.py:115] loss = 1.1950641e-05, step = 14900 (37.347 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 15000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:57:19.369372 139883003524864 tf_logging.py:115] Saving checkpoints for 15000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:57:23.127156 139883003524864 tf_logging.py:115] global_step/sec: 2.45254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.6528476e-05, step = 15000 (40.774 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:57:23.129177 139883003524864 tf_logging.py:115] loss = 1.6528476e-05, step = 15000 (40.774 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:58:00.437389 139883003524864 tf_logging.py:115] global_step/sec: 2.68023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.13371891, step = 15100 (37.310 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:58:00.439343 139883003524864 tf_logging.py:115] loss = 0.13371891, step = 15100 (37.310 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:58:37.753237 139883003524864 tf_logging.py:115] global_step/sec: 2.67982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.257115e-05, step = 15200 (37.316 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:58:37.755740 139883003524864 tf_logging.py:115] loss = 3.257115e-05, step = 15200 (37.316 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:59:14.957253 139883003524864 tf_logging.py:115] global_step/sec: 2.68788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.3980872e-05, step = 15300 (37.204 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:59:14.959421 139883003524864 tf_logging.py:115] loss = 3.3980872e-05, step = 15300 (37.204 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:59:52.329288 139883003524864 tf_logging.py:115] global_step/sec: 2.6758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00017330392, step = 15400 (37.372 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0508 23:59:52.331260 139883003524864 tf_logging.py:115] loss = 0.00017330392, step = 15400 (37.372 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 15500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:00:29.311650 139883003524864 tf_logging.py:115] Saving checkpoints for 15500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:00:33.116753 139883003524864 tf_logging.py:115] global_step/sec: 2.45173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.0674768e-05, step = 15500 (40.788 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:00:33.119310 139883003524864 tf_logging.py:115] loss = 4.0674768e-05, step = 15500 (40.788 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:01:10.440331 139883003524864 tf_logging.py:115] global_step/sec: 2.67927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00048508047, step = 15600 (37.323 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:01:10.442235 139883003524864 tf_logging.py:115] loss = 0.00048508047, step = 15600 (37.323 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:01:47.720025 139883003524864 tf_logging.py:115] global_step/sec: 2.68243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.2180455e-05, step = 15700 (37.280 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:01:47.722467 139883003524864 tf_logging.py:115] loss = 3.2180455e-05, step = 15700 (37.280 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:02:25.020379 139883003524864 tf_logging.py:115] global_step/sec: 2.68094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.002233e-05, step = 15800 (37.300 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:02:25.022641 139883003524864 tf_logging.py:115] loss = 2.002233e-05, step = 15800 (37.300 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:03:02.437104 139883003524864 tf_logging.py:115] global_step/sec: 2.6726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0003507375, step = 15900 (37.417 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:03:02.439268 139883003524864 tf_logging.py:115] loss = 0.0003507375, step = 15900 (37.417 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 16000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:03:39.425647 139883003524864 tf_logging.py:115] Saving checkpoints for 16000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:03:43.241891 139883003524864 tf_logging.py:115] global_step/sec: 2.45069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.5195963e-05, step = 16000 (40.805 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:03:43.244364 139883003524864 tf_logging.py:115] loss = 2.5195963e-05, step = 16000 (40.805 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:04:20.649422 139883003524864 tf_logging.py:115] global_step/sec: 2.67326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.9988678e-05, step = 16100 (37.407 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:04:20.651401 139883003524864 tf_logging.py:115] loss = 2.9988678e-05, step = 16100 (37.407 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:04:58.017059 139883003524864 tf_logging.py:115] global_step/sec: 2.67611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 8.273832e-06, step = 16200 (37.368 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:04:58.019313 139883003524864 tf_logging.py:115] loss = 8.273832e-06, step = 16200 (37.368 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:05:35.384016 139883003524864 tf_logging.py:115] global_step/sec: 2.67616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.9837673e-05, step = 16300 (37.367 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:05:35.386026 139883003524864 tf_logging.py:115] loss = 2.9837673e-05, step = 16300 (37.367 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:06:12.777876 139883003524864 tf_logging.py:115] global_step/sec: 2.67424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.4845345e-06, step = 16400 (37.394 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:06:12.779864 139883003524864 tf_logging.py:115] loss = 9.4845345e-06, step = 16400 (37.394 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 16500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:06:49.685335 139883003524864 tf_logging.py:115] Saving checkpoints for 16500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:06:53.477091 139883003524864 tf_logging.py:115] global_step/sec: 2.45705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 8.750665e-06, step = 16500 (40.699 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:06:53.479144 139883003524864 tf_logging.py:115] loss = 8.750665e-06, step = 16500 (40.699 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:07:30.799753 139883003524864 tf_logging.py:115] global_step/sec: 2.67934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.036699492, step = 16600 (37.323 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:07:30.802648 139883003524864 tf_logging.py:115] loss = 0.036699492, step = 16600 (37.323 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:08:08.144249 139883003524864 tf_logging.py:115] global_step/sec: 2.67777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.760203e-06, step = 16700 (37.344 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:08:08.146795 139883003524864 tf_logging.py:115] loss = 9.760203e-06, step = 16700 (37.344 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:08:45.446278 139883003524864 tf_logging.py:115] global_step/sec: 2.68082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0002732883, step = 16800 (37.302 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:08:45.448491 139883003524864 tf_logging.py:115] loss = 0.0002732883, step = 16800 (37.302 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:09:22.831101 139883003524864 tf_logging.py:115] global_step/sec: 2.67489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.8136724e-05, step = 16900 (37.385 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:09:22.833087 139883003524864 tf_logging.py:115] loss = 6.8136724e-05, step = 16900 (37.385 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 17000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:09:59.756737 139883003524864 tf_logging.py:115] Saving checkpoints for 17000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:10:03.531873 139883003524864 tf_logging.py:115] global_step/sec: 2.45695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.9100712e-05, step = 17000 (40.701 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:10:03.534171 139883003524864 tf_logging.py:115] loss = 3.9100712e-05, step = 17000 (40.701 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:10:40.898575 139883003524864 tf_logging.py:115] global_step/sec: 2.67618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.694753e-05, step = 17100 (37.369 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:10:40.902943 139883003524864 tf_logging.py:115] loss = 7.694753e-05, step = 17100 (37.369 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:11:18.182051 139883003524864 tf_logging.py:115] global_step/sec: 2.68216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.07533151, step = 17200 (37.281 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:11:18.184212 139883003524864 tf_logging.py:115] loss = 0.07533151, step = 17200 (37.281 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:11:55.594734 139883003524864 tf_logging.py:115] global_step/sec: 2.67289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0004847786, step = 17300 (37.413 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:11:55.597282 139883003524864 tf_logging.py:115] loss = 0.0004847786, step = 17300 (37.413 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:12:32.974789 139883003524864 tf_logging.py:115] global_step/sec: 2.67522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00067211734, step = 17400 (37.380 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:12:32.977442 139883003524864 tf_logging.py:115] loss = 0.00067211734, step = 17400 (37.380 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 17500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:13:09.940107 139883003524864 tf_logging.py:115] Saving checkpoints for 17500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:13:13.623927 139883003524864 tf_logging.py:115] global_step/sec: 2.46008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00019043779, step = 17500 (40.648 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:13:13.625686 139883003524864 tf_logging.py:115] loss = 0.00019043779, step = 17500 (40.648 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:13:50.978121 139883003524864 tf_logging.py:115] global_step/sec: 2.67708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.1869363e-05, step = 17600 (37.355 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:13:50.980395 139883003524864 tf_logging.py:115] loss = 5.1869363e-05, step = 17600 (37.355 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:14:28.270157 139883003524864 tf_logging.py:115] global_step/sec: 2.68154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.6398316e-05, step = 17700 (37.292 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:14:28.272324 139883003524864 tf_logging.py:115] loss = 3.6398316e-05, step = 17700 (37.292 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:15:05.593073 139883003524864 tf_logging.py:115] global_step/sec: 2.67931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.2071512e-05, step = 17800 (37.323 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:15:05.595349 139883003524864 tf_logging.py:115] loss = 2.2071512e-05, step = 17800 (37.323 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:15:42.956847 139883003524864 tf_logging.py:115] global_step/sec: 2.67639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.5105799e-05, step = 17900 (37.364 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:15:42.959020 139883003524864 tf_logging.py:115] loss = 1.5105799e-05, step = 17900 (37.364 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 18000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:16:20.014863 139883003524864 tf_logging.py:115] Saving checkpoints for 18000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.43624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:16:24.003756 139883003524864 tf_logging.py:115] global_step/sec: 2.43624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.7225264e-05, step = 18000 (41.047 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:16:24.006479 139883003524864 tf_logging.py:115] loss = 1.7225264e-05, step = 18000 (41.047 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:17:01.562774 139883003524864 tf_logging.py:115] global_step/sec: 2.66248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.6539958e-05, step = 18100 (37.559 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:17:01.565441 139883003524864 tf_logging.py:115] loss = 2.6539958e-05, step = 18100 (37.559 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:17:38.960285 139883003524864 tf_logging.py:115] global_step/sec: 2.67396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0438204e-05, step = 18200 (37.397 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:17:38.962054 139883003524864 tf_logging.py:115] loss = 1.0438204e-05, step = 18200 (37.397 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:18:16.221395 139883003524864 tf_logging.py:115] global_step/sec: 2.68377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.39886e-06, step = 18300 (37.262 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:18:16.223713 139883003524864 tf_logging.py:115] loss = 9.39886e-06, step = 18300 (37.262 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:18:53.587285 139883003524864 tf_logging.py:115] global_step/sec: 2.67624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.1376952e-05, step = 18400 (37.366 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:18:53.589720 139883003524864 tf_logging.py:115] loss = 1.1376952e-05, step = 18400 (37.366 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 18500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:19:30.459001 139883003524864 tf_logging.py:115] Saving checkpoints for 18500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:19:34.261168 139883003524864 tf_logging.py:115] global_step/sec: 2.45858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.5241861e-05, step = 18500 (40.673 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:19:34.263135 139883003524864 tf_logging.py:115] loss = 2.5241861e-05, step = 18500 (40.673 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:20:11.704879 139883003524864 tf_logging.py:115] global_step/sec: 2.67068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.417254e-05, step = 18600 (37.444 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:20:11.707402 139883003524864 tf_logging.py:115] loss = 2.417254e-05, step = 18600 (37.444 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:20:49.186929 139883003524864 tf_logging.py:115] global_step/sec: 2.66794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0026787603, step = 18700 (37.482 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:20:49.189311 139883003524864 tf_logging.py:115] loss = 0.0026787603, step = 18700 (37.482 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:21:26.624026 139883003524864 tf_logging.py:115] global_step/sec: 2.67115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00025819422, step = 18800 (37.437 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:21:26.626152 139883003524864 tf_logging.py:115] loss = 0.00025819422, step = 18800 (37.437 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:22:04.037234 139883003524864 tf_logging.py:115] global_step/sec: 2.67285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0003999337, step = 18900 (37.414 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:22:04.039961 139883003524864 tf_logging.py:115] loss = 0.0003999337, step = 18900 (37.414 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 19000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:22:41.053300 139883003524864 tf_logging.py:115] Saving checkpoints for 19000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:22:44.947367 139883003524864 tf_logging.py:115] global_step/sec: 2.44438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00013743654, step = 19000 (40.910 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:22:44.949534 139883003524864 tf_logging.py:115] loss = 0.00013743654, step = 19000 (40.910 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:23:22.280095 139883003524864 tf_logging.py:115] global_step/sec: 2.67862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.5113993e-05, step = 19100 (37.333 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:23:22.282445 139883003524864 tf_logging.py:115] loss = 4.5113993e-05, step = 19100 (37.333 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:23:59.597154 139883003524864 tf_logging.py:115] global_step/sec: 2.67974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00072618725, step = 19200 (37.317 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:23:59.599692 139883003524864 tf_logging.py:115] loss = 0.00072618725, step = 19200 (37.317 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:24:36.915021 139883003524864 tf_logging.py:115] global_step/sec: 2.67968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.3638076e-05, step = 19300 (37.318 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:24:36.917202 139883003524864 tf_logging.py:115] loss = 5.3638076e-05, step = 19300 (37.318 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:25:14.325826 139883003524864 tf_logging.py:115] global_step/sec: 2.67302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.00149e-05, step = 19400 (37.411 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:25:14.328297 139883003524864 tf_logging.py:115] loss = 4.00149e-05, step = 19400 (37.411 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 19500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:25:51.230144 139883003524864 tf_logging.py:115] Saving checkpoints for 19500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.37369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:25:56.454295 139883003524864 tf_logging.py:115] global_step/sec: 2.37369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.5262265e-05, step = 19500 (42.129 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:25:56.456827 139883003524864 tf_logging.py:115] loss = 1.5262265e-05, step = 19500 (42.129 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:26:33.723170 139883003524864 tf_logging.py:115] global_step/sec: 2.6832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0654256e-05, step = 19600 (37.269 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:26:33.725495 139883003524864 tf_logging.py:115] loss = 1.0654256e-05, step = 19600 (37.269 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:27:11.055138 139883003524864 tf_logging.py:115] global_step/sec: 2.67867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.4573621e-05, step = 19700 (37.332 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:27:11.057616 139883003524864 tf_logging.py:115] loss = 2.4573621e-05, step = 19700 (37.332 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:27:48.352058 139883003524864 tf_logging.py:115] global_step/sec: 2.68119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.618649e-06, step = 19800 (37.297 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:27:48.354723 139883003524864 tf_logging.py:115] loss = 9.618649e-06, step = 19800 (37.297 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:28:25.753965 139883003524864 tf_logging.py:115] global_step/sec: 2.67366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 8.951829e-06, step = 19900 (37.402 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:28:25.756846 139883003524864 tf_logging.py:115] loss = 8.951829e-06, step = 19900 (37.402 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 20000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:29:02.786564 139883003524864 tf_logging.py:115] Saving checkpoints for 20000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:29:06.555162 139883003524864 tf_logging.py:115] global_step/sec: 2.45091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.045683e-05, step = 20000 (40.800 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:29:06.557264 139883003524864 tf_logging.py:115] loss = 1.045683e-05, step = 20000 (40.800 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:29:44.045668 139883003524864 tf_logging.py:115] global_step/sec: 2.66734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4714562e-05, step = 20100 (37.490 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:29:44.047741 139883003524864 tf_logging.py:115] loss = 1.4714562e-05, step = 20100 (37.490 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:30:21.509638 139883003524864 tf_logging.py:115] global_step/sec: 2.66923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.2527623e-05, step = 20200 (37.464 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:30:21.512085 139883003524864 tf_logging.py:115] loss = 4.2527623e-05, step = 20200 (37.464 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:30:58.896170 139883003524864 tf_logging.py:115] global_step/sec: 2.67476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.64935e-05, step = 20300 (37.386 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:30:58.898450 139883003524864 tf_logging.py:115] loss = 3.64935e-05, step = 20300 (37.386 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:31:36.338676 139883003524864 tf_logging.py:115] global_step/sec: 2.67076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00010087051, step = 20400 (37.442 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:31:36.340869 139883003524864 tf_logging.py:115] loss = 0.00010087051, step = 20400 (37.442 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 20500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:32:13.363862 139883003524864 tf_logging.py:115] Saving checkpoints for 20500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:32:16.991431 139883003524864 tf_logging.py:115] global_step/sec: 2.45986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.0478542e-05, step = 20500 (40.653 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:32:16.993592 139883003524864 tf_logging.py:115] loss = 4.0478542e-05, step = 20500 (40.653 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:32:54.379467 139883003524864 tf_logging.py:115] global_step/sec: 2.67465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.910134e-05, step = 20600 (37.388 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:32:54.381510 139883003524864 tf_logging.py:115] loss = 9.910134e-05, step = 20600 (37.388 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:33:31.726024 139883003524864 tf_logging.py:115] global_step/sec: 2.67762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.624189e-05, step = 20700 (37.346 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:33:31.727945 139883003524864 tf_logging.py:115] loss = 7.624189e-05, step = 20700 (37.346 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:34:09.013332 139883003524864 tf_logging.py:115] global_step/sec: 2.68188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.5696256e-05, step = 20800 (37.288 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:34:09.015473 139883003524864 tf_logging.py:115] loss = 3.5696256e-05, step = 20800 (37.288 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:34:46.366296 139883003524864 tf_logging.py:115] global_step/sec: 2.67716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4975318e-05, step = 20900 (37.355 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:34:46.370667 139883003524864 tf_logging.py:115] loss = 1.4975318e-05, step = 20900 (37.355 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 21000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:35:23.428279 139883003524864 tf_logging.py:115] Saving checkpoints for 21000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:35:27.058619 139883003524864 tf_logging.py:115] global_step/sec: 2.45746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.0955867e-05, step = 21000 (40.690 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:35:27.060655 139883003524864 tf_logging.py:115] loss = 3.0955867e-05, step = 21000 (40.690 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:36:04.470283 139883003524864 tf_logging.py:115] global_step/sec: 2.67297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.6351334e-05, step = 21100 (37.412 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:36:04.472804 139883003524864 tf_logging.py:115] loss = 2.6351334e-05, step = 21100 (37.412 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:36:41.904663 139883003524864 tf_logging.py:115] global_step/sec: 2.67134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.1645166e-05, step = 21200 (37.434 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:36:41.907011 139883003524864 tf_logging.py:115] loss = 1.1645166e-05, step = 21200 (37.434 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:37:19.235584 139883003524864 tf_logging.py:115] global_step/sec: 2.67874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.0723353e-05, step = 21300 (37.330 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:37:19.237399 139883003524864 tf_logging.py:115] loss = 4.0723353e-05, step = 21300 (37.330 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:37:56.748524 139883003524864 tf_logging.py:115] global_step/sec: 2.66575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.1574301e-05, step = 21400 (37.514 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:37:56.750926 139883003524864 tf_logging.py:115] loss = 1.1574301e-05, step = 21400 (37.514 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 21500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:38:33.784721 139883003524864 tf_logging.py:115] Saving checkpoints for 21500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:38:37.412912 139883003524864 tf_logging.py:115] global_step/sec: 2.45915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.811901e-06, step = 21500 (40.664 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:38:37.414927 139883003524864 tf_logging.py:115] loss = 7.811901e-06, step = 21500 (40.664 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:39:14.721065 139883003524864 tf_logging.py:115] global_step/sec: 2.68038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.394672e-06, step = 21600 (37.308 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:39:14.723150 139883003524864 tf_logging.py:115] loss = 7.394672e-06, step = 21600 (37.308 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:39:52.044352 139883003524864 tf_logging.py:115] global_step/sec: 2.67929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.964632e-06, step = 21700 (37.324 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:39:52.046853 139883003524864 tf_logging.py:115] loss = 7.964632e-06, step = 21700 (37.324 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:40:29.375565 139883003524864 tf_logging.py:115] global_step/sec: 2.67872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.10058493, step = 21800 (37.331 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:40:29.377865 139883003524864 tf_logging.py:115] loss = 0.10058493, step = 21800 (37.331 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:41:06.880161 139883003524864 tf_logging.py:115] global_step/sec: 2.66634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.3620377e-05, step = 21900 (37.505 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:41:06.882427 139883003524864 tf_logging.py:115] loss = 4.3620377e-05, step = 21900 (37.505 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 22000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:41:43.889738 139883003524864 tf_logging.py:115] Saving checkpoints for 22000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:41:47.703017 139883003524864 tf_logging.py:115] global_step/sec: 2.44961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.0883427e-05, step = 22000 (40.823 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:41:47.704919 139883003524864 tf_logging.py:115] loss = 5.0883427e-05, step = 22000 (40.823 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:42:25.089363 139883003524864 tf_logging.py:115] global_step/sec: 2.67478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.2632145e-05, step = 22100 (37.387 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:42:25.091664 139883003524864 tf_logging.py:115] loss = 9.2632145e-05, step = 22100 (37.387 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:43:02.551710 139883003524864 tf_logging.py:115] global_step/sec: 2.66934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.58682e-05, step = 22200 (37.462 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:43:02.553922 139883003524864 tf_logging.py:115] loss = 3.58682e-05, step = 22200 (37.462 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:43:39.932022 139883003524864 tf_logging.py:115] global_step/sec: 2.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.016356925, step = 22300 (37.380 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:43:39.934341 139883003524864 tf_logging.py:115] loss = 0.016356925, step = 22300 (37.380 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:44:17.449774 139883003524864 tf_logging.py:115] global_step/sec: 2.6654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.8235245e-05, step = 22400 (37.517 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:44:17.451766 139883003524864 tf_logging.py:115] loss = 3.8235245e-05, step = 22400 (37.517 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 22500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:44:54.409734 139883003524864 tf_logging.py:115] Saving checkpoints for 22500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:44:58.163891 139883003524864 tf_logging.py:115] global_step/sec: 2.45615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.5906967e-05, step = 22500 (40.715 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:44:58.166601 139883003524864 tf_logging.py:115] loss = 2.5906967e-05, step = 22500 (40.715 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:45:35.483216 139883003524864 tf_logging.py:115] global_step/sec: 2.67958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.3450568e-05, step = 22600 (37.319 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:45:35.485565 139883003524864 tf_logging.py:115] loss = 3.3450568e-05, step = 22600 (37.319 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:46:12.702665 139883003524864 tf_logging.py:115] global_step/sec: 2.68677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.589254e-05, step = 22700 (37.219 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:46:12.705013 139883003524864 tf_logging.py:115] loss = 5.589254e-05, step = 22700 (37.219 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:46:50.030459 139883003524864 tf_logging.py:115] global_step/sec: 2.67897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.596849e-05, step = 22800 (37.328 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:46:50.032880 139883003524864 tf_logging.py:115] loss = 3.596849e-05, step = 22800 (37.328 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:47:27.446819 139883003524864 tf_logging.py:115] global_step/sec: 2.67263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0184798e-05, step = 22900 (37.417 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:47:27.449411 139883003524864 tf_logging.py:115] loss = 1.0184798e-05, step = 22900 (37.417 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 23000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:48:04.411124 139883003524864 tf_logging.py:115] Saving checkpoints for 23000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:48:08.191055 139883003524864 tf_logging.py:115] global_step/sec: 2.45434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.953461e-06, step = 23000 (40.745 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:48:08.194903 139883003524864 tf_logging.py:115] loss = 7.953461e-06, step = 23000 (40.745 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:48:45.645090 139883003524864 tf_logging.py:115] global_step/sec: 2.66994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.6889655e-06, step = 23100 (37.453 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:48:45.647504 139883003524864 tf_logging.py:115] loss = 7.6889655e-06, step = 23100 (37.453 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:49:22.900292 139883003524864 tf_logging.py:115] global_step/sec: 2.68419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.376045e-06, step = 23200 (37.255 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:49:22.902167 139883003524864 tf_logging.py:115] loss = 7.376045e-06, step = 23200 (37.255 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:50:00.228225 139883003524864 tf_logging.py:115] global_step/sec: 2.67897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.860319e-06, step = 23300 (37.328 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:50:00.230587 139883003524864 tf_logging.py:115] loss = 7.860319e-06, step = 23300 (37.328 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:50:37.720119 139883003524864 tf_logging.py:115] global_step/sec: 2.66724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.7150435e-06, step = 23400 (37.492 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:50:37.722278 139883003524864 tf_logging.py:115] loss = 7.7150435e-06, step = 23400 (37.492 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 23500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:51:14.754456 139883003524864 tf_logging.py:115] Saving checkpoints for 23500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:51:18.313977 139883003524864 tf_logging.py:115] global_step/sec: 2.46343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.6695963e-05, step = 23500 (40.594 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:51:18.315949 139883003524864 tf_logging.py:115] loss = 1.6695963e-05, step = 23500 (40.594 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:51:55.656284 139883003524864 tf_logging.py:115] global_step/sec: 2.67793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.0177129e-05, step = 23600 (37.343 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:51:55.658843 139883003524864 tf_logging.py:115] loss = 3.0177129e-05, step = 23600 (37.343 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:52:32.951606 139883003524864 tf_logging.py:115] global_step/sec: 2.6813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.6018128e-05, step = 23700 (37.295 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:52:32.954020 139883003524864 tf_logging.py:115] loss = 1.6018128e-05, step = 23700 (37.295 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:53:10.274463 139883003524864 tf_logging.py:115] global_step/sec: 2.67932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0914871e-05, step = 23800 (37.323 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:53:10.276525 139883003524864 tf_logging.py:115] loss = 1.0914871e-05, step = 23800 (37.323 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:53:47.557759 139883003524864 tf_logging.py:115] global_step/sec: 2.68216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 8.2514325e-06, step = 23900 (37.283 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:53:47.559595 139883003524864 tf_logging.py:115] loss = 8.2514325e-06, step = 23900 (37.283 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 24000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:54:24.579621 139883003524864 tf_logging.py:115] Saving checkpoints for 24000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:54:28.149890 139883003524864 tf_logging.py:115] global_step/sec: 2.46353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.614733e-05, step = 24000 (40.592 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:54:28.152072 139883003524864 tf_logging.py:115] loss = 3.614733e-05, step = 24000 (40.592 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:55:05.595833 139883003524864 tf_logging.py:115] global_step/sec: 2.67052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.8885064e-05, step = 24100 (37.446 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:55:05.597877 139883003524864 tf_logging.py:115] loss = 3.8885064e-05, step = 24100 (37.446 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:55:43.000986 139883003524864 tf_logging.py:115] global_step/sec: 2.67343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.7858569e-05, step = 24200 (37.405 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:55:43.002942 139883003524864 tf_logging.py:115] loss = 1.7858569e-05, step = 24200 (37.405 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:56:20.446913 139883003524864 tf_logging.py:115] global_step/sec: 2.67052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4725825e-05, step = 24300 (37.446 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:56:20.448928 139883003524864 tf_logging.py:115] loss = 1.4725825e-05, step = 24300 (37.446 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:56:57.947700 139883003524864 tf_logging.py:115] global_step/sec: 2.66661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.379453e-05, step = 24400 (37.501 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:56:57.950135 139883003524864 tf_logging.py:115] loss = 1.379453e-05, step = 24400 (37.501 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 24500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:57:34.995243 139883003524864 tf_logging.py:115] Saving checkpoints for 24500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:57:38.656664 139883003524864 tf_logging.py:115] global_step/sec: 2.45647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.0648767e-05, step = 24500 (40.709 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:57:38.659147 139883003524864 tf_logging.py:115] loss = 3.0648767e-05, step = 24500 (40.709 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:58:16.108922 139883003524864 tf_logging.py:115] global_step/sec: 2.67006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0627977e-05, step = 24600 (37.452 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:58:16.111303 139883003524864 tf_logging.py:115] loss = 1.0627977e-05, step = 24600 (37.452 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:58:53.493168 139883003524864 tf_logging.py:115] global_step/sec: 2.67492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.4430964e-06, step = 24700 (37.384 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:58:53.495673 139883003524864 tf_logging.py:115] loss = 7.4430964e-06, step = 24700 (37.384 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:59:31.026504 139883003524864 tf_logging.py:115] global_step/sec: 2.6643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 8.124805e-06, step = 24800 (37.533 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 00:59:31.028930 139883003524864 tf_logging.py:115] loss = 8.124805e-06, step = 24800 (37.533 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:00:08.530267 139883003524864 tf_logging.py:115] global_step/sec: 2.6664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 8.612791e-06, step = 24900 (37.504 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:00:08.532714 139883003524864 tf_logging.py:115] loss = 8.612791e-06, step = 24900 (37.504 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 25000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:00:45.575515 139883003524864 tf_logging.py:115] Saving checkpoints for 25000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:00:49.374107 139883003524864 tf_logging.py:115] global_step/sec: 2.44834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.869398e-06, step = 25000 (40.844 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:00:49.376356 139883003524864 tf_logging.py:115] loss = 6.869398e-06, step = 25000 (40.844 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:01:26.830328 139883003524864 tf_logging.py:115] global_step/sec: 2.66979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.409567e-06, step = 25100 (37.457 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:01:26.832925 139883003524864 tf_logging.py:115] loss = 7.409567e-06, step = 25100 (37.457 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:02:04.150018 139883003524864 tf_logging.py:115] global_step/sec: 2.67955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.2282055e-05, step = 25200 (37.320 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:02:04.152461 139883003524864 tf_logging.py:115] loss = 1.2282055e-05, step = 25200 (37.320 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:02:41.582691 139883003524864 tf_logging.py:115] global_step/sec: 2.67146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.277011e-05, step = 25300 (37.434 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:02:41.586561 139883003524864 tf_logging.py:115] loss = 1.277011e-05, step = 25300 (37.434 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:03:19.157733 139883003524864 tf_logging.py:115] global_step/sec: 2.66134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.7426019e-05, step = 25400 (37.574 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:03:19.160453 139883003524864 tf_logging.py:115] loss = 1.7426019e-05, step = 25400 (37.574 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 25500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:03:56.170511 139883003524864 tf_logging.py:115] Saving checkpoints for 25500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:03:59.936515 139883003524864 tf_logging.py:115] global_step/sec: 2.45226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.063108e-06, step = 25500 (40.778 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:03:59.938538 139883003524864 tf_logging.py:115] loss = 7.063108e-06, step = 25500 (40.778 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:04:37.408458 139883003524864 tf_logging.py:115] global_step/sec: 2.66866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.151018e-05, step = 25600 (37.472 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:04:37.410440 139883003524864 tf_logging.py:115] loss = 5.151018e-05, step = 25600 (37.472 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:05:14.745033 139883003524864 tf_logging.py:115] global_step/sec: 2.67834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.3176075e-05, step = 25700 (37.337 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:05:14.747625 139883003524864 tf_logging.py:115] loss = 1.3176075e-05, step = 25700 (37.337 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:05:52.056754 139883003524864 tf_logging.py:115] global_step/sec: 2.68012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0001174804, step = 25800 (37.312 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:05:52.059277 139883003524864 tf_logging.py:115] loss = 0.0001174804, step = 25800 (37.312 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:06:29.357059 139883003524864 tf_logging.py:115] global_step/sec: 2.68094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.1677068e-05, step = 25900 (37.300 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:06:29.359318 139883003524864 tf_logging.py:115] loss = 2.1677068e-05, step = 25900 (37.300 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 26000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:07:06.382324 139883003524864 tf_logging.py:115] Saving checkpoints for 26000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:07:10.085609 139883003524864 tf_logging.py:115] global_step/sec: 2.45528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.417445e-06, step = 26000 (40.729 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:07:10.088095 139883003524864 tf_logging.py:115] loss = 9.417445e-06, step = 26000 (40.729 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:07:47.531368 139883003524864 tf_logging.py:115] global_step/sec: 2.67053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.070962e-06, step = 26100 (37.445 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:07:47.533362 139883003524864 tf_logging.py:115] loss = 9.070962e-06, step = 26100 (37.445 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:08:24.856680 139883003524864 tf_logging.py:115] global_step/sec: 2.67915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.3553134e-06, step = 26200 (37.326 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:08:24.858927 139883003524864 tf_logging.py:115] loss = 6.3553134e-06, step = 26200 (37.326 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:09:02.289880 139883003524864 tf_logging.py:115] global_step/sec: 2.67143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00077797665, step = 26300 (37.434 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:09:02.292801 139883003524864 tf_logging.py:115] loss = 0.00077797665, step = 26300 (37.434 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:09:39.773539 139883003524864 tf_logging.py:115] global_step/sec: 2.66783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.6267983e-06, step = 26400 (37.483 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:09:39.775854 139883003524864 tf_logging.py:115] loss = 4.6267983e-06, step = 26400 (37.483 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 26500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:10:16.836817 139883003524864 tf_logging.py:115] Saving checkpoints for 26500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.4357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:10:20.829626 139883003524864 tf_logging.py:115] global_step/sec: 2.4357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.623074e-06, step = 26500 (41.056 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:10:20.831944 139883003524864 tf_logging.py:115] loss = 4.623074e-06, step = 26500 (41.056 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:10:58.151254 139883003524864 tf_logging.py:115] global_step/sec: 2.67941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.573011e-06, step = 26600 (37.321 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:10:58.153407 139883003524864 tf_logging.py:115] loss = 5.573011e-06, step = 26600 (37.321 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:11:35.458424 139883003524864 tf_logging.py:115] global_step/sec: 2.68045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.746378e-06, step = 26700 (37.307 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:11:35.460341 139883003524864 tf_logging.py:115] loss = 6.746378e-06, step = 26700 (37.307 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:12:12.909557 139883003524864 tf_logging.py:115] global_step/sec: 2.67015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.9583446e-06, step = 26800 (37.451 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:12:12.911666 139883003524864 tf_logging.py:115] loss = 4.9583446e-06, step = 26800 (37.451 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:12:50.313878 139883003524864 tf_logging.py:115] global_step/sec: 2.67349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.325191e-05, step = 26900 (37.405 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:12:50.316329 139883003524864 tf_logging.py:115] loss = 3.325191e-05, step = 26900 (37.405 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 27000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:13:27.347928 139883003524864 tf_logging.py:115] Saving checkpoints for 27000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:13:30.938621 139883003524864 tf_logging.py:115] global_step/sec: 2.46155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.6794078e-06, step = 27000 (40.624 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:13:30.940476 139883003524864 tf_logging.py:115] loss = 6.6794078e-06, step = 27000 (40.624 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:14:08.240266 139883003524864 tf_logging.py:115] global_step/sec: 2.68085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.241906e-06, step = 27100 (37.302 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:14:08.242616 139883003524864 tf_logging.py:115] loss = 7.241906e-06, step = 27100 (37.302 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:14:45.655711 139883003524864 tf_logging.py:115] global_step/sec: 2.6727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.6831326e-06, step = 27200 (37.415 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:14:45.658038 139883003524864 tf_logging.py:115] loss = 6.6831326e-06, step = 27200 (37.415 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:15:23.119030 139883003524864 tf_logging.py:115] global_step/sec: 2.66928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.3037303e-05, step = 27300 (37.463 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:15:23.121154 139883003524864 tf_logging.py:115] loss = 2.3037303e-05, step = 27300 (37.463 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:16:00.501986 139883003524864 tf_logging.py:115] global_step/sec: 2.67502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.331335e-06, step = 27400 (37.383 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:16:00.504138 139883003524864 tf_logging.py:115] loss = 7.331335e-06, step = 27400 (37.383 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 27500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:16:37.578414 139883003524864 tf_logging.py:115] Saving checkpoints for 27500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:16:41.295672 139883003524864 tf_logging.py:115] global_step/sec: 2.45136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.1253989e-05, step = 27500 (40.794 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:16:41.298057 139883003524864 tf_logging.py:115] loss = 1.1253989e-05, step = 27500 (40.794 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:17:18.647036 139883003524864 tf_logging.py:115] global_step/sec: 2.67728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.9836207e-05, step = 27600 (37.351 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:17:18.649134 139883003524864 tf_logging.py:115] loss = 1.9836207e-05, step = 27600 (37.351 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:17:56.052219 139883003524864 tf_logging.py:115] global_step/sec: 2.67342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.845839e-06, step = 27700 (37.406 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:17:56.054679 139883003524864 tf_logging.py:115] loss = 9.845839e-06, step = 27700 (37.406 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:18:33.396223 139883003524864 tf_logging.py:115] global_step/sec: 2.6778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.295581e-05, step = 27800 (37.343 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:18:33.398091 139883003524864 tf_logging.py:115] loss = 2.295581e-05, step = 27800 (37.343 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:19:10.670190 139883003524864 tf_logging.py:115] global_step/sec: 2.68284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.958799e-06, step = 27900 (37.275 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:19:10.672690 139883003524864 tf_logging.py:115] loss = 6.958799e-06, step = 27900 (37.275 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 28000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:19:47.655602 139883003524864 tf_logging.py:115] Saving checkpoints for 28000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:19:51.533385 139883003524864 tf_logging.py:115] global_step/sec: 2.44719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.7518287e-06, step = 28000 (40.866 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:19:51.538778 139883003524864 tf_logging.py:115] loss = 5.7518287e-06, step = 28000 (40.866 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:20:28.921424 139883003524864 tf_logging.py:115] global_step/sec: 2.67465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.484016e-06, step = 28100 (37.385 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:20:28.923642 139883003524864 tf_logging.py:115] loss = 7.484016e-06, step = 28100 (37.385 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:21:06.303345 139883003524864 tf_logging.py:115] global_step/sec: 2.67508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.083368e-06, step = 28200 (37.382 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:21:06.305632 139883003524864 tf_logging.py:115] loss = 6.083368e-06, step = 28200 (37.382 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:21:43.629162 139883003524864 tf_logging.py:115] global_step/sec: 2.67911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.9359965e-06, step = 28300 (37.326 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:21:43.631145 139883003524864 tf_logging.py:115] loss = 4.9359965e-06, step = 28300 (37.326 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:22:20.978800 139883003524864 tf_logging.py:115] global_step/sec: 2.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.2940434e-06, step = 28400 (37.350 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:22:20.980771 139883003524864 tf_logging.py:115] loss = 7.2940434e-06, step = 28400 (37.350 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 28500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:22:57.894224 139883003524864 tf_logging.py:115] Saving checkpoints for 28500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:23:01.623626 139883003524864 tf_logging.py:115] global_step/sec: 2.46034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.284523e-06, step = 28500 (40.645 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:23:01.625791 139883003524864 tf_logging.py:115] loss = 6.284523e-06, step = 28500 (40.645 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:23:38.881221 139883003524864 tf_logging.py:115] global_step/sec: 2.68402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 8.210424e-06, step = 28600 (37.258 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:23:38.883317 139883003524864 tf_logging.py:115] loss = 8.210424e-06, step = 28600 (37.258 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:24:16.087181 139883003524864 tf_logging.py:115] global_step/sec: 2.68774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 8.709644e-06, step = 28700 (37.206 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:24:16.089321 139883003524864 tf_logging.py:115] loss = 8.709644e-06, step = 28700 (37.206 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:24:53.478495 139883003524864 tf_logging.py:115] global_step/sec: 2.67442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.908855e-06, step = 28800 (37.391 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:24:53.480545 139883003524864 tf_logging.py:115] loss = 9.908855e-06, step = 28800 (37.391 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:25:30.838804 139883003524864 tf_logging.py:115] global_step/sec: 2.67663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 8.3408195e-06, step = 28900 (37.360 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:25:30.840845 139883003524864 tf_logging.py:115] loss = 8.3408195e-06, step = 28900 (37.360 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 29000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:26:07.808506 139883003524864 tf_logging.py:115] Saving checkpoints for 29000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:26:11.608011 139883003524864 tf_logging.py:115] global_step/sec: 2.45283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.1187017e-05, step = 29000 (40.769 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:26:11.610213 139883003524864 tf_logging.py:115] loss = 3.1187017e-05, step = 29000 (40.769 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:26:48.921865 139883003524864 tf_logging.py:115] global_step/sec: 2.67997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0896319e-05, step = 29100 (37.314 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:26:48.924381 139883003524864 tf_logging.py:115] loss = 1.0896319e-05, step = 29100 (37.314 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:27:26.278655 139883003524864 tf_logging.py:115] global_step/sec: 2.67689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.530865e-05, step = 29200 (37.356 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:27:26.280700 139883003524864 tf_logging.py:115] loss = 7.530865e-05, step = 29200 (37.356 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:28:03.642047 139883003524864 tf_logging.py:115] global_step/sec: 2.67642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 8.046527e-06, step = 29300 (37.364 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:28:03.644931 139883003524864 tf_logging.py:115] loss = 8.046527e-06, step = 29300 (37.364 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:28:41.060178 139883003524864 tf_logging.py:115] global_step/sec: 2.6725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.9289042e-05, step = 29400 (37.418 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:28:41.062463 139883003524864 tf_logging.py:115] loss = 2.9289042e-05, step = 29400 (37.418 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 29500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:29:17.985224 139883003524864 tf_logging.py:115] Saving checkpoints for 29500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.4618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:29:21.680823 139883003524864 tf_logging.py:115] global_step/sec: 2.4618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.8731215e-06, step = 29500 (40.621 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:29:21.683050 139883003524864 tf_logging.py:115] loss = 6.8731215e-06, step = 29500 (40.621 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:29:59.043884 139883003524864 tf_logging.py:115] global_step/sec: 2.67645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.91057e-05, step = 29600 (37.363 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:29:59.046299 139883003524864 tf_logging.py:115] loss = 1.91057e-05, step = 29600 (37.363 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:30:36.366807 139883003524864 tf_logging.py:115] global_step/sec: 2.67932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.3734804e-06, step = 29700 (37.323 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:30:36.369645 139883003524864 tf_logging.py:115] loss = 4.3734804e-06, step = 29700 (37.323 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:31:13.638247 139883003524864 tf_logging.py:115] global_step/sec: 2.68302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.267611e-05, step = 29800 (37.270 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:31:13.640056 139883003524864 tf_logging.py:115] loss = 1.267611e-05, step = 29800 (37.270 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:31:50.868929 139883003524864 tf_logging.py:115] global_step/sec: 2.68596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.634245e-06, step = 29900 (37.231 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:31:50.871443 139883003524864 tf_logging.py:115] loss = 4.634245e-06, step = 29900 (37.231 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 30000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:32:27.923605 139883003524864 tf_logging.py:115] Saving checkpoints for 30000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.4518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:32:31.655272 139883003524864 tf_logging.py:115] global_step/sec: 2.4518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.819679e-06, step = 30000 (40.786 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:32:31.657253 139883003524864 tf_logging.py:115] loss = 9.819679e-06, step = 30000 (40.786 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:33:09.027497 139883003524864 tf_logging.py:115] global_step/sec: 2.67579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.231919e-06, step = 30100 (37.373 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:33:09.030138 139883003524864 tf_logging.py:115] loss = 4.231919e-06, step = 30100 (37.373 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:33:46.435253 139883003524864 tf_logging.py:115] global_step/sec: 2.67324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.1706693e-06, step = 30200 (37.407 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:33:46.437410 139883003524864 tf_logging.py:115] loss = 5.1706693e-06, step = 30200 (37.407 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:34:23.790446 139883003524864 tf_logging.py:115] global_step/sec: 2.677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.5576082e-05, step = 30300 (37.355 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:34:23.792733 139883003524864 tf_logging.py:115] loss = 3.5576082e-05, step = 30300 (37.355 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:35:01.244954 139883003524864 tf_logging.py:115] global_step/sec: 2.6699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.3097879e-05, step = 30400 (37.454 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:35:01.247059 139883003524864 tf_logging.py:115] loss = 1.3097879e-05, step = 30400 (37.454 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 30500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:35:38.144949 139883003524864 tf_logging.py:115] Saving checkpoints for 30500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:35:41.891328 139883003524864 tf_logging.py:115] global_step/sec: 2.46024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.6654933e-05, step = 30500 (40.646 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:35:41.893212 139883003524864 tf_logging.py:115] loss = 1.6654933e-05, step = 30500 (40.646 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:36:19.280561 139883003524864 tf_logging.py:115] global_step/sec: 2.67457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.850769e-06, step = 30600 (37.390 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:36:19.282938 139883003524864 tf_logging.py:115] loss = 6.850769e-06, step = 30600 (37.390 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:36:56.618808 139883003524864 tf_logging.py:115] global_step/sec: 2.67822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.3383716e-05, step = 30700 (37.338 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:36:56.621227 139883003524864 tf_logging.py:115] loss = 2.3383716e-05, step = 30700 (37.338 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:37:33.898788 139883003524864 tf_logging.py:115] global_step/sec: 2.68241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.17791615e-05, step = 30800 (37.279 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:37:33.900672 139883003524864 tf_logging.py:115] loss = 1.17791615e-05, step = 30800 (37.279 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:38:11.265628 139883003524864 tf_logging.py:115] global_step/sec: 2.67617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4736763e-05, step = 30900 (37.367 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:38:11.267553 139883003524864 tf_logging.py:115] loss = 1.4736763e-05, step = 30900 (37.367 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 31000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:38:48.218190 139883003524864 tf_logging.py:115] Saving checkpoints for 31000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:38:52.050709 139883003524864 tf_logging.py:115] global_step/sec: 2.45188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.703859e-06, step = 31000 (40.785 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:38:52.052978 139883003524864 tf_logging.py:115] loss = 7.703859e-06, step = 31000 (40.785 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:39:29.451441 139883003524864 tf_logging.py:115] global_step/sec: 2.67374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.485815e-05, step = 31100 (37.400 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:39:29.453284 139883003524864 tf_logging.py:115] loss = 2.485815e-05, step = 31100 (37.400 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:40:06.858287 139883003524864 tf_logging.py:115] global_step/sec: 2.67331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.3590264e-06, step = 31200 (37.408 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:40:06.861108 139883003524864 tf_logging.py:115] loss = 6.3590264e-06, step = 31200 (37.408 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:40:44.332614 139883003524864 tf_logging.py:115] global_step/sec: 2.66849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.6065296e-06, step = 31300 (37.474 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:40:44.334761 139883003524864 tf_logging.py:115] loss = 5.6065296e-06, step = 31300 (37.474 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:41:21.627790 139883003524864 tf_logging.py:115] global_step/sec: 2.68131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.4802756e-06, step = 31400 (37.295 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:41:21.630072 139883003524864 tf_logging.py:115] loss = 7.4802756e-06, step = 31400 (37.295 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 31500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:41:58.541069 139883003524864 tf_logging.py:115] Saving checkpoints for 31500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:42:02.336706 139883003524864 tf_logging.py:115] global_step/sec: 2.45646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.805609e-06, step = 31500 (40.709 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:42:02.339472 139883003524864 tf_logging.py:115] loss = 4.805609e-06, step = 31500 (40.709 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:42:39.636011 139883003524864 tf_logging.py:115] global_step/sec: 2.68101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.755085e-06, step = 31600 (37.299 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:42:39.638136 139883003524864 tf_logging.py:115] loss = 3.755085e-06, step = 31600 (37.299 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:43:16.906485 139883003524864 tf_logging.py:115] global_step/sec: 2.68309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.7161984e-06, step = 31700 (37.270 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:43:16.908358 139883003524864 tf_logging.py:115] loss = 4.7161984e-06, step = 31700 (37.270 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:43:54.203326 139883003524864 tf_logging.py:115] global_step/sec: 2.6812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.6917552e-06, step = 31800 (37.297 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:43:54.205527 139883003524864 tf_logging.py:115] loss = 3.6917552e-06, step = 31800 (37.297 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:44:31.502082 139883003524864 tf_logging.py:115] global_step/sec: 2.68105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.6880301e-06, step = 31900 (37.299 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:44:31.504355 139883003524864 tf_logging.py:115] loss = 3.6880301e-06, step = 31900 (37.299 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 32000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:45:08.434771 139883003524864 tf_logging.py:115] Saving checkpoints for 32000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:45:12.063152 139883003524864 tf_logging.py:115] global_step/sec: 2.46542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.9455037e-06, step = 32000 (40.561 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:45:12.065252 139883003524864 tf_logging.py:115] loss = 5.9455037e-06, step = 32000 (40.561 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:45:49.465434 139883003524864 tf_logging.py:115] global_step/sec: 2.67363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.191397e-06, step = 32100 (37.402 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:45:49.467253 139883003524864 tf_logging.py:115] loss = 6.191397e-06, step = 32100 (37.402 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:46:26.762489 139883003524864 tf_logging.py:115] global_step/sec: 2.68118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.6975774e-06, step = 32200 (37.297 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:46:26.764516 139883003524864 tf_logging.py:115] loss = 4.6975774e-06, step = 32200 (37.297 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:47:04.045051 139883003524864 tf_logging.py:115] global_step/sec: 2.68222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.3734785e-06, step = 32300 (37.282 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:47:04.046984 139883003524864 tf_logging.py:115] loss = 4.3734785e-06, step = 32300 (37.282 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:47:41.542099 139883003524864 tf_logging.py:115] global_step/sec: 2.66687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.986428e-06, step = 32400 (37.498 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:47:41.544591 139883003524864 tf_logging.py:115] loss = 5.986428e-06, step = 32400 (37.498 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 32500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:48:18.544064 139883003524864 tf_logging.py:115] Saving checkpoints for 32500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:48:22.369333 139883003524864 tf_logging.py:115] global_step/sec: 2.44935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.5671886e-06, step = 32500 (40.827 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:48:22.371682 139883003524864 tf_logging.py:115] loss = 4.5671886e-06, step = 32500 (40.827 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:48:59.733181 139883003524864 tf_logging.py:115] global_step/sec: 2.67638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.9136397e-06, step = 32600 (37.364 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:48:59.735204 139883003524864 tf_logging.py:115] loss = 4.9136397e-06, step = 32600 (37.364 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:49:37.053999 139883003524864 tf_logging.py:115] global_step/sec: 2.67947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.2654465e-06, step = 32700 (37.321 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:49:37.056149 139883003524864 tf_logging.py:115] loss = 4.2654465e-06, step = 32700 (37.321 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:50:14.396450 139883003524864 tf_logging.py:115] global_step/sec: 2.67792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.843278e-06, step = 32800 (37.342 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:50:14.398633 139883003524864 tf_logging.py:115] loss = 6.843278e-06, step = 32800 (37.342 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:50:51.694546 139883003524864 tf_logging.py:115] global_step/sec: 2.68111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.141445e-06, step = 32900 (37.298 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:50:51.696428 139883003524864 tf_logging.py:115] loss = 9.141445e-06, step = 32900 (37.298 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 33000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:51:28.629912 139883003524864 tf_logging.py:115] Saving checkpoints for 33000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:51:32.350810 139883003524864 tf_logging.py:115] global_step/sec: 2.45964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.6714995e-06, step = 33000 (40.657 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:51:32.353154 139883003524864 tf_logging.py:115] loss = 4.6714995e-06, step = 33000 (40.657 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:52:09.674592 139883003524864 tf_logging.py:115] global_step/sec: 2.67925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.135062e-06, step = 33100 (37.324 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:52:09.677308 139883003524864 tf_logging.py:115] loss = 4.135062e-06, step = 33100 (37.324 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:52:47.059793 139883003524864 tf_logging.py:115] global_step/sec: 2.67486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.3341285e-06, step = 33200 (37.384 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:52:47.061747 139883003524864 tf_logging.py:115] loss = 3.3341285e-06, step = 33200 (37.384 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:53:24.414428 139883003524864 tf_logging.py:115] global_step/sec: 2.67705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.7774364e-06, step = 33300 (37.355 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:53:24.416432 139883003524864 tf_logging.py:115] loss = 3.7774364e-06, step = 33300 (37.355 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:54:01.848731 139883003524864 tf_logging.py:115] global_step/sec: 2.67134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.3006015e-06, step = 33400 (37.435 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:54:01.851384 139883003524864 tf_logging.py:115] loss = 3.3006015e-06, step = 33400 (37.435 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 33500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:54:38.864126 139883003524864 tf_logging.py:115] Saving checkpoints for 33500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:54:42.565410 139883003524864 tf_logging.py:115] global_step/sec: 2.45599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.4347113e-06, step = 33500 (40.716 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:54:42.567713 139883003524864 tf_logging.py:115] loss = 3.4347113e-06, step = 33500 (40.716 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:55:19.875431 139883003524864 tf_logging.py:115] global_step/sec: 2.68025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.8970286e-06, step = 33600 (37.310 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:55:19.877571 139883003524864 tf_logging.py:115] loss = 5.8970286e-06, step = 33600 (37.310 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:55:57.213937 139883003524864 tf_logging.py:115] global_step/sec: 2.6782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.4090815e-06, step = 33700 (37.339 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:55:57.216238 139883003524864 tf_logging.py:115] loss = 5.4090815e-06, step = 33700 (37.339 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:56:34.490244 139883003524864 tf_logging.py:115] global_step/sec: 2.68267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.0456553e-06, step = 33800 (37.276 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:56:34.492201 139883003524864 tf_logging.py:115] loss = 4.0456553e-06, step = 33800 (37.276 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:57:11.778484 139883003524864 tf_logging.py:115] global_step/sec: 2.68181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.4256317e-06, step = 33900 (37.289 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:57:11.780979 139883003524864 tf_logging.py:115] loss = 4.4256317e-06, step = 33900 (37.289 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 34000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:57:48.751217 139883003524864 tf_logging.py:115] Saving checkpoints for 34000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:57:52.459253 139883003524864 tf_logging.py:115] global_step/sec: 2.45816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.2377263e-06, step = 34000 (40.681 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:57:52.461492 139883003524864 tf_logging.py:115] loss = 5.2377263e-06, step = 34000 (40.681 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:58:29.851605 139883003524864 tf_logging.py:115] global_step/sec: 2.67434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.21492e-06, step = 34100 (37.393 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:58:29.854006 139883003524864 tf_logging.py:115] loss = 3.21492e-06, step = 34100 (37.393 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:59:07.107518 139883003524864 tf_logging.py:115] global_step/sec: 2.68414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.7459985e-06, step = 34200 (37.256 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:59:07.109704 139883003524864 tf_logging.py:115] loss = 4.7459985e-06, step = 34200 (37.256 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:59:44.450911 139883003524864 tf_logging.py:115] global_step/sec: 2.67785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.0161983e-06, step = 34300 (37.343 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 01:59:44.453139 139883003524864 tf_logging.py:115] loss = 6.0161983e-06, step = 34300 (37.343 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:00:21.801656 139883003524864 tf_logging.py:115] global_step/sec: 2.67732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.772374e-06, step = 34400 (37.351 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:00:21.804372 139883003524864 tf_logging.py:115] loss = 6.772374e-06, step = 34400 (37.351 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 34500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:00:58.758248 139883003524864 tf_logging.py:115] Saving checkpoints for 34500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:01:02.604183 139883003524864 tf_logging.py:115] global_step/sec: 2.45083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.6156183e-06, step = 34500 (40.803 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:01:02.607318 139883003524864 tf_logging.py:115] loss = 4.6156183e-06, step = 34500 (40.803 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:01:39.948548 139883003524864 tf_logging.py:115] global_step/sec: 2.67778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.6474846e-06, step = 34600 (37.343 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:01:39.950673 139883003524864 tf_logging.py:115] loss = 5.6474846e-06, step = 34600 (37.343 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:02:17.376637 139883003524864 tf_logging.py:115] global_step/sec: 2.67179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.7004375e-05, step = 34700 (37.428 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:02:17.378914 139883003524864 tf_logging.py:115] loss = 1.7004375e-05, step = 34700 (37.428 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:02:54.729009 139883003524864 tf_logging.py:115] global_step/sec: 2.67721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.9732275e-06, step = 34800 (37.352 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:02:54.731285 139883003524864 tf_logging.py:115] loss = 4.9732275e-06, step = 34800 (37.352 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:03:32.179294 139883003524864 tf_logging.py:115] global_step/sec: 2.6702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 8.150612e-06, step = 34900 (37.450 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:03:32.181456 139883003524864 tf_logging.py:115] loss = 8.150612e-06, step = 34900 (37.450 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 35000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:04:09.133866 139883003524864 tf_logging.py:115] Saving checkpoints for 35000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:04:13.091758 139883003524864 tf_logging.py:115] global_step/sec: 2.44424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.2484472e-06, step = 35000 (40.913 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:04:13.093997 139883003524864 tf_logging.py:115] loss = 3.2484472e-06, step = 35000 (40.913 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:04:50.467840 139883003524864 tf_logging.py:115] global_step/sec: 2.67551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.363931e-06, step = 35100 (37.376 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:04:50.469907 139883003524864 tf_logging.py:115] loss = 3.363931e-06, step = 35100 (37.376 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:05:27.747251 139883003524864 tf_logging.py:115] global_step/sec: 2.68245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.106887e-06, step = 35200 (37.280 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:05:27.749827 139883003524864 tf_logging.py:115] loss = 3.106887e-06, step = 35200 (37.280 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:06:05.108869 139883003524864 tf_logging.py:115] global_step/sec: 2.67655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.3846426e-06, step = 35300 (37.361 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:06:05.111247 139883003524864 tf_logging.py:115] loss = 4.3846426e-06, step = 35300 (37.361 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:06:42.515682 139883003524864 tf_logging.py:115] global_step/sec: 2.67331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.3569283e-06, step = 35400 (37.406 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:06:42.517564 139883003524864 tf_logging.py:115] loss = 5.3569283e-06, step = 35400 (37.406 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 35500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:07:19.455204 139883003524864 tf_logging.py:115] Saving checkpoints for 35500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:07:23.204360 139883003524864 tf_logging.py:115] global_step/sec: 2.45769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.6246981e-06, step = 35500 (40.689 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:07:23.206287 139883003524864 tf_logging.py:115] loss = 3.6246981e-06, step = 35500 (40.689 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:08:00.597996 139883003524864 tf_logging.py:115] global_step/sec: 2.67426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.7401824e-06, step = 35600 (37.394 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:08:00.600233 139883003524864 tf_logging.py:115] loss = 3.7401824e-06, step = 35600 (37.394 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:08:37.973726 139883003524864 tf_logging.py:115] global_step/sec: 2.67553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.2674723e-06, step = 35700 (37.376 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:08:37.976207 139883003524864 tf_logging.py:115] loss = 5.2674723e-06, step = 35700 (37.376 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:09:15.247084 139883003524864 tf_logging.py:115] global_step/sec: 2.68288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.860281e-06, step = 35800 (37.273 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:09:15.249289 139883003524864 tf_logging.py:115] loss = 9.860281e-06, step = 35800 (37.273 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:09:52.568626 139883003524864 tf_logging.py:115] global_step/sec: 2.67942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.5092157e-06, step = 35900 (37.322 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:09:52.571227 139883003524864 tf_logging.py:115] loss = 3.5092157e-06, step = 35900 (37.322 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 36000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:10:29.487935 139883003524864 tf_logging.py:115] Saving checkpoints for 36000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:10:33.246023 139883003524864 tf_logging.py:115] global_step/sec: 2.45837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.5986216e-06, step = 36000 (40.677 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:10:33.248136 139883003524864 tf_logging.py:115] loss = 3.5986216e-06, step = 36000 (40.677 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:11:10.582993 139883003524864 tf_logging.py:115] global_step/sec: 2.67831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.673481e-06, step = 36100 (37.337 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:11:10.585213 139883003524864 tf_logging.py:115] loss = 5.673481e-06, step = 36100 (37.337 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:11:47.932509 139883003524864 tf_logging.py:115] global_step/sec: 2.67742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.5895367e-06, step = 36200 (37.350 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:11:47.935670 139883003524864 tf_logging.py:115] loss = 4.5895367e-06, step = 36200 (37.350 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:12:25.227609 139883003524864 tf_logging.py:115] global_step/sec: 2.68132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.9392495e-06, step = 36300 (37.294 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:12:25.229524 139883003524864 tf_logging.py:115] loss = 2.9392495e-06, step = 36300 (37.294 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:13:02.615133 139883003524864 tf_logging.py:115] global_step/sec: 2.67469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.8349416e-06, step = 36400 (37.388 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:13:02.617189 139883003524864 tf_logging.py:115] loss = 2.8349416e-06, step = 36400 (37.388 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 36500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:13:39.628367 139883003524864 tf_logging.py:115] Saving checkpoints for 36500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:13:43.372838 139883003524864 tf_logging.py:115] global_step/sec: 2.45352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 6.3141833e-06, step = 36500 (40.758 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:13:43.374970 139883003524864 tf_logging.py:115] loss = 6.3141833e-06, step = 36500 (40.758 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:14:20.722293 139883003524864 tf_logging.py:115] global_step/sec: 2.67742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.8684694e-06, step = 36600 (37.351 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:14:20.725528 139883003524864 tf_logging.py:115] loss = 2.8684694e-06, step = 36600 (37.351 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:14:58.118352 139883003524864 tf_logging.py:115] global_step/sec: 2.67408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.8721934e-06, step = 36700 (37.395 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:14:58.120311 139883003524864 tf_logging.py:115] loss = 2.8721934e-06, step = 36700 (37.395 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:15:35.439695 139883003524864 tf_logging.py:115] global_step/sec: 2.67944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.3713804e-06, step = 36800 (37.321 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:15:35.441774 139883003524864 tf_logging.py:115] loss = 3.3713804e-06, step = 36800 (37.321 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:16:12.874644 139883003524864 tf_logging.py:115] global_step/sec: 2.6713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.9802277e-06, step = 36900 (37.435 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:16:12.877179 139883003524864 tf_logging.py:115] loss = 2.9802277e-06, step = 36900 (37.435 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 37000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:16:49.885927 139883003524864 tf_logging.py:115] Saving checkpoints for 37000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.4513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:16:53.669201 139883003524864 tf_logging.py:115] global_step/sec: 2.4513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.9765022e-06, step = 37000 (40.794 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:16:53.671534 139883003524864 tf_logging.py:115] loss = 2.9765022e-06, step = 37000 (40.794 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:17:31.020184 139883003524864 tf_logging.py:115] global_step/sec: 2.6773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.345303e-06, step = 37100 (37.351 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:17:31.022796 139883003524864 tf_logging.py:115] loss = 3.345303e-06, step = 37100 (37.351 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:18:08.388454 139883003524864 tf_logging.py:115] global_step/sec: 2.67607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.7588084e-06, step = 37200 (37.368 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:18:08.390756 139883003524864 tf_logging.py:115] loss = 3.7588084e-06, step = 37200 (37.368 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:18:45.663894 139883003524864 tf_logging.py:115] global_step/sec: 2.68273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.909447e-06, step = 37300 (37.275 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:18:45.665934 139883003524864 tf_logging.py:115] loss = 2.909447e-06, step = 37300 (37.275 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:19:23.003165 139883003524864 tf_logging.py:115] global_step/sec: 2.67815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.8482094e-06, step = 37400 (37.340 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:19:23.005473 139883003524864 tf_logging.py:115] loss = 3.8482094e-06, step = 37400 (37.340 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 37500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:20:00.072129 139883003524864 tf_logging.py:115] Saving checkpoints for 37500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:20:03.814209 139883003524864 tf_logging.py:115] global_step/sec: 2.45032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.9003685e-06, step = 37500 (40.811 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:20:03.816482 139883003524864 tf_logging.py:115] loss = 3.9003685e-06, step = 37500 (40.811 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:20:41.139413 139883003524864 tf_logging.py:115] global_step/sec: 2.67915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.1106106e-06, step = 37600 (37.325 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:20:41.141466 139883003524864 tf_logging.py:115] loss = 3.1106106e-06, step = 37600 (37.325 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:21:18.464888 139883003524864 tf_logging.py:115] global_step/sec: 2.67913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.4831373e-06, step = 37700 (37.325 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:21:18.466874 139883003524864 tf_logging.py:115] loss = 3.4831373e-06, step = 37700 (37.325 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:21:55.757453 139883003524864 tf_logging.py:115] global_step/sec: 2.68151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.479413e-06, step = 37800 (37.293 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:21:55.759809 139883003524864 tf_logging.py:115] loss = 3.479413e-06, step = 37800 (37.293 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:22:33.094184 139883003524864 tf_logging.py:115] global_step/sec: 2.67832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.993499e-06, step = 37900 (37.337 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:22:33.096571 139883003524864 tf_logging.py:115] loss = 3.993499e-06, step = 37900 (37.337 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 38000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:23:10.180871 139883003524864 tf_logging.py:115] Saving checkpoints for 38000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.44557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:23:13.984484 139883003524864 tf_logging.py:115] global_step/sec: 2.44557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.5278404e-06, step = 38000 (40.890 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:23:13.986602 139883003524864 tf_logging.py:115] loss = 3.5278404e-06, step = 38000 (40.890 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:23:51.461760 139883003524864 tf_logging.py:115] global_step/sec: 2.66829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.3064097e-06, step = 38100 (37.477 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:23:51.463636 139883003524864 tf_logging.py:115] loss = 4.3064097e-06, step = 38100 (37.477 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:24:28.770184 139883003524864 tf_logging.py:115] global_step/sec: 2.68036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0232883e-05, step = 38200 (37.309 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:24:28.772353 139883003524864 tf_logging.py:115] loss = 1.0232883e-05, step = 38200 (37.309 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:25:06.035564 139883003524864 tf_logging.py:115] global_step/sec: 2.68346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.4651952e-05, step = 38300 (37.265 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:25:06.037638 139883003524864 tf_logging.py:115] loss = 3.4651952e-05, step = 38300 (37.265 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:25:43.447127 139883003524864 tf_logging.py:115] global_step/sec: 2.67297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.1813897e-06, step = 38400 (37.412 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:25:43.449235 139883003524864 tf_logging.py:115] loss = 3.1813897e-06, step = 38400 (37.412 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 38500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:26:20.396431 139883003524864 tf_logging.py:115] Saving checkpoints for 38500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.4617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:26:24.069496 139883003524864 tf_logging.py:115] global_step/sec: 2.4617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.1664904e-06, step = 38500 (40.623 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:26:24.072013 139883003524864 tf_logging.py:115] loss = 3.1664904e-06, step = 38500 (40.623 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:27:01.474923 139883003524864 tf_logging.py:115] global_step/sec: 2.67341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.7306337e-06, step = 38600 (37.405 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:27:01.476929 139883003524864 tf_logging.py:115] loss = 2.7306337e-06, step = 38600 (37.405 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:27:38.758592 139883003524864 tf_logging.py:115] global_step/sec: 2.68214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.9094467e-06, step = 38700 (37.284 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:27:38.760451 139883003524864 tf_logging.py:115] loss = 2.9094467e-06, step = 38700 (37.284 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:28:16.030373 139883003524864 tf_logging.py:115] global_step/sec: 2.683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.0063038e-06, step = 38800 (37.272 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:28:16.032712 139883003524864 tf_logging.py:115] loss = 3.0063038e-06, step = 38800 (37.272 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:28:53.338574 139883003524864 tf_logging.py:115] global_step/sec: 2.68038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.3263989e-05, step = 38900 (37.309 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:28:53.341220 139883003524864 tf_logging.py:115] loss = 1.3263989e-05, step = 38900 (37.309 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 39000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:29:30.297280 139883003524864 tf_logging.py:115] Saving checkpoints for 39000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.38843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:29:35.207120 139883003524864 tf_logging.py:115] global_step/sec: 2.38843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.8423922e-06, step = 39000 (41.868 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:29:35.209668 139883003524864 tf_logging.py:115] loss = 2.8423922e-06, step = 39000 (41.868 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.6711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:30:12.644918 139883003524864 tf_logging.py:115] global_step/sec: 2.6711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.058456e-06, step = 39100 (37.438 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:30:12.647387 139883003524864 tf_logging.py:115] loss = 3.058456e-06, step = 39100 (37.438 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:30:49.992774 139883003524864 tf_logging.py:115] global_step/sec: 2.67753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.4682366e-06, step = 39200 (37.347 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:30:49.994844 139883003524864 tf_logging.py:115] loss = 3.4682366e-06, step = 39200 (37.347 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:31:27.390766 139883003524864 tf_logging.py:115] global_step/sec: 2.67394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.140825e-06, step = 39300 (37.398 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:31:27.392621 139883003524864 tf_logging.py:115] loss = 5.140825e-06, step = 39300 (37.398 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:32:04.718952 139883003524864 tf_logging.py:115] global_step/sec: 2.67894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.8817407e-06, step = 39400 (37.328 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:32:04.720972 139883003524864 tf_logging.py:115] loss = 3.8817407e-06, step = 39400 (37.328 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 39500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:32:41.643833 139883003524864 tf_logging.py:115] Saving checkpoints for 39500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:32:45.299296 139883003524864 tf_logging.py:115] global_step/sec: 2.46424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.8759189e-06, step = 39500 (40.580 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:32:45.301308 139883003524864 tf_logging.py:115] loss = 2.8759189e-06, step = 39500 (40.580 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:33:22.589743 139883003524864 tf_logging.py:115] global_step/sec: 2.68165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.0361057e-06, step = 39600 (37.292 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:33:22.593232 139883003524864 tf_logging.py:115] loss = 3.0361057e-06, step = 39600 (37.292 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:33:59.932989 139883003524864 tf_logging.py:115] global_step/sec: 2.67786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.5948924e-06, step = 39700 (37.342 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:33:59.935096 139883003524864 tf_logging.py:115] loss = 3.5948924e-06, step = 39700 (37.342 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:34:37.219278 139883003524864 tf_logging.py:115] global_step/sec: 2.68195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.2447194e-06, step = 39800 (37.286 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:34:37.221497 139883003524864 tf_logging.py:115] loss = 3.2447194e-06, step = 39800 (37.286 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.68266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:35:14.495668 139883003524864 tf_logging.py:115] global_step/sec: 2.68266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.1329623e-06, step = 39900 (37.276 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:35:14.497902 139883003524864 tf_logging.py:115] loss = 3.1329623e-06, step = 39900 (37.276 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 40000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:35:51.439508 139883003524864 tf_logging.py:115] Saving checkpoints for 40000 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:35:55.096262 139883003524864 tf_logging.py:115] global_step/sec: 2.46302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.8796449e-06, step = 40000 (40.600 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:35:55.098415 139883003524864 tf_logging.py:115] loss = 2.8796449e-06, step = 40000 (40.600 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:36:32.492406 139883003524864 tf_logging.py:115] global_step/sec: 2.67407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.3572355e-06, step = 40100 (37.396 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:36:32.494339 139883003524864 tf_logging.py:115] loss = 7.3572355e-06, step = 40100 (37.396 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.66649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:37:09.994932 139883003524864 tf_logging.py:115] global_step/sec: 2.66649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.7357903e-05, step = 40200 (37.503 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:37:09.997335 139883003524864 tf_logging.py:115] loss = 1.7357903e-05, step = 40200 (37.503 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:37:47.326585 139883003524864 tf_logging.py:115] global_step/sec: 2.67869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.7703055e-06, step = 40300 (37.334 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:37:47.330978 139883003524864 tf_logging.py:115] loss = 5.7703055e-06, step = 40300 (37.334 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.67834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:38:24.663178 139883003524864 tf_logging.py:115] global_step/sec: 2.67834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.7588075e-06, step = 40400 (37.335 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:38:24.665593 139883003524864 tf_logging.py:115] loss = 3.7588075e-06, step = 40400 (37.335 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 40500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:39:01.631488 139883003524864 tf_logging.py:115] Saving checkpoints for 40500 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.45393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:39:05.414192 139883003524864 tf_logging.py:115] global_step/sec: 2.45393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.0361057e-06, step = 40500 (40.751 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:39:05.416590 139883003524864 tf_logging.py:115] loss = 3.0361057e-06, step = 40500 (40.751 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 40540 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:39:19.952416 139883003524864 tf_logging.py:115] Saving checkpoints for 40540 into bert_new_prepositions/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 3.043557e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 02:39:24.187605 139883003524864 tf_logging.py:115] Loss for final step: 3.043557e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took time  4:18:52.397762\n"
     ]
    }
   ],
   "source": [
    "print('Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    with tf.device('/gpu:0'):\n",
    "        estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "God help me.\n"
     ]
    }
   ],
   "source": [
    "print(\"God help me.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6Nukby2EB6-"
   },
   "source": [
    "Now we train our model! For me, using a Colab notebook running on Google's GPUs, my training time was about 14 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CmbLTVniARy3"
   },
   "source": [
    "Now let's use our test data to see how well our model did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIhejfpyJ8Bx"
   },
   "outputs": [],
   "source": [
    "test_input_fn = run_classifier.input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "colab_type": "code",
    "id": "PPVEXhNjYXC-",
    "outputId": "42dde0bd-1a75-4779-d071-219982498fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:57:07.697016 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:57:11.744238 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n",
      "/home/ivantorubarov/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:57:25.274677 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-05-09-06:57:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:57:25.297378 140552650831616 tf_logging.py:115] Starting evaluation at 2019-05-09-06:57:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:57:26.773633 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:57:26.780099 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:57:30.340137 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:57:30.598232 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-05-09-06:58:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:58:23.477437 140552650831616 tf_logging.py:115] Finished evaluation at 2019-05-09-06:58:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 40540: auc = 0.68536246, eval_accuracy = 0.95160574, f1_score = 0.49614787, false_negatives = 523.0, false_positives = 131.0, global_step = 40540, loss = 0.5112707, precision = 0.7108168, recall = 0.3810651, true_negatives = 12538.0, true_positives = 322.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:58:23.480092 140552650831616 tf_logging.py:115] Saving dict for global step 40540: auc = 0.68536246, eval_accuracy = 0.95160574, f1_score = 0.49614787, false_negatives = 523.0, false_positives = 131.0, global_step = 40540, loss = 0.5112707, precision = 0.7108168, recall = 0.3810651, true_negatives = 12538.0, true_positives = 322.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40540: bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:58:26.319608 140552650831616 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 40540: bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.68536246,\n",
       " 'eval_accuracy': 0.95160574,\n",
       " 'f1_score': 0.49614787,\n",
       " 'false_negatives': 523.0,\n",
       " 'false_positives': 131.0,\n",
       " 'global_step': 40540,\n",
       " 'loss': 0.5112707,\n",
       " 'precision': 0.7108168,\n",
       " 'recall': 0.3810651,\n",
       " 'true_negatives': 12538.0,\n",
       " 'true_positives': 322.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=test_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uettEz32yqIN"
   },
   "source": [
    "#Extracting the trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ueKsULteiz1B"
   },
   "source": [
    "Now let's save our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "OsrbTD2EJTVl"
   },
   "outputs": [],
   "source": [
    "def getPrediction(in_sentences):\n",
    "  labels = [\"Not an error\", \"Is an error\"]\n",
    "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x[0], text_b = x[1], label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
    "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "  predictions = estimator.predict(predict_input_fn)\n",
    "  return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "4CbCTzuk3SL9",
    "outputId": "a1a9ae96-16cd-4d96-ede0-dedeadcc0bc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/ivantorubarov/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/ivantorubarov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "nltk.download('perluniprops')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iPJwPeOa80Qc"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "from nltk.tokenize.moses import MosesDetokenizer\n",
    "detokenizer = MosesDetokenizer()\n",
    "\n",
    "def annotate(text):\n",
    "  current_time = datetime.now()\n",
    "  raw = text\n",
    "  raw = re.sub(r'\\s', ' ', raw)\n",
    "  raw = re.sub(r'( )+', ' ', raw)\n",
    "  sentences = nltk.sent_tokenize(raw)\n",
    "  wordsoup = []\n",
    "  annotation_set = []\n",
    "  checking_ids = []\n",
    "  tokens = []\n",
    "  J = 0\n",
    "  for sentence in sentences:\n",
    "    wordsoup.append(tknzr.tokenize(sentence))\n",
    "  for i in range(len(wordsoup)):\n",
    "    tokenized_sentence = wordsoup[i]\n",
    "    for j in range(len(tokenized_sentence)):\n",
    "      token = tokenized_sentence[j]\n",
    "      if not re.search(r'[a-zA-Z]', token):\n",
    "        tokens.append([token, 0])\n",
    "      else:\n",
    "        tokens.append([token, None])\n",
    "        substring = token\n",
    "        si = i-2\n",
    "        if si < 0:\n",
    "          si = 0\n",
    "        detokenizing_string = wordsoup[si:i] + [tokenized_sentence[:j] + ['[MASK]'] + tokenized_sentence[j+1:]] + wordsoup[i+1:i+3]\n",
    "        detokenizing_string = [item for sublist in detokenizing_string for item in sublist]\n",
    "        entry = detokenizer.detokenize(detokenizing_string, return_str=True)\n",
    "        annotation_set.append([entry, substring])\n",
    "        checking_ids.append(J)\n",
    "      J += 1\n",
    "  predictions = getPrediction(annotation_set[:128])\n",
    "  for p in range(len(predictions)):\n",
    "    if predictions[p][-1] == 'Is an error':\n",
    "      tokens[checking_ids[p]][1] = 1\n",
    "    else:\n",
    "      tokens[checking_ids[p]][1] = 0\n",
    "  print('\\n')\n",
    "  print(\"Annotation took time \", datetime.now() - current_time)\n",
    "  return tokens\n",
    "\n",
    "def print_annotated_webpage(tokens, title):\n",
    "  out = '<html>\\n<head>\\n<title>'+title+'</title>\\n<meta charset=\"utf-8\">\\n<style type=\"text/css\">\\n.blue {\\n\\tbackground: #a8d1ff;\\n\\tdisplay: inline-block;\\n}\\n</style>\\n</head>\\n<body>'\n",
    "  outsoup = []\n",
    "  for token in tokens:\n",
    "    if token[1] == 1:\n",
    "      token[0] = '<div class=\"blue\">'+token[0]+'</div>'\n",
    "    outsoup.append(token[0])\n",
    "  bodystring = detokenizer.detokenize(outsoup, return_str=True)\n",
    "  out += bodystring\n",
    "  out += '</body>\\n</html>'\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4085
    },
    "colab_type": "code",
    "id": "lrnyWIYaCNng",
    "outputId": "2a4f3799-82a7-492f-9320-576077dde269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.096188 140552650831616 tf_logging.py:115] Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.099165 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.101068 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [MASK] is strongly believed that some subject in universities are hard explain and understand for female students and there should be more boys to study specific areas of science . However , some people believe that women can benefit to various subjects in many ways . On the one hand , the number of male students is very important for universities . [SEP] It [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.102649 140552650831616 tf_logging.py:115] tokens: [CLS] [MASK] is strongly believed that some subject in universities are hard explain and understand for female students and there should be more boys to study specific areas of science . However , some people believe that women can benefit to various subjects in many ways . On the one hand , the number of male students is very important for universities . [SEP] It [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 103 1110 5473 2475 1115 1199 2548 1107 5659 1132 1662 4137 1105 2437 1111 2130 1651 1105 1175 1431 1129 1167 3287 1106 2025 2747 1877 1104 2598 119 1438 117 1199 1234 2059 1115 1535 1169 5257 1106 1672 5174 1107 1242 3242 119 1212 1103 1141 1289 117 1103 1295 1104 2581 1651 1110 1304 1696 1111 5659 119 102 1135 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.104204 140552650831616 tf_logging.py:115] input_ids: 101 103 1110 5473 2475 1115 1199 2548 1107 5659 1132 1662 4137 1105 2437 1111 2130 1651 1105 1175 1431 1129 1167 3287 1106 2025 2747 1877 1104 2598 119 1438 117 1199 1234 2059 1115 1535 1169 5257 1106 1672 5174 1107 1242 3242 119 1212 1103 1141 1289 117 1103 1295 1104 2581 1651 1110 1304 1696 1111 5659 119 102 1135 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.105637 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.107298 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.108611 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.111066 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.112254 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] It [MASK] strongly believed that some subject in universities are hard explain and understand for female students and there should be more boys to study specific areas of science . However , some people believe that women can benefit to various subjects in many ways . On the one hand , the number of male students is very important for universities . [SEP] is [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.113696 140552650831616 tf_logging.py:115] tokens: [CLS] It [MASK] strongly believed that some subject in universities are hard explain and understand for female students and there should be more boys to study specific areas of science . However , some people believe that women can benefit to various subjects in many ways . On the one hand , the number of male students is very important for universities . [SEP] is [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1135 103 5473 2475 1115 1199 2548 1107 5659 1132 1662 4137 1105 2437 1111 2130 1651 1105 1175 1431 1129 1167 3287 1106 2025 2747 1877 1104 2598 119 1438 117 1199 1234 2059 1115 1535 1169 5257 1106 1672 5174 1107 1242 3242 119 1212 1103 1141 1289 117 1103 1295 1104 2581 1651 1110 1304 1696 1111 5659 119 102 1110 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.115145 140552650831616 tf_logging.py:115] input_ids: 101 1135 103 5473 2475 1115 1199 2548 1107 5659 1132 1662 4137 1105 2437 1111 2130 1651 1105 1175 1431 1129 1167 3287 1106 2025 2747 1877 1104 2598 119 1438 117 1199 1234 2059 1115 1535 1169 5257 1106 1672 5174 1107 1242 3242 119 1212 1103 1141 1289 117 1103 1295 1104 2581 1651 1110 1304 1696 1111 5659 119 102 1110 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.116724 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.118162 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.119570 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.122136 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.123408 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] It is [MASK] believed that some subject in universities are hard explain and understand for female students and there should be more boys to study specific areas of science . However , some people believe that women can benefit to various subjects in many ways . On the one hand , the number of male students is very important for universities . [SEP] strongly [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.124673 140552650831616 tf_logging.py:115] tokens: [CLS] It is [MASK] believed that some subject in universities are hard explain and understand for female students and there should be more boys to study specific areas of science . However , some people believe that women can benefit to various subjects in many ways . On the one hand , the number of male students is very important for universities . [SEP] strongly [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1135 1110 103 2475 1115 1199 2548 1107 5659 1132 1662 4137 1105 2437 1111 2130 1651 1105 1175 1431 1129 1167 3287 1106 2025 2747 1877 1104 2598 119 1438 117 1199 1234 2059 1115 1535 1169 5257 1106 1672 5174 1107 1242 3242 119 1212 1103 1141 1289 117 1103 1295 1104 2581 1651 1110 1304 1696 1111 5659 119 102 5473 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.126106 140552650831616 tf_logging.py:115] input_ids: 101 1135 1110 103 2475 1115 1199 2548 1107 5659 1132 1662 4137 1105 2437 1111 2130 1651 1105 1175 1431 1129 1167 3287 1106 2025 2747 1877 1104 2598 119 1438 117 1199 1234 2059 1115 1535 1169 5257 1106 1672 5174 1107 1242 3242 119 1212 1103 1141 1289 117 1103 1295 1104 2581 1651 1110 1304 1696 1111 5659 119 102 5473 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.127619 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.128844 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.130269 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.132815 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.134089 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] It is strongly [MASK] that some subject in universities are hard explain and understand for female students and there should be more boys to study specific areas of science . However , some people believe that women can benefit to various subjects in many ways . On the one hand , the number of male students is very important for universities . [SEP] believed [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.135317 140552650831616 tf_logging.py:115] tokens: [CLS] It is strongly [MASK] that some subject in universities are hard explain and understand for female students and there should be more boys to study specific areas of science . However , some people believe that women can benefit to various subjects in many ways . On the one hand , the number of male students is very important for universities . [SEP] believed [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1135 1110 5473 103 1115 1199 2548 1107 5659 1132 1662 4137 1105 2437 1111 2130 1651 1105 1175 1431 1129 1167 3287 1106 2025 2747 1877 1104 2598 119 1438 117 1199 1234 2059 1115 1535 1169 5257 1106 1672 5174 1107 1242 3242 119 1212 1103 1141 1289 117 1103 1295 1104 2581 1651 1110 1304 1696 1111 5659 119 102 2475 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.136724 140552650831616 tf_logging.py:115] input_ids: 101 1135 1110 5473 103 1115 1199 2548 1107 5659 1132 1662 4137 1105 2437 1111 2130 1651 1105 1175 1431 1129 1167 3287 1106 2025 2747 1877 1104 2598 119 1438 117 1199 1234 2059 1115 1535 1169 5257 1106 1672 5174 1107 1242 3242 119 1212 1103 1141 1289 117 1103 1295 1104 2581 1651 1110 1304 1696 1111 5659 119 102 2475 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.137944 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.139402 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.140953 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.143393 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.144831 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] It is strongly believed [MASK] some subject in universities are hard explain and understand for female students and there should be more boys to study specific areas of science . However , some people believe that women can benefit to various subjects in many ways . On the one hand , the number of male students is very important for universities . [SEP] that [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.146067 140552650831616 tf_logging.py:115] tokens: [CLS] It is strongly believed [MASK] some subject in universities are hard explain and understand for female students and there should be more boys to study specific areas of science . However , some people believe that women can benefit to various subjects in many ways . On the one hand , the number of male students is very important for universities . [SEP] that [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1135 1110 5473 2475 103 1199 2548 1107 5659 1132 1662 4137 1105 2437 1111 2130 1651 1105 1175 1431 1129 1167 3287 1106 2025 2747 1877 1104 2598 119 1438 117 1199 1234 2059 1115 1535 1169 5257 1106 1672 5174 1107 1242 3242 119 1212 1103 1141 1289 117 1103 1295 1104 2581 1651 1110 1304 1696 1111 5659 119 102 1115 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.147730 140552650831616 tf_logging.py:115] input_ids: 101 1135 1110 5473 2475 103 1199 2548 1107 5659 1132 1662 4137 1105 2437 1111 2130 1651 1105 1175 1431 1129 1167 3287 1106 2025 2747 1877 1104 2598 119 1438 117 1199 1234 2059 1115 1535 1169 5257 1106 1672 5174 1107 1242 3242 119 1212 1103 1141 1289 117 1103 1295 1104 2581 1651 1110 1304 1696 1111 5659 119 102 1115 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.149089 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.150421 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.151883 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:52.436449 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:55.779552 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:55.926868 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:56.448431 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:56.452128 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:57.128863 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:57.190499 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotation took time  0:00:07.942542\n",
      "INFO:tensorflow:Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.611118 140552650831616 tf_logging.py:115] Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.613545 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.615041 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [MASK] pay chart give information about the transportation of goods between countries in Eastern Europe . As it is evidence from the chart there were two types goods transported : by rail and by road . The largest number of goods transported by rail were metals . [SEP] The [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.616222 140552650831616 tf_logging.py:115] tokens: [CLS] [MASK] pay chart give information about the transportation of goods between countries in Eastern Europe . As it is evidence from the chart there were two types goods transported : by rail and by road . The largest number of goods transported by rail were metals . [SEP] The [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 103 2653 3481 1660 1869 1164 1103 6312 1104 4817 1206 2182 1107 2882 1980 119 1249 1122 1110 2554 1121 1103 3481 1175 1127 1160 3322 4817 9470 131 1118 4356 1105 1118 1812 119 1109 2026 1295 1104 4817 9470 1118 4356 1127 13237 119 102 1109 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.617793 140552650831616 tf_logging.py:115] input_ids: 101 103 2653 3481 1660 1869 1164 1103 6312 1104 4817 1206 2182 1107 2882 1980 119 1249 1122 1110 2554 1121 1103 3481 1175 1127 1160 3322 4817 9470 131 1118 4356 1105 1118 1812 119 1109 2026 1295 1104 4817 9470 1118 4356 1127 13237 119 102 1109 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.619277 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.620600 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.621856 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.624479 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.625827 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The [MASK] chart give information about the transportation of goods between countries in Eastern Europe . As it is evidence from the chart there were two types goods transported : by rail and by road . The largest number of goods transported by rail were metals . [SEP] pay [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.627657 140552650831616 tf_logging.py:115] tokens: [CLS] The [MASK] chart give information about the transportation of goods between countries in Eastern Europe . As it is evidence from the chart there were two types goods transported : by rail and by road . The largest number of goods transported by rail were metals . [SEP] pay [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 103 3481 1660 1869 1164 1103 6312 1104 4817 1206 2182 1107 2882 1980 119 1249 1122 1110 2554 1121 1103 3481 1175 1127 1160 3322 4817 9470 131 1118 4356 1105 1118 1812 119 1109 2026 1295 1104 4817 9470 1118 4356 1127 13237 119 102 2653 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.628993 140552650831616 tf_logging.py:115] input_ids: 101 1109 103 3481 1660 1869 1164 1103 6312 1104 4817 1206 2182 1107 2882 1980 119 1249 1122 1110 2554 1121 1103 3481 1175 1127 1160 3322 4817 9470 131 1118 4356 1105 1118 1812 119 1109 2026 1295 1104 4817 9470 1118 4356 1127 13237 119 102 2653 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.630682 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.632036 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.633262 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.635381 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.637101 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The pay [MASK] give information about the transportation of goods between countries in Eastern Europe . As it is evidence from the chart there were two types goods transported : by rail and by road . The largest number of goods transported by rail were metals . [SEP] chart [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.639030 140552650831616 tf_logging.py:115] tokens: [CLS] The pay [MASK] give information about the transportation of goods between countries in Eastern Europe . As it is evidence from the chart there were two types goods transported : by rail and by road . The largest number of goods transported by rail were metals . [SEP] chart [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 2653 103 1660 1869 1164 1103 6312 1104 4817 1206 2182 1107 2882 1980 119 1249 1122 1110 2554 1121 1103 3481 1175 1127 1160 3322 4817 9470 131 1118 4356 1105 1118 1812 119 1109 2026 1295 1104 4817 9470 1118 4356 1127 13237 119 102 3481 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.640962 140552650831616 tf_logging.py:115] input_ids: 101 1109 2653 103 1660 1869 1164 1103 6312 1104 4817 1206 2182 1107 2882 1980 119 1249 1122 1110 2554 1121 1103 3481 1175 1127 1160 3322 4817 9470 131 1118 4356 1105 1118 1812 119 1109 2026 1295 1104 4817 9470 1118 4356 1127 13237 119 102 3481 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.642670 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.644614 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.646128 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.648117 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.649857 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The pay chart [MASK] information about the transportation of goods between countries in Eastern Europe . As it is evidence from the chart there were two types goods transported : by rail and by road . The largest number of goods transported by rail were metals . [SEP] give [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.651587 140552650831616 tf_logging.py:115] tokens: [CLS] The pay chart [MASK] information about the transportation of goods between countries in Eastern Europe . As it is evidence from the chart there were two types goods transported : by rail and by road . The largest number of goods transported by rail were metals . [SEP] give [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 2653 3481 103 1869 1164 1103 6312 1104 4817 1206 2182 1107 2882 1980 119 1249 1122 1110 2554 1121 1103 3481 1175 1127 1160 3322 4817 9470 131 1118 4356 1105 1118 1812 119 1109 2026 1295 1104 4817 9470 1118 4356 1127 13237 119 102 1660 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.652939 140552650831616 tf_logging.py:115] input_ids: 101 1109 2653 3481 103 1869 1164 1103 6312 1104 4817 1206 2182 1107 2882 1980 119 1249 1122 1110 2554 1121 1103 3481 1175 1127 1160 3322 4817 9470 131 1118 4356 1105 1118 1812 119 1109 2026 1295 1104 4817 9470 1118 4356 1127 13237 119 102 1660 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.654239 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.655827 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.657004 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.659013 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.660316 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The pay chart give [MASK] about the transportation of goods between countries in Eastern Europe . As it is evidence from the chart there were two types goods transported : by rail and by road . The largest number of goods transported by rail were metals . [SEP] information [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.662040 140552650831616 tf_logging.py:115] tokens: [CLS] The pay chart give [MASK] about the transportation of goods between countries in Eastern Europe . As it is evidence from the chart there were two types goods transported : by rail and by road . The largest number of goods transported by rail were metals . [SEP] information [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 2653 3481 1660 103 1164 1103 6312 1104 4817 1206 2182 1107 2882 1980 119 1249 1122 1110 2554 1121 1103 3481 1175 1127 1160 3322 4817 9470 131 1118 4356 1105 1118 1812 119 1109 2026 1295 1104 4817 9470 1118 4356 1127 13237 119 102 1869 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.663469 140552650831616 tf_logging.py:115] input_ids: 101 1109 2653 3481 1660 103 1164 1103 6312 1104 4817 1206 2182 1107 2882 1980 119 1249 1122 1110 2554 1121 1103 3481 1175 1127 1160 3322 4817 9470 131 1118 4356 1105 1118 1812 119 1109 2026 1295 1104 4817 9470 1118 4356 1127 13237 119 102 1869 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.664895 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.666213 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.667549 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 06:59:58.884044 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:02.722996 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:02.888209 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:03.393251 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:03.398240 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:04.144170 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:04.206970 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotation took time  0:00:07.126727\n",
      "INFO:tensorflow:Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:05.990275 140552650831616 tf_logging.py:115] Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:05.993638 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:05.995679 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [MASK] linear graph demonstrates the development of number of senior citizens in three countries throughout a century . There are some interesting facts concerning the population of people aged 65 and over in Japan , Sweden and the USA in the period between 1940 and 204 ##0 . The overall trend in each country is upward , though there is one exception to this which occur ##ed in Japan and lasted from 1940 till the beginning of 21st century . [SEP] The [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:05.997506 140552650831616 tf_logging.py:115] tokens: [CLS] [MASK] linear graph demonstrates the development of number of senior citizens in three countries throughout a century . There are some interesting facts concerning the population of people aged 65 and over in Japan , Sweden and the USA in the period between 1940 and 204 ##0 . The overall trend in each country is upward , though there is one exception to this which occur ##ed in Japan and lasted from 1940 till the beginning of 21st century . [SEP] The [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 103 7378 10873 17798 1103 1718 1104 1295 1104 2682 4037 1107 1210 2182 2032 170 1432 119 1247 1132 1199 5426 9193 6995 1103 1416 1104 1234 4079 2625 1105 1166 1107 1999 117 3865 1105 1103 3066 1107 1103 1669 1206 3020 1105 21355 1568 119 1109 2905 10209 1107 1296 1583 1110 10828 117 1463 1175 1110 1141 5856 1106 1142 1134 4467 1174 1107 1999 1105 5695 1121 3020 6174 1103 2150 1104 6880 1432 119 102 1109 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.000201 140552650831616 tf_logging.py:115] input_ids: 101 103 7378 10873 17798 1103 1718 1104 1295 1104 2682 4037 1107 1210 2182 2032 170 1432 119 1247 1132 1199 5426 9193 6995 1103 1416 1104 1234 4079 2625 1105 1166 1107 1999 117 3865 1105 1103 3066 1107 1103 1669 1206 3020 1105 21355 1568 119 1109 2905 10209 1107 1296 1583 1110 10828 117 1463 1175 1110 1141 5856 1106 1142 1134 4467 1174 1107 1999 1105 5695 1121 3020 6174 1103 2150 1104 6880 1432 119 102 1109 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.002002 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.003687 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.005467 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.008708 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.010552 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The [MASK] graph demonstrates the development of number of senior citizens in three countries throughout a century . There are some interesting facts concerning the population of people aged 65 and over in Japan , Sweden and the USA in the period between 1940 and 204 ##0 . The overall trend in each country is upward , though there is one exception to this which occur ##ed in Japan and lasted from 1940 till the beginning of 21st century . [SEP] linear [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.012223 140552650831616 tf_logging.py:115] tokens: [CLS] The [MASK] graph demonstrates the development of number of senior citizens in three countries throughout a century . There are some interesting facts concerning the population of people aged 65 and over in Japan , Sweden and the USA in the period between 1940 and 204 ##0 . The overall trend in each country is upward , though there is one exception to this which occur ##ed in Japan and lasted from 1940 till the beginning of 21st century . [SEP] linear [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 103 10873 17798 1103 1718 1104 1295 1104 2682 4037 1107 1210 2182 2032 170 1432 119 1247 1132 1199 5426 9193 6995 1103 1416 1104 1234 4079 2625 1105 1166 1107 1999 117 3865 1105 1103 3066 1107 1103 1669 1206 3020 1105 21355 1568 119 1109 2905 10209 1107 1296 1583 1110 10828 117 1463 1175 1110 1141 5856 1106 1142 1134 4467 1174 1107 1999 1105 5695 1121 3020 6174 1103 2150 1104 6880 1432 119 102 7378 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.013900 140552650831616 tf_logging.py:115] input_ids: 101 1109 103 10873 17798 1103 1718 1104 1295 1104 2682 4037 1107 1210 2182 2032 170 1432 119 1247 1132 1199 5426 9193 6995 1103 1416 1104 1234 4079 2625 1105 1166 1107 1999 117 3865 1105 1103 3066 1107 1103 1669 1206 3020 1105 21355 1568 119 1109 2905 10209 1107 1296 1583 1110 10828 117 1463 1175 1110 1141 5856 1106 1142 1134 4467 1174 1107 1999 1105 5695 1121 3020 6174 1103 2150 1104 6880 1432 119 102 7378 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.015709 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.017416 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.019100 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.022183 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.023936 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The linear [MASK] demonstrates the development of number of senior citizens in three countries throughout a century . There are some interesting facts concerning the population of people aged 65 and over in Japan , Sweden and the USA in the period between 1940 and 204 ##0 . The overall trend in each country is upward , though there is one exception to this which occur ##ed in Japan and lasted from 1940 till the beginning of 21st century . [SEP] graph [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.025777 140552650831616 tf_logging.py:115] tokens: [CLS] The linear [MASK] demonstrates the development of number of senior citizens in three countries throughout a century . There are some interesting facts concerning the population of people aged 65 and over in Japan , Sweden and the USA in the period between 1940 and 204 ##0 . The overall trend in each country is upward , though there is one exception to this which occur ##ed in Japan and lasted from 1940 till the beginning of 21st century . [SEP] graph [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 7378 103 17798 1103 1718 1104 1295 1104 2682 4037 1107 1210 2182 2032 170 1432 119 1247 1132 1199 5426 9193 6995 1103 1416 1104 1234 4079 2625 1105 1166 1107 1999 117 3865 1105 1103 3066 1107 1103 1669 1206 3020 1105 21355 1568 119 1109 2905 10209 1107 1296 1583 1110 10828 117 1463 1175 1110 1141 5856 1106 1142 1134 4467 1174 1107 1999 1105 5695 1121 3020 6174 1103 2150 1104 6880 1432 119 102 10873 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.027691 140552650831616 tf_logging.py:115] input_ids: 101 1109 7378 103 17798 1103 1718 1104 1295 1104 2682 4037 1107 1210 2182 2032 170 1432 119 1247 1132 1199 5426 9193 6995 1103 1416 1104 1234 4079 2625 1105 1166 1107 1999 117 3865 1105 1103 3066 1107 1103 1669 1206 3020 1105 21355 1568 119 1109 2905 10209 1107 1296 1583 1110 10828 117 1463 1175 1110 1141 5856 1106 1142 1134 4467 1174 1107 1999 1105 5695 1121 3020 6174 1103 2150 1104 6880 1432 119 102 10873 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.029585 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.031444 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.033108 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.036355 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.037926 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The linear graph [MASK] the development of number of senior citizens in three countries throughout a century . There are some interesting facts concerning the population of people aged 65 and over in Japan , Sweden and the USA in the period between 1940 and 204 ##0 . The overall trend in each country is upward , though there is one exception to this which occur ##ed in Japan and lasted from 1940 till the beginning of 21st century . [SEP] demonstrates [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.039318 140552650831616 tf_logging.py:115] tokens: [CLS] The linear graph [MASK] the development of number of senior citizens in three countries throughout a century . There are some interesting facts concerning the population of people aged 65 and over in Japan , Sweden and the USA in the period between 1940 and 204 ##0 . The overall trend in each country is upward , though there is one exception to this which occur ##ed in Japan and lasted from 1940 till the beginning of 21st century . [SEP] demonstrates [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 7378 10873 103 1103 1718 1104 1295 1104 2682 4037 1107 1210 2182 2032 170 1432 119 1247 1132 1199 5426 9193 6995 1103 1416 1104 1234 4079 2625 1105 1166 1107 1999 117 3865 1105 1103 3066 1107 1103 1669 1206 3020 1105 21355 1568 119 1109 2905 10209 1107 1296 1583 1110 10828 117 1463 1175 1110 1141 5856 1106 1142 1134 4467 1174 1107 1999 1105 5695 1121 3020 6174 1103 2150 1104 6880 1432 119 102 17798 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.040588 140552650831616 tf_logging.py:115] input_ids: 101 1109 7378 10873 103 1103 1718 1104 1295 1104 2682 4037 1107 1210 2182 2032 170 1432 119 1247 1132 1199 5426 9193 6995 1103 1416 1104 1234 4079 2625 1105 1166 1107 1999 117 3865 1105 1103 3066 1107 1103 1669 1206 3020 1105 21355 1568 119 1109 2905 10209 1107 1296 1583 1110 10828 117 1463 1175 1110 1141 5856 1106 1142 1134 4467 1174 1107 1999 1105 5695 1121 3020 6174 1103 2150 1104 6880 1432 119 102 17798 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.042005 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.043773 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.044912 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.047503 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.049104 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The linear graph demonstrates [MASK] development of number of senior citizens in three countries throughout a century . There are some interesting facts concerning the population of people aged 65 and over in Japan , Sweden and the USA in the period between 1940 and 204 ##0 . The overall trend in each country is upward , though there is one exception to this which occur ##ed in Japan and lasted from 1940 till the beginning of 21st century . [SEP] the [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.050336 140552650831616 tf_logging.py:115] tokens: [CLS] The linear graph demonstrates [MASK] development of number of senior citizens in three countries throughout a century . There are some interesting facts concerning the population of people aged 65 and over in Japan , Sweden and the USA in the period between 1940 and 204 ##0 . The overall trend in each country is upward , though there is one exception to this which occur ##ed in Japan and lasted from 1940 till the beginning of 21st century . [SEP] the [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 7378 10873 17798 103 1718 1104 1295 1104 2682 4037 1107 1210 2182 2032 170 1432 119 1247 1132 1199 5426 9193 6995 1103 1416 1104 1234 4079 2625 1105 1166 1107 1999 117 3865 1105 1103 3066 1107 1103 1669 1206 3020 1105 21355 1568 119 1109 2905 10209 1107 1296 1583 1110 10828 117 1463 1175 1110 1141 5856 1106 1142 1134 4467 1174 1107 1999 1105 5695 1121 3020 6174 1103 2150 1104 6880 1432 119 102 1103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.051659 140552650831616 tf_logging.py:115] input_ids: 101 1109 7378 10873 17798 103 1718 1104 1295 1104 2682 4037 1107 1210 2182 2032 170 1432 119 1247 1132 1199 5426 9193 6995 1103 1416 1104 1234 4079 2625 1105 1166 1107 1999 117 3865 1105 1103 3066 1107 1103 1669 1206 3020 1105 21355 1568 119 1109 2905 10209 1107 1296 1583 1110 10828 117 1463 1175 1110 1141 5856 1106 1142 1134 4467 1174 1107 1999 1105 5695 1121 3020 6174 1103 2150 1104 6880 1432 119 102 1103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.053002 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.054483 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.055621 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:06.369712 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:10.891014 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:11.049366 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:11.569077 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:11.573510 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:12.329029 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:12.426254 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotation took time  0:00:08.272321\n",
      "INFO:tensorflow:Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.219897 140552650831616 tf_logging.py:115] Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.224414 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.225730 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [MASK] bar chart below reports the amount of financial supply into renewable energy in period from 2006 to 2013 . it can be seen that investments are made by developed and developing countries and the investment of the whole world as well and that over tendency is to rise up the amount of supply . The supply of developed countries had flu ##ct ##uated between almost 70 b ##n dollars and 100 b ##n dollars in the period from 2006 to 2009 while the investment of developing countries had permanently move up to 60 b ##n in 2009 from 2010 to 2013 the developed countries investment had hit the highest point in 2011 and moderately reduce in 2013 . Meanwhile developing countries had go [SEP] The [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.227235 140552650831616 tf_logging.py:115] tokens: [CLS] [MASK] bar chart below reports the amount of financial supply into renewable energy in period from 2006 to 2013 . it can be seen that investments are made by developed and developing countries and the investment of the whole world as well and that over tendency is to rise up the amount of supply . The supply of developed countries had flu ##ct ##uated between almost 70 b ##n dollars and 100 b ##n dollars in the period from 2006 to 2009 while the investment of developing countries had permanently move up to 60 b ##n in 2009 from 2010 to 2013 the developed countries investment had hit the highest point in 2011 and moderately reduce in 2013 . Meanwhile developing countries had go [SEP] The [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 103 2927 3481 2071 3756 1103 2971 1104 2798 3880 1154 17216 2308 1107 1669 1121 1386 1106 1381 119 1122 1169 1129 1562 1115 12372 1132 1189 1118 1872 1105 4297 2182 1105 1103 5151 1104 1103 2006 1362 1112 1218 1105 1115 1166 12034 1110 1106 3606 1146 1103 2971 1104 3880 119 1109 3880 1104 1872 2182 1125 23896 5822 13567 1206 1593 3102 171 1179 5860 1105 1620 171 1179 5860 1107 1103 1669 1121 1386 1106 1371 1229 1103 5151 1104 4297 2182 1125 8321 1815 1146 1106 2539 171 1179 1107 1371 1121 1333 1106 1381 1103 1872 2182 5151 1125 1855 1103 2439 1553 1107 1349 1105 19455 4851 1107 1381 119 5459 4297 2182 1125 1301 102 1109 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.228542 140552650831616 tf_logging.py:115] input_ids: 101 103 2927 3481 2071 3756 1103 2971 1104 2798 3880 1154 17216 2308 1107 1669 1121 1386 1106 1381 119 1122 1169 1129 1562 1115 12372 1132 1189 1118 1872 1105 4297 2182 1105 1103 5151 1104 1103 2006 1362 1112 1218 1105 1115 1166 12034 1110 1106 3606 1146 1103 2971 1104 3880 119 1109 3880 1104 1872 2182 1125 23896 5822 13567 1206 1593 3102 171 1179 5860 1105 1620 171 1179 5860 1107 1103 1669 1121 1386 1106 1371 1229 1103 5151 1104 4297 2182 1125 8321 1815 1146 1106 2539 171 1179 1107 1371 1121 1333 1106 1381 1103 1872 2182 5151 1125 1855 1103 2439 1553 1107 1349 1105 19455 4851 1107 1381 119 5459 4297 2182 1125 1301 102 1109 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.230079 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.231549 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.232939 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.236668 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.237982 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The [MASK] chart below reports the amount of financial supply into renewable energy in period from 2006 to 2013 . it can be seen that investments are made by developed and developing countries and the investment of the whole world as well and that over tendency is to rise up the amount of supply . The supply of developed countries had flu ##ct ##uated between almost 70 b ##n dollars and 100 b ##n dollars in the period from 2006 to 2009 while the investment of developing countries had permanently move up to 60 b ##n in 2009 from 2010 to 2013 the developed countries investment had hit the highest point in 2011 and moderately reduce in 2013 . Meanwhile developing countries had go [SEP] bar [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.239482 140552650831616 tf_logging.py:115] tokens: [CLS] The [MASK] chart below reports the amount of financial supply into renewable energy in period from 2006 to 2013 . it can be seen that investments are made by developed and developing countries and the investment of the whole world as well and that over tendency is to rise up the amount of supply . The supply of developed countries had flu ##ct ##uated between almost 70 b ##n dollars and 100 b ##n dollars in the period from 2006 to 2009 while the investment of developing countries had permanently move up to 60 b ##n in 2009 from 2010 to 2013 the developed countries investment had hit the highest point in 2011 and moderately reduce in 2013 . Meanwhile developing countries had go [SEP] bar [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 103 3481 2071 3756 1103 2971 1104 2798 3880 1154 17216 2308 1107 1669 1121 1386 1106 1381 119 1122 1169 1129 1562 1115 12372 1132 1189 1118 1872 1105 4297 2182 1105 1103 5151 1104 1103 2006 1362 1112 1218 1105 1115 1166 12034 1110 1106 3606 1146 1103 2971 1104 3880 119 1109 3880 1104 1872 2182 1125 23896 5822 13567 1206 1593 3102 171 1179 5860 1105 1620 171 1179 5860 1107 1103 1669 1121 1386 1106 1371 1229 1103 5151 1104 4297 2182 1125 8321 1815 1146 1106 2539 171 1179 1107 1371 1121 1333 1106 1381 1103 1872 2182 5151 1125 1855 1103 2439 1553 1107 1349 1105 19455 4851 1107 1381 119 5459 4297 2182 1125 1301 102 2927 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.240893 140552650831616 tf_logging.py:115] input_ids: 101 1109 103 3481 2071 3756 1103 2971 1104 2798 3880 1154 17216 2308 1107 1669 1121 1386 1106 1381 119 1122 1169 1129 1562 1115 12372 1132 1189 1118 1872 1105 4297 2182 1105 1103 5151 1104 1103 2006 1362 1112 1218 1105 1115 1166 12034 1110 1106 3606 1146 1103 2971 1104 3880 119 1109 3880 1104 1872 2182 1125 23896 5822 13567 1206 1593 3102 171 1179 5860 1105 1620 171 1179 5860 1107 1103 1669 1121 1386 1106 1371 1229 1103 5151 1104 4297 2182 1125 8321 1815 1146 1106 2539 171 1179 1107 1371 1121 1333 1106 1381 1103 1872 2182 5151 1125 1855 1103 2439 1553 1107 1349 1105 19455 4851 1107 1381 119 5459 4297 2182 1125 1301 102 2927 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.243022 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.244355 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.245762 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.249265 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.250778 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The bar [MASK] below reports the amount of financial supply into renewable energy in period from 2006 to 2013 . it can be seen that investments are made by developed and developing countries and the investment of the whole world as well and that over tendency is to rise up the amount of supply . The supply of developed countries had flu ##ct ##uated between almost 70 b ##n dollars and 100 b ##n dollars in the period from 2006 to 2009 while the investment of developing countries had permanently move up to 60 b ##n in 2009 from 2010 to 2013 the developed countries investment had hit the highest point in 2011 and moderately reduce in 2013 . Meanwhile developing countries had go [SEP] chart [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.252098 140552650831616 tf_logging.py:115] tokens: [CLS] The bar [MASK] below reports the amount of financial supply into renewable energy in period from 2006 to 2013 . it can be seen that investments are made by developed and developing countries and the investment of the whole world as well and that over tendency is to rise up the amount of supply . The supply of developed countries had flu ##ct ##uated between almost 70 b ##n dollars and 100 b ##n dollars in the period from 2006 to 2009 while the investment of developing countries had permanently move up to 60 b ##n in 2009 from 2010 to 2013 the developed countries investment had hit the highest point in 2011 and moderately reduce in 2013 . Meanwhile developing countries had go [SEP] chart [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 2927 103 2071 3756 1103 2971 1104 2798 3880 1154 17216 2308 1107 1669 1121 1386 1106 1381 119 1122 1169 1129 1562 1115 12372 1132 1189 1118 1872 1105 4297 2182 1105 1103 5151 1104 1103 2006 1362 1112 1218 1105 1115 1166 12034 1110 1106 3606 1146 1103 2971 1104 3880 119 1109 3880 1104 1872 2182 1125 23896 5822 13567 1206 1593 3102 171 1179 5860 1105 1620 171 1179 5860 1107 1103 1669 1121 1386 1106 1371 1229 1103 5151 1104 4297 2182 1125 8321 1815 1146 1106 2539 171 1179 1107 1371 1121 1333 1106 1381 1103 1872 2182 5151 1125 1855 1103 2439 1553 1107 1349 1105 19455 4851 1107 1381 119 5459 4297 2182 1125 1301 102 3481 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.253528 140552650831616 tf_logging.py:115] input_ids: 101 1109 2927 103 2071 3756 1103 2971 1104 2798 3880 1154 17216 2308 1107 1669 1121 1386 1106 1381 119 1122 1169 1129 1562 1115 12372 1132 1189 1118 1872 1105 4297 2182 1105 1103 5151 1104 1103 2006 1362 1112 1218 1105 1115 1166 12034 1110 1106 3606 1146 1103 2971 1104 3880 119 1109 3880 1104 1872 2182 1125 23896 5822 13567 1206 1593 3102 171 1179 5860 1105 1620 171 1179 5860 1107 1103 1669 1121 1386 1106 1371 1229 1103 5151 1104 4297 2182 1125 8321 1815 1146 1106 2539 171 1179 1107 1371 1121 1333 1106 1381 1103 1872 2182 5151 1125 1855 1103 2439 1553 1107 1349 1105 19455 4851 1107 1381 119 5459 4297 2182 1125 1301 102 3481 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.255034 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.256380 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.257978 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.261767 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.263127 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The bar chart [MASK] reports the amount of financial supply into renewable energy in period from 2006 to 2013 . it can be seen that investments are made by developed and developing countries and the investment of the whole world as well and that over tendency is to rise up the amount of supply . The supply of developed countries had flu ##ct ##uated between almost 70 b ##n dollars and 100 b ##n dollars in the period from 2006 to 2009 while the investment of developing countries had permanently move up to 60 b ##n in 2009 from 2010 to 2013 the developed countries investment had hit the highest point in 2011 and moderately reduce in 2013 . Meanwhile developing countries had go [SEP] below [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.264582 140552650831616 tf_logging.py:115] tokens: [CLS] The bar chart [MASK] reports the amount of financial supply into renewable energy in period from 2006 to 2013 . it can be seen that investments are made by developed and developing countries and the investment of the whole world as well and that over tendency is to rise up the amount of supply . The supply of developed countries had flu ##ct ##uated between almost 70 b ##n dollars and 100 b ##n dollars in the period from 2006 to 2009 while the investment of developing countries had permanently move up to 60 b ##n in 2009 from 2010 to 2013 the developed countries investment had hit the highest point in 2011 and moderately reduce in 2013 . Meanwhile developing countries had go [SEP] below [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 2927 3481 103 3756 1103 2971 1104 2798 3880 1154 17216 2308 1107 1669 1121 1386 1106 1381 119 1122 1169 1129 1562 1115 12372 1132 1189 1118 1872 1105 4297 2182 1105 1103 5151 1104 1103 2006 1362 1112 1218 1105 1115 1166 12034 1110 1106 3606 1146 1103 2971 1104 3880 119 1109 3880 1104 1872 2182 1125 23896 5822 13567 1206 1593 3102 171 1179 5860 1105 1620 171 1179 5860 1107 1103 1669 1121 1386 1106 1371 1229 1103 5151 1104 4297 2182 1125 8321 1815 1146 1106 2539 171 1179 1107 1371 1121 1333 1106 1381 1103 1872 2182 5151 1125 1855 1103 2439 1553 1107 1349 1105 19455 4851 1107 1381 119 5459 4297 2182 1125 1301 102 2071 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.266227 140552650831616 tf_logging.py:115] input_ids: 101 1109 2927 3481 103 3756 1103 2971 1104 2798 3880 1154 17216 2308 1107 1669 1121 1386 1106 1381 119 1122 1169 1129 1562 1115 12372 1132 1189 1118 1872 1105 4297 2182 1105 1103 5151 1104 1103 2006 1362 1112 1218 1105 1115 1166 12034 1110 1106 3606 1146 1103 2971 1104 3880 119 1109 3880 1104 1872 2182 1125 23896 5822 13567 1206 1593 3102 171 1179 5860 1105 1620 171 1179 5860 1107 1103 1669 1121 1386 1106 1371 1229 1103 5151 1104 4297 2182 1125 8321 1815 1146 1106 2539 171 1179 1107 1371 1121 1333 1106 1381 1103 1872 2182 5151 1125 1855 1103 2439 1553 1107 1349 1105 19455 4851 1107 1381 119 5459 4297 2182 1125 1301 102 2071 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.267577 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.269043 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.270316 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.274096 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.275689 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The bar chart below [MASK] the amount of financial supply into renewable energy in period from 2006 to 2013 . it can be seen that investments are made by developed and developing countries and the investment of the whole world as well and that over tendency is to rise up the amount of supply . The supply of developed countries had flu ##ct ##uated between almost 70 b ##n dollars and 100 b ##n dollars in the period from 2006 to 2009 while the investment of developing countries had permanently move up to 60 b ##n in 2009 from 2010 to 2013 the developed countries investment had hit the highest point in 2011 and moderately reduce in 2013 . Meanwhile developing countries had go [SEP] reports [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.277059 140552650831616 tf_logging.py:115] tokens: [CLS] The bar chart below [MASK] the amount of financial supply into renewable energy in period from 2006 to 2013 . it can be seen that investments are made by developed and developing countries and the investment of the whole world as well and that over tendency is to rise up the amount of supply . The supply of developed countries had flu ##ct ##uated between almost 70 b ##n dollars and 100 b ##n dollars in the period from 2006 to 2009 while the investment of developing countries had permanently move up to 60 b ##n in 2009 from 2010 to 2013 the developed countries investment had hit the highest point in 2011 and moderately reduce in 2013 . Meanwhile developing countries had go [SEP] reports [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 2927 3481 2071 103 1103 2971 1104 2798 3880 1154 17216 2308 1107 1669 1121 1386 1106 1381 119 1122 1169 1129 1562 1115 12372 1132 1189 1118 1872 1105 4297 2182 1105 1103 5151 1104 1103 2006 1362 1112 1218 1105 1115 1166 12034 1110 1106 3606 1146 1103 2971 1104 3880 119 1109 3880 1104 1872 2182 1125 23896 5822 13567 1206 1593 3102 171 1179 5860 1105 1620 171 1179 5860 1107 1103 1669 1121 1386 1106 1371 1229 1103 5151 1104 4297 2182 1125 8321 1815 1146 1106 2539 171 1179 1107 1371 1121 1333 1106 1381 1103 1872 2182 5151 1125 1855 1103 2439 1553 1107 1349 1105 19455 4851 1107 1381 119 5459 4297 2182 1125 1301 102 3756 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.278654 140552650831616 tf_logging.py:115] input_ids: 101 1109 2927 3481 2071 103 1103 2971 1104 2798 3880 1154 17216 2308 1107 1669 1121 1386 1106 1381 119 1122 1169 1129 1562 1115 12372 1132 1189 1118 1872 1105 4297 2182 1105 1103 5151 1104 1103 2006 1362 1112 1218 1105 1115 1166 12034 1110 1106 3606 1146 1103 2971 1104 3880 119 1109 3880 1104 1872 2182 1125 23896 5822 13567 1206 1593 3102 171 1179 5860 1105 1620 171 1179 5860 1107 1103 1669 1121 1386 1106 1371 1229 1103 5151 1104 4297 2182 1125 8321 1815 1146 1106 2539 171 1179 1107 1371 1121 1333 1106 1381 1103 1872 2182 5151 1125 1855 1103 2439 1553 1107 1349 1105 19455 4851 1107 1381 119 5459 4297 2182 1125 1301 102 3756 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.280113 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.281476 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.283016 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:14.638748 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:18.281223 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:18.433767 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:18.942755 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:18.946704 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:19.585397 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:19.674839 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotation took time  0:00:07.142647\n",
      "INFO:tensorflow:Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.641472 140552650831616 tf_logging.py:115] Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.645604 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.647835 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [MASK] has already taken a great part of our living and in future its influence is only going to increase . Own ##ing to fast pace of life most people spend great amount of their time on transportation . It might be one of the main reasons why some people are concerned with the purposes and usage of transport in future . [SEP] Transport [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.649388 140552650831616 tf_logging.py:115] tokens: [CLS] [MASK] has already taken a great part of our living and in future its influence is only going to increase . Own ##ing to fast pace of life most people spend great amount of their time on transportation . It might be one of the main reasons why some people are concerned with the purposes and usage of transport in future . [SEP] Transport [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 103 1144 1640 1678 170 1632 1226 1104 1412 1690 1105 1107 2174 1157 2933 1110 1178 1280 1106 2773 119 13432 1158 1106 2698 6418 1104 1297 1211 1234 4511 1632 2971 1104 1147 1159 1113 6312 119 1135 1547 1129 1141 1104 1103 1514 3672 1725 1199 1234 1132 4264 1114 1103 4998 1105 7991 1104 3936 1107 2174 119 102 5371 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.650964 140552650831616 tf_logging.py:115] input_ids: 101 103 1144 1640 1678 170 1632 1226 1104 1412 1690 1105 1107 2174 1157 2933 1110 1178 1280 1106 2773 119 13432 1158 1106 2698 6418 1104 1297 1211 1234 4511 1632 2971 1104 1147 1159 1113 6312 119 1135 1547 1129 1141 1104 1103 1514 3672 1725 1199 1234 1132 4264 1114 1103 4998 1105 7991 1104 3936 1107 2174 119 102 5371 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.652521 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.654085 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.655623 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.659131 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.660783 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] Transport [MASK] already taken a great part of our living and in future its influence is only going to increase . Own ##ing to fast pace of life most people spend great amount of their time on transportation . It might be one of the main reasons why some people are concerned with the purposes and usage of transport in future . [SEP] has [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.662425 140552650831616 tf_logging.py:115] tokens: [CLS] Transport [MASK] already taken a great part of our living and in future its influence is only going to increase . Own ##ing to fast pace of life most people spend great amount of their time on transportation . It might be one of the main reasons why some people are concerned with the purposes and usage of transport in future . [SEP] has [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5371 103 1640 1678 170 1632 1226 1104 1412 1690 1105 1107 2174 1157 2933 1110 1178 1280 1106 2773 119 13432 1158 1106 2698 6418 1104 1297 1211 1234 4511 1632 2971 1104 1147 1159 1113 6312 119 1135 1547 1129 1141 1104 1103 1514 3672 1725 1199 1234 1132 4264 1114 1103 4998 1105 7991 1104 3936 1107 2174 119 102 1144 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.663864 140552650831616 tf_logging.py:115] input_ids: 101 5371 103 1640 1678 170 1632 1226 1104 1412 1690 1105 1107 2174 1157 2933 1110 1178 1280 1106 2773 119 13432 1158 1106 2698 6418 1104 1297 1211 1234 4511 1632 2971 1104 1147 1159 1113 6312 119 1135 1547 1129 1141 1104 1103 1514 3672 1725 1199 1234 1132 4264 1114 1103 4998 1105 7991 1104 3936 1107 2174 119 102 1144 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.665287 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.666838 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.668325 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.671827 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.673568 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] Transport has [MASK] taken a great part of our living and in future its influence is only going to increase . Own ##ing to fast pace of life most people spend great amount of their time on transportation . It might be one of the main reasons why some people are concerned with the purposes and usage of transport in future . [SEP] already [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.675236 140552650831616 tf_logging.py:115] tokens: [CLS] Transport has [MASK] taken a great part of our living and in future its influence is only going to increase . Own ##ing to fast pace of life most people spend great amount of their time on transportation . It might be one of the main reasons why some people are concerned with the purposes and usage of transport in future . [SEP] already [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5371 1144 103 1678 170 1632 1226 1104 1412 1690 1105 1107 2174 1157 2933 1110 1178 1280 1106 2773 119 13432 1158 1106 2698 6418 1104 1297 1211 1234 4511 1632 2971 1104 1147 1159 1113 6312 119 1135 1547 1129 1141 1104 1103 1514 3672 1725 1199 1234 1132 4264 1114 1103 4998 1105 7991 1104 3936 1107 2174 119 102 1640 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.676794 140552650831616 tf_logging.py:115] input_ids: 101 5371 1144 103 1678 170 1632 1226 1104 1412 1690 1105 1107 2174 1157 2933 1110 1178 1280 1106 2773 119 13432 1158 1106 2698 6418 1104 1297 1211 1234 4511 1632 2971 1104 1147 1159 1113 6312 119 1135 1547 1129 1141 1104 1103 1514 3672 1725 1199 1234 1132 4264 1114 1103 4998 1105 7991 1104 3936 1107 2174 119 102 1640 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.678306 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.679919 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.681428 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.685107 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.686960 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] Transport has already [MASK] a great part of our living and in future its influence is only going to increase . Own ##ing to fast pace of life most people spend great amount of their time on transportation . It might be one of the main reasons why some people are concerned with the purposes and usage of transport in future . [SEP] taken [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.688689 140552650831616 tf_logging.py:115] tokens: [CLS] Transport has already [MASK] a great part of our living and in future its influence is only going to increase . Own ##ing to fast pace of life most people spend great amount of their time on transportation . It might be one of the main reasons why some people are concerned with the purposes and usage of transport in future . [SEP] taken [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5371 1144 1640 103 170 1632 1226 1104 1412 1690 1105 1107 2174 1157 2933 1110 1178 1280 1106 2773 119 13432 1158 1106 2698 6418 1104 1297 1211 1234 4511 1632 2971 1104 1147 1159 1113 6312 119 1135 1547 1129 1141 1104 1103 1514 3672 1725 1199 1234 1132 4264 1114 1103 4998 1105 7991 1104 3936 1107 2174 119 102 1678 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.690519 140552650831616 tf_logging.py:115] input_ids: 101 5371 1144 1640 103 170 1632 1226 1104 1412 1690 1105 1107 2174 1157 2933 1110 1178 1280 1106 2773 119 13432 1158 1106 2698 6418 1104 1297 1211 1234 4511 1632 2971 1104 1147 1159 1113 6312 119 1135 1547 1129 1141 1104 1103 1514 3672 1725 1199 1234 1132 4264 1114 1103 4998 1105 7991 1104 3936 1107 2174 119 102 1678 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.692316 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.693892 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.695387 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.698854 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.700600 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] Transport has already taken [MASK] great part of our living and in future its influence is only going to increase . Own ##ing to fast pace of life most people spend great amount of their time on transportation . It might be one of the main reasons why some people are concerned with the purposes and usage of transport in future . [SEP] a [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.702343 140552650831616 tf_logging.py:115] tokens: [CLS] Transport has already taken [MASK] great part of our living and in future its influence is only going to increase . Own ##ing to fast pace of life most people spend great amount of their time on transportation . It might be one of the main reasons why some people are concerned with the purposes and usage of transport in future . [SEP] a [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5371 1144 1640 1678 103 1632 1226 1104 1412 1690 1105 1107 2174 1157 2933 1110 1178 1280 1106 2773 119 13432 1158 1106 2698 6418 1104 1297 1211 1234 4511 1632 2971 1104 1147 1159 1113 6312 119 1135 1547 1129 1141 1104 1103 1514 3672 1725 1199 1234 1132 4264 1114 1103 4998 1105 7991 1104 3936 1107 2174 119 102 170 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.704171 140552650831616 tf_logging.py:115] input_ids: 101 5371 1144 1640 1678 103 1632 1226 1104 1412 1690 1105 1107 2174 1157 2933 1110 1178 1280 1106 2773 119 13432 1158 1106 2698 6418 1104 1297 1211 1234 4511 1632 2971 1104 1147 1159 1113 6312 119 1135 1547 1129 1141 1104 1103 1514 3672 1725 1199 1234 1132 4264 1114 1103 4998 1105 7991 1104 3936 1107 2174 119 102 170 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.705903 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.707905 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.709860 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:21.968478 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:25.654235 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:25.800781 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:26.851748 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:26.857239 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:27.623524 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:27.696298 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotation took time  0:00:07.977657\n",
      "INFO:tensorflow:Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.128403 140552650831616 tf_logging.py:115] Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.131427 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.132628 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [MASK] is clear that musicians and film producers lose a gradually value of their money from illegal pirate copies every year . But often people can ’ t buy a disk , because they have a little money , and disks can crash after some times of using . So I think that it ’ s nor very well , but it ’ s true a way for this people . [SEP] It [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.134019 140552650831616 tf_logging.py:115] tokens: [CLS] [MASK] is clear that musicians and film producers lose a gradually value of their money from illegal pirate copies every year . But often people can ’ t buy a disk , because they have a little money , and disks can crash after some times of using . So I think that it ’ s nor very well , but it ’ s true a way for this people . [SEP] It [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 103 1110 2330 1115 4992 1105 1273 6419 3857 170 6044 2860 1104 1147 1948 1121 5696 15266 4034 1451 1214 119 1252 1510 1234 1169 787 189 4417 170 10437 117 1272 1152 1138 170 1376 1948 117 1105 27725 1169 5683 1170 1199 1551 1104 1606 119 1573 146 1341 1115 1122 787 188 4040 1304 1218 117 1133 1122 787 188 2276 170 1236 1111 1142 1234 119 102 1135 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.135552 140552650831616 tf_logging.py:115] input_ids: 101 103 1110 2330 1115 4992 1105 1273 6419 3857 170 6044 2860 1104 1147 1948 1121 5696 15266 4034 1451 1214 119 1252 1510 1234 1169 787 189 4417 170 10437 117 1272 1152 1138 170 1376 1948 117 1105 27725 1169 5683 1170 1199 1551 1104 1606 119 1573 146 1341 1115 1122 787 188 4040 1304 1218 117 1133 1122 787 188 2276 170 1236 1111 1142 1234 119 102 1135 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.136824 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.137981 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.140186 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.142333 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.143461 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] It [MASK] clear that musicians and film producers lose a gradually value of their money from illegal pirate copies every year . But often people can ’ t buy a disk , because they have a little money , and disks can crash after some times of using . So I think that it ’ s nor very well , but it ’ s true a way for this people . [SEP] is [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.144604 140552650831616 tf_logging.py:115] tokens: [CLS] It [MASK] clear that musicians and film producers lose a gradually value of their money from illegal pirate copies every year . But often people can ’ t buy a disk , because they have a little money , and disks can crash after some times of using . So I think that it ’ s nor very well , but it ’ s true a way for this people . [SEP] is [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1135 103 2330 1115 4992 1105 1273 6419 3857 170 6044 2860 1104 1147 1948 1121 5696 15266 4034 1451 1214 119 1252 1510 1234 1169 787 189 4417 170 10437 117 1272 1152 1138 170 1376 1948 117 1105 27725 1169 5683 1170 1199 1551 1104 1606 119 1573 146 1341 1115 1122 787 188 4040 1304 1218 117 1133 1122 787 188 2276 170 1236 1111 1142 1234 119 102 1110 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.145901 140552650831616 tf_logging.py:115] input_ids: 101 1135 103 2330 1115 4992 1105 1273 6419 3857 170 6044 2860 1104 1147 1948 1121 5696 15266 4034 1451 1214 119 1252 1510 1234 1169 787 189 4417 170 10437 117 1272 1152 1138 170 1376 1948 117 1105 27725 1169 5683 1170 1199 1551 1104 1606 119 1573 146 1341 1115 1122 787 188 4040 1304 1218 117 1133 1122 787 188 2276 170 1236 1111 1142 1234 119 102 1110 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.147405 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.149695 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.150969 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.153195 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.154440 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] It is [MASK] that musicians and film producers lose a gradually value of their money from illegal pirate copies every year . But often people can ’ t buy a disk , because they have a little money , and disks can crash after some times of using . So I think that it ’ s nor very well , but it ’ s true a way for this people . [SEP] clear [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.155696 140552650831616 tf_logging.py:115] tokens: [CLS] It is [MASK] that musicians and film producers lose a gradually value of their money from illegal pirate copies every year . But often people can ’ t buy a disk , because they have a little money , and disks can crash after some times of using . So I think that it ’ s nor very well , but it ’ s true a way for this people . [SEP] clear [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1135 1110 103 1115 4992 1105 1273 6419 3857 170 6044 2860 1104 1147 1948 1121 5696 15266 4034 1451 1214 119 1252 1510 1234 1169 787 189 4417 170 10437 117 1272 1152 1138 170 1376 1948 117 1105 27725 1169 5683 1170 1199 1551 1104 1606 119 1573 146 1341 1115 1122 787 188 4040 1304 1218 117 1133 1122 787 188 2276 170 1236 1111 1142 1234 119 102 2330 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.156834 140552650831616 tf_logging.py:115] input_ids: 101 1135 1110 103 1115 4992 1105 1273 6419 3857 170 6044 2860 1104 1147 1948 1121 5696 15266 4034 1451 1214 119 1252 1510 1234 1169 787 189 4417 170 10437 117 1272 1152 1138 170 1376 1948 117 1105 27725 1169 5683 1170 1199 1551 1104 1606 119 1573 146 1341 1115 1122 787 188 4040 1304 1218 117 1133 1122 787 188 2276 170 1236 1111 1142 1234 119 102 2330 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.158079 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.159341 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.160514 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.162663 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.163774 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] It is clear [MASK] musicians and film producers lose a gradually value of their money from illegal pirate copies every year . But often people can ’ t buy a disk , because they have a little money , and disks can crash after some times of using . So I think that it ’ s nor very well , but it ’ s true a way for this people . [SEP] that [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.164971 140552650831616 tf_logging.py:115] tokens: [CLS] It is clear [MASK] musicians and film producers lose a gradually value of their money from illegal pirate copies every year . But often people can ’ t buy a disk , because they have a little money , and disks can crash after some times of using . So I think that it ’ s nor very well , but it ’ s true a way for this people . [SEP] that [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1135 1110 2330 103 4992 1105 1273 6419 3857 170 6044 2860 1104 1147 1948 1121 5696 15266 4034 1451 1214 119 1252 1510 1234 1169 787 189 4417 170 10437 117 1272 1152 1138 170 1376 1948 117 1105 27725 1169 5683 1170 1199 1551 1104 1606 119 1573 146 1341 1115 1122 787 188 4040 1304 1218 117 1133 1122 787 188 2276 170 1236 1111 1142 1234 119 102 1115 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.166167 140552650831616 tf_logging.py:115] input_ids: 101 1135 1110 2330 103 4992 1105 1273 6419 3857 170 6044 2860 1104 1147 1948 1121 5696 15266 4034 1451 1214 119 1252 1510 1234 1169 787 189 4417 170 10437 117 1272 1152 1138 170 1376 1948 117 1105 27725 1169 5683 1170 1199 1551 1104 1606 119 1573 146 1341 1115 1122 787 188 4040 1304 1218 117 1133 1122 787 188 2276 170 1236 1111 1142 1234 119 102 1115 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.167694 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.169114 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.170230 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.172333 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.173657 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] It is clear that [MASK] and film producers lose a gradually value of their money from illegal pirate copies every year . But often people can ’ t buy a disk , because they have a little money , and disks can crash after some times of using . So I think that it ’ s nor very well , but it ’ s true a way for this people . [SEP] musicians [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.174993 140552650831616 tf_logging.py:115] tokens: [CLS] It is clear that [MASK] and film producers lose a gradually value of their money from illegal pirate copies every year . But often people can ’ t buy a disk , because they have a little money , and disks can crash after some times of using . So I think that it ’ s nor very well , but it ’ s true a way for this people . [SEP] musicians [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1135 1110 2330 1115 103 1105 1273 6419 3857 170 6044 2860 1104 1147 1948 1121 5696 15266 4034 1451 1214 119 1252 1510 1234 1169 787 189 4417 170 10437 117 1272 1152 1138 170 1376 1948 117 1105 27725 1169 5683 1170 1199 1551 1104 1606 119 1573 146 1341 1115 1122 787 188 4040 1304 1218 117 1133 1122 787 188 2276 170 1236 1111 1142 1234 119 102 4992 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.176211 140552650831616 tf_logging.py:115] input_ids: 101 1135 1110 2330 1115 103 1105 1273 6419 3857 170 6044 2860 1104 1147 1948 1121 5696 15266 4034 1451 1214 119 1252 1510 1234 1169 787 189 4417 170 10437 117 1272 1152 1138 170 1376 1948 117 1105 27725 1169 5683 1170 1199 1551 1104 1606 119 1573 146 1341 1115 1122 787 188 4040 1304 1218 117 1133 1122 787 188 2276 170 1236 1111 1142 1234 119 102 4992 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.177311 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.178817 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.180125 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:29.383213 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:32.500375 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:32.659760 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:33.686087 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:33.690334 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:34.363247 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:34.423932 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotation took time  0:00:06.741428\n",
      "INFO:tensorflow:Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.033671 140552650831616 tf_logging.py:115] Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.037640 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.039574 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [MASK] the modern world plenty of international companies believe that it is the good idea to change location of their businesses . So poor ##er developing countries with their local workers become the most brilliant place for it . First of all , if companies employ local workers for their businesses , they will economy a lot of money on salaries . [SEP] In [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.040976 140552650831616 tf_logging.py:115] tokens: [CLS] [MASK] the modern world plenty of international companies believe that it is the good idea to change location of their businesses . So poor ##er developing countries with their local workers become the most brilliant place for it . First of all , if companies employ local workers for their businesses , they will economy a lot of money on salaries . [SEP] In [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 103 1103 2030 1362 7722 1104 1835 2557 2059 1115 1122 1110 1103 1363 1911 1106 1849 2450 1104 1147 5028 119 1573 2869 1200 4297 2182 1114 1147 1469 3239 1561 1103 1211 8431 1282 1111 1122 119 1752 1104 1155 117 1191 2557 12912 1469 3239 1111 1147 5028 117 1152 1209 4190 170 1974 1104 1948 1113 23343 119 102 1130 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.042345 140552650831616 tf_logging.py:115] input_ids: 101 103 1103 2030 1362 7722 1104 1835 2557 2059 1115 1122 1110 1103 1363 1911 1106 1849 2450 1104 1147 5028 119 1573 2869 1200 4297 2182 1114 1147 1469 3239 1561 1103 1211 8431 1282 1111 1122 119 1752 1104 1155 117 1191 2557 12912 1469 3239 1111 1147 5028 117 1152 1209 4190 170 1974 1104 1948 1113 23343 119 102 1130 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.043833 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.045274 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.046541 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.048941 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.050385 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] In [MASK] modern world plenty of international companies believe that it is the good idea to change location of their businesses . So poor ##er developing countries with their local workers become the most brilliant place for it . First of all , if companies employ local workers for their businesses , they will economy a lot of money on salaries . [SEP] the [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.051615 140552650831616 tf_logging.py:115] tokens: [CLS] In [MASK] modern world plenty of international companies believe that it is the good idea to change location of their businesses . So poor ##er developing countries with their local workers become the most brilliant place for it . First of all , if companies employ local workers for their businesses , they will economy a lot of money on salaries . [SEP] the [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1130 103 2030 1362 7722 1104 1835 2557 2059 1115 1122 1110 1103 1363 1911 1106 1849 2450 1104 1147 5028 119 1573 2869 1200 4297 2182 1114 1147 1469 3239 1561 1103 1211 8431 1282 1111 1122 119 1752 1104 1155 117 1191 2557 12912 1469 3239 1111 1147 5028 117 1152 1209 4190 170 1974 1104 1948 1113 23343 119 102 1103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.052912 140552650831616 tf_logging.py:115] input_ids: 101 1130 103 2030 1362 7722 1104 1835 2557 2059 1115 1122 1110 1103 1363 1911 1106 1849 2450 1104 1147 5028 119 1573 2869 1200 4297 2182 1114 1147 1469 3239 1561 1103 1211 8431 1282 1111 1122 119 1752 1104 1155 117 1191 2557 12912 1469 3239 1111 1147 5028 117 1152 1209 4190 170 1974 1104 1948 1113 23343 119 102 1103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.054090 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.055419 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.056714 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.058898 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.060350 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] In the [MASK] world plenty of international companies believe that it is the good idea to change location of their businesses . So poor ##er developing countries with their local workers become the most brilliant place for it . First of all , if companies employ local workers for their businesses , they will economy a lot of money on salaries . [SEP] modern [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.061656 140552650831616 tf_logging.py:115] tokens: [CLS] In the [MASK] world plenty of international companies believe that it is the good idea to change location of their businesses . So poor ##er developing countries with their local workers become the most brilliant place for it . First of all , if companies employ local workers for their businesses , they will economy a lot of money on salaries . [SEP] modern [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1130 1103 103 1362 7722 1104 1835 2557 2059 1115 1122 1110 1103 1363 1911 1106 1849 2450 1104 1147 5028 119 1573 2869 1200 4297 2182 1114 1147 1469 3239 1561 1103 1211 8431 1282 1111 1122 119 1752 1104 1155 117 1191 2557 12912 1469 3239 1111 1147 5028 117 1152 1209 4190 170 1974 1104 1948 1113 23343 119 102 2030 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.063214 140552650831616 tf_logging.py:115] input_ids: 101 1130 1103 103 1362 7722 1104 1835 2557 2059 1115 1122 1110 1103 1363 1911 1106 1849 2450 1104 1147 5028 119 1573 2869 1200 4297 2182 1114 1147 1469 3239 1561 1103 1211 8431 1282 1111 1122 119 1752 1104 1155 117 1191 2557 12912 1469 3239 1111 1147 5028 117 1152 1209 4190 170 1974 1104 1948 1113 23343 119 102 2030 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.064367 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.065623 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.067095 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.069199 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.070663 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] In the modern [MASK] plenty of international companies believe that it is the good idea to change location of their businesses . So poor ##er developing countries with their local workers become the most brilliant place for it . First of all , if companies employ local workers for their businesses , they will economy a lot of money on salaries . [SEP] world [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.071707 140552650831616 tf_logging.py:115] tokens: [CLS] In the modern [MASK] plenty of international companies believe that it is the good idea to change location of their businesses . So poor ##er developing countries with their local workers become the most brilliant place for it . First of all , if companies employ local workers for their businesses , they will economy a lot of money on salaries . [SEP] world [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1130 1103 2030 103 7722 1104 1835 2557 2059 1115 1122 1110 1103 1363 1911 1106 1849 2450 1104 1147 5028 119 1573 2869 1200 4297 2182 1114 1147 1469 3239 1561 1103 1211 8431 1282 1111 1122 119 1752 1104 1155 117 1191 2557 12912 1469 3239 1111 1147 5028 117 1152 1209 4190 170 1974 1104 1948 1113 23343 119 102 1362 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.073360 140552650831616 tf_logging.py:115] input_ids: 101 1130 1103 2030 103 7722 1104 1835 2557 2059 1115 1122 1110 1103 1363 1911 1106 1849 2450 1104 1147 5028 119 1573 2869 1200 4297 2182 1114 1147 1469 3239 1561 1103 1211 8431 1282 1111 1122 119 1752 1104 1155 117 1191 2557 12912 1469 3239 1111 1147 5028 117 1152 1209 4190 170 1974 1104 1948 1113 23343 119 102 1362 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.074611 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.075828 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.077006 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.079503 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.080739 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] In the modern world [MASK] of international companies believe that it is the good idea to change location of their businesses . So poor ##er developing countries with their local workers become the most brilliant place for it . First of all , if companies employ local workers for their businesses , they will economy a lot of money on salaries . [SEP] plenty [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.081836 140552650831616 tf_logging.py:115] tokens: [CLS] In the modern world [MASK] of international companies believe that it is the good idea to change location of their businesses . So poor ##er developing countries with their local workers become the most brilliant place for it . First of all , if companies employ local workers for their businesses , they will economy a lot of money on salaries . [SEP] plenty [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1130 1103 2030 1362 103 1104 1835 2557 2059 1115 1122 1110 1103 1363 1911 1106 1849 2450 1104 1147 5028 119 1573 2869 1200 4297 2182 1114 1147 1469 3239 1561 1103 1211 8431 1282 1111 1122 119 1752 1104 1155 117 1191 2557 12912 1469 3239 1111 1147 5028 117 1152 1209 4190 170 1974 1104 1948 1113 23343 119 102 7722 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.083092 140552650831616 tf_logging.py:115] input_ids: 101 1130 1103 2030 1362 103 1104 1835 2557 2059 1115 1122 1110 1103 1363 1911 1106 1849 2450 1104 1147 5028 119 1573 2869 1200 4297 2182 1114 1147 1469 3239 1561 1103 1211 8431 1282 1111 1122 119 1752 1104 1155 117 1191 2557 12912 1469 3239 1111 1147 5028 117 1152 1209 4190 170 1974 1104 1948 1113 23343 119 102 7722 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.084208 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.085272 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.086450 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:36.319222 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:39.429197 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:39.582708 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:40.597428 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:40.602019 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:41.266900 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:41.329419 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotation took time  0:00:06.840817\n",
      "INFO:tensorflow:Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.093484 140552650831616 tf_logging.py:115] Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.096975 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.098543 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [MASK] our world there are a lot of global problems and one of them is the worse public health . Someone believes that a good decision of this will be an increase of the amount of sports facilities , but others have another point of view . Anyway , a rise of sport centres , swimming pools , g ##ems , etc . [SEP] In [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.099842 140552650831616 tf_logging.py:115] tokens: [CLS] [MASK] our world there are a lot of global problems and one of them is the worse public health . Someone believes that a good decision of this will be an increase of the amount of sports facilities , but others have another point of view . Anyway , a rise of sport centres , swimming pools , g ##ems , etc . [SEP] In [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 103 1412 1362 1175 1132 170 1974 1104 4265 2645 1105 1141 1104 1172 1110 1103 4146 1470 2332 119 6518 6616 1115 170 1363 2383 1104 1142 1209 1129 1126 2773 1104 1103 2971 1104 2865 3380 117 1133 1639 1138 1330 1553 1104 2458 119 10756 117 170 3606 1104 4799 9335 117 5947 13546 117 176 14587 117 3576 119 102 1130 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.101129 140552650831616 tf_logging.py:115] input_ids: 101 103 1412 1362 1175 1132 170 1974 1104 4265 2645 1105 1141 1104 1172 1110 1103 4146 1470 2332 119 6518 6616 1115 170 1363 2383 1104 1142 1209 1129 1126 2773 1104 1103 2971 1104 2865 3380 117 1133 1639 1138 1330 1553 1104 2458 119 10756 117 170 3606 1104 4799 9335 117 5947 13546 117 176 14587 117 3576 119 102 1130 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.102595 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.104372 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.105823 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.108398 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.109841 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] In [MASK] world there are a lot of global problems and one of them is the worse public health . Someone believes that a good decision of this will be an increase of the amount of sports facilities , but others have another point of view . Anyway , a rise of sport centres , swimming pools , g ##ems , etc . [SEP] our [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.111455 140552650831616 tf_logging.py:115] tokens: [CLS] In [MASK] world there are a lot of global problems and one of them is the worse public health . Someone believes that a good decision of this will be an increase of the amount of sports facilities , but others have another point of view . Anyway , a rise of sport centres , swimming pools , g ##ems , etc . [SEP] our [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1130 103 1362 1175 1132 170 1974 1104 4265 2645 1105 1141 1104 1172 1110 1103 4146 1470 2332 119 6518 6616 1115 170 1363 2383 1104 1142 1209 1129 1126 2773 1104 1103 2971 1104 2865 3380 117 1133 1639 1138 1330 1553 1104 2458 119 10756 117 170 3606 1104 4799 9335 117 5947 13546 117 176 14587 117 3576 119 102 1412 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.112888 140552650831616 tf_logging.py:115] input_ids: 101 1130 103 1362 1175 1132 170 1974 1104 4265 2645 1105 1141 1104 1172 1110 1103 4146 1470 2332 119 6518 6616 1115 170 1363 2383 1104 1142 1209 1129 1126 2773 1104 1103 2971 1104 2865 3380 117 1133 1639 1138 1330 1553 1104 2458 119 10756 117 170 3606 1104 4799 9335 117 5947 13546 117 176 14587 117 3576 119 102 1412 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.114258 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.115596 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.117110 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.119489 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.120655 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] In our [MASK] there are a lot of global problems and one of them is the worse public health . Someone believes that a good decision of this will be an increase of the amount of sports facilities , but others have another point of view . Anyway , a rise of sport centres , swimming pools , g ##ems , etc . [SEP] world [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.122108 140552650831616 tf_logging.py:115] tokens: [CLS] In our [MASK] there are a lot of global problems and one of them is the worse public health . Someone believes that a good decision of this will be an increase of the amount of sports facilities , but others have another point of view . Anyway , a rise of sport centres , swimming pools , g ##ems , etc . [SEP] world [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1130 1412 103 1175 1132 170 1974 1104 4265 2645 1105 1141 1104 1172 1110 1103 4146 1470 2332 119 6518 6616 1115 170 1363 2383 1104 1142 1209 1129 1126 2773 1104 1103 2971 1104 2865 3380 117 1133 1639 1138 1330 1553 1104 2458 119 10756 117 170 3606 1104 4799 9335 117 5947 13546 117 176 14587 117 3576 119 102 1362 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.123378 140552650831616 tf_logging.py:115] input_ids: 101 1130 1412 103 1175 1132 170 1974 1104 4265 2645 1105 1141 1104 1172 1110 1103 4146 1470 2332 119 6518 6616 1115 170 1363 2383 1104 1142 1209 1129 1126 2773 1104 1103 2971 1104 2865 3380 117 1133 1639 1138 1330 1553 1104 2458 119 10756 117 170 3606 1104 4799 9335 117 5947 13546 117 176 14587 117 3576 119 102 1362 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.124799 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.126413 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.127645 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.129786 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.131601 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] In our world [MASK] are a lot of global problems and one of them is the worse public health . Someone believes that a good decision of this will be an increase of the amount of sports facilities , but others have another point of view . Anyway , a rise of sport centres , swimming pools , g ##ems , etc . [SEP] there [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.133033 140552650831616 tf_logging.py:115] tokens: [CLS] In our world [MASK] are a lot of global problems and one of them is the worse public health . Someone believes that a good decision of this will be an increase of the amount of sports facilities , but others have another point of view . Anyway , a rise of sport centres , swimming pools , g ##ems , etc . [SEP] there [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1130 1412 1362 103 1132 170 1974 1104 4265 2645 1105 1141 1104 1172 1110 1103 4146 1470 2332 119 6518 6616 1115 170 1363 2383 1104 1142 1209 1129 1126 2773 1104 1103 2971 1104 2865 3380 117 1133 1639 1138 1330 1553 1104 2458 119 10756 117 170 3606 1104 4799 9335 117 5947 13546 117 176 14587 117 3576 119 102 1175 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.134692 140552650831616 tf_logging.py:115] input_ids: 101 1130 1412 1362 103 1132 170 1974 1104 4265 2645 1105 1141 1104 1172 1110 1103 4146 1470 2332 119 6518 6616 1115 170 1363 2383 1104 1142 1209 1129 1126 2773 1104 1103 2971 1104 2865 3380 117 1133 1639 1138 1330 1553 1104 2458 119 10756 117 170 3606 1104 4799 9335 117 5947 13546 117 176 14587 117 3576 119 102 1175 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.136241 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.137888 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.139204 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.141454 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.142683 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] In our world there [MASK] a lot of global problems and one of them is the worse public health . Someone believes that a good decision of this will be an increase of the amount of sports facilities , but others have another point of view . Anyway , a rise of sport centres , swimming pools , g ##ems , etc . [SEP] are [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.143979 140552650831616 tf_logging.py:115] tokens: [CLS] In our world there [MASK] a lot of global problems and one of them is the worse public health . Someone believes that a good decision of this will be an increase of the amount of sports facilities , but others have another point of view . Anyway , a rise of sport centres , swimming pools , g ##ems , etc . [SEP] are [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1130 1412 1362 1175 103 170 1974 1104 4265 2645 1105 1141 1104 1172 1110 1103 4146 1470 2332 119 6518 6616 1115 170 1363 2383 1104 1142 1209 1129 1126 2773 1104 1103 2971 1104 2865 3380 117 1133 1639 1138 1330 1553 1104 2458 119 10756 117 170 3606 1104 4799 9335 117 5947 13546 117 176 14587 117 3576 119 102 1132 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.145370 140552650831616 tf_logging.py:115] input_ids: 101 1130 1412 1362 1175 103 170 1974 1104 4265 2645 1105 1141 1104 1172 1110 1103 4146 1470 2332 119 6518 6616 1115 170 1363 2383 1104 1142 1209 1129 1126 2773 1104 1103 2971 1104 2865 3380 117 1133 1639 1138 1330 1553 1104 2458 119 10756 117 170 3606 1104 4799 9335 117 5947 13546 117 176 14587 117 3576 119 102 1132 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.147019 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.148401 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.149682 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:43.398133 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:46.628057 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:46.809293 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:48.001429 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:48.005796 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:48.743851 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:48.808696 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotation took time  0:00:07.538410\n",
      "INFO:tensorflow:Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.214102 140552650831616 tf_logging.py:115] Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.217244 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.218710 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [MASK] there are a lot of different magazines newspapers and others sources of various information from politics to culture . All pieces of news appear due to the work of journalists . Today there are a lot of opinions about the jobs in journalism : is it a good profession to make a living or not ? [SEP] Nowadays [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.219869 140552650831616 tf_logging.py:115] tokens: [CLS] [MASK] there are a lot of different magazines newspapers and others sources of various information from politics to culture . All pieces of news appear due to the work of journalists . Today there are a lot of opinions about the jobs in journalism : is it a good profession to make a living or not ? [SEP] Nowadays [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 103 1175 1132 170 1974 1104 1472 6959 6195 1105 1639 3509 1104 1672 1869 1121 4039 1106 2754 119 1398 3423 1104 2371 2845 1496 1106 1103 1250 1104 9891 119 3570 1175 1132 170 1974 1104 11089 1164 1103 5448 1107 10210 131 1110 1122 170 1363 9545 1106 1294 170 1690 1137 1136 136 102 25883 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.221115 140552650831616 tf_logging.py:115] input_ids: 101 103 1175 1132 170 1974 1104 1472 6959 6195 1105 1639 3509 1104 1672 1869 1121 4039 1106 2754 119 1398 3423 1104 2371 2845 1496 1106 1103 1250 1104 9891 119 3570 1175 1132 170 1974 1104 11089 1164 1103 5448 1107 10210 131 1110 1122 170 1363 9545 1106 1294 170 1690 1137 1136 136 102 25883 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.222387 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.223747 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.225005 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.227336 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.228604 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] Nowadays [MASK] are a lot of different magazines newspapers and others sources of various information from politics to culture . All pieces of news appear due to the work of journalists . Today there are a lot of opinions about the jobs in journalism : is it a good profession to make a living or not ? [SEP] there [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.229630 140552650831616 tf_logging.py:115] tokens: [CLS] Nowadays [MASK] are a lot of different magazines newspapers and others sources of various information from politics to culture . All pieces of news appear due to the work of journalists . Today there are a lot of opinions about the jobs in journalism : is it a good profession to make a living or not ? [SEP] there [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 25883 103 1132 170 1974 1104 1472 6959 6195 1105 1639 3509 1104 1672 1869 1121 4039 1106 2754 119 1398 3423 1104 2371 2845 1496 1106 1103 1250 1104 9891 119 3570 1175 1132 170 1974 1104 11089 1164 1103 5448 1107 10210 131 1110 1122 170 1363 9545 1106 1294 170 1690 1137 1136 136 102 1175 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.230892 140552650831616 tf_logging.py:115] input_ids: 101 25883 103 1132 170 1974 1104 1472 6959 6195 1105 1639 3509 1104 1672 1869 1121 4039 1106 2754 119 1398 3423 1104 2371 2845 1496 1106 1103 1250 1104 9891 119 3570 1175 1132 170 1974 1104 11089 1164 1103 5448 1107 10210 131 1110 1122 170 1363 9545 1106 1294 170 1690 1137 1136 136 102 1175 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.232123 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.233397 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.234675 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.236980 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.238239 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] Nowadays there [MASK] a lot of different magazines newspapers and others sources of various information from politics to culture . All pieces of news appear due to the work of journalists . Today there are a lot of opinions about the jobs in journalism : is it a good profession to make a living or not ? [SEP] are [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.239588 140552650831616 tf_logging.py:115] tokens: [CLS] Nowadays there [MASK] a lot of different magazines newspapers and others sources of various information from politics to culture . All pieces of news appear due to the work of journalists . Today there are a lot of opinions about the jobs in journalism : is it a good profession to make a living or not ? [SEP] are [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 25883 1175 103 170 1974 1104 1472 6959 6195 1105 1639 3509 1104 1672 1869 1121 4039 1106 2754 119 1398 3423 1104 2371 2845 1496 1106 1103 1250 1104 9891 119 3570 1175 1132 170 1974 1104 11089 1164 1103 5448 1107 10210 131 1110 1122 170 1363 9545 1106 1294 170 1690 1137 1136 136 102 1132 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.240628 140552650831616 tf_logging.py:115] input_ids: 101 25883 1175 103 170 1974 1104 1472 6959 6195 1105 1639 3509 1104 1672 1869 1121 4039 1106 2754 119 1398 3423 1104 2371 2845 1496 1106 1103 1250 1104 9891 119 3570 1175 1132 170 1974 1104 11089 1164 1103 5448 1107 10210 131 1110 1122 170 1363 9545 1106 1294 170 1690 1137 1136 136 102 1132 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.242139 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.243458 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.244890 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.247384 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.248620 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] Nowadays there are [MASK] lot of different magazines newspapers and others sources of various information from politics to culture . All pieces of news appear due to the work of journalists . Today there are a lot of opinions about the jobs in journalism : is it a good profession to make a living or not ? [SEP] a [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.250236 140552650831616 tf_logging.py:115] tokens: [CLS] Nowadays there are [MASK] lot of different magazines newspapers and others sources of various information from politics to culture . All pieces of news appear due to the work of journalists . Today there are a lot of opinions about the jobs in journalism : is it a good profession to make a living or not ? [SEP] a [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 25883 1175 1132 103 1974 1104 1472 6959 6195 1105 1639 3509 1104 1672 1869 1121 4039 1106 2754 119 1398 3423 1104 2371 2845 1496 1106 1103 1250 1104 9891 119 3570 1175 1132 170 1974 1104 11089 1164 1103 5448 1107 10210 131 1110 1122 170 1363 9545 1106 1294 170 1690 1137 1136 136 102 170 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.251610 140552650831616 tf_logging.py:115] input_ids: 101 25883 1175 1132 103 1974 1104 1472 6959 6195 1105 1639 3509 1104 1672 1869 1121 4039 1106 2754 119 1398 3423 1104 2371 2845 1496 1106 1103 1250 1104 9891 119 3570 1175 1132 170 1974 1104 11089 1164 1103 5448 1107 10210 131 1110 1122 170 1363 9545 1106 1294 170 1690 1137 1136 136 102 170 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.252812 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.253935 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.255148 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.257202 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.258576 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] Nowadays there are a [MASK] of different magazines newspapers and others sources of various information from politics to culture . All pieces of news appear due to the work of journalists . Today there are a lot of opinions about the jobs in journalism : is it a good profession to make a living or not ? [SEP] lot [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.259728 140552650831616 tf_logging.py:115] tokens: [CLS] Nowadays there are a [MASK] of different magazines newspapers and others sources of various information from politics to culture . All pieces of news appear due to the work of journalists . Today there are a lot of opinions about the jobs in journalism : is it a good profession to make a living or not ? [SEP] lot [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 25883 1175 1132 170 103 1104 1472 6959 6195 1105 1639 3509 1104 1672 1869 1121 4039 1106 2754 119 1398 3423 1104 2371 2845 1496 1106 1103 1250 1104 9891 119 3570 1175 1132 170 1974 1104 11089 1164 1103 5448 1107 10210 131 1110 1122 170 1363 9545 1106 1294 170 1690 1137 1136 136 102 1974 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.261143 140552650831616 tf_logging.py:115] input_ids: 101 25883 1175 1132 170 103 1104 1472 6959 6195 1105 1639 3509 1104 1672 1869 1121 4039 1106 2754 119 1398 3423 1104 2371 2845 1496 1106 1103 1250 1104 9891 119 3570 1175 1132 170 1974 1104 11089 1164 1103 5448 1107 10210 131 1110 1122 170 1363 9545 1106 1294 170 1690 1137 1136 136 102 1974 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.262733 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.264403 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.265699 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:51.483710 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:54.822447 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:54.984071 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:56.081312 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:56.086399 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:56.774100 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:56.843220 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotation took time  0:00:07.981859\n",
      "INFO:tensorflow:Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.612590 140552650831616 tf_logging.py:115] Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.615014 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.616661 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [MASK] to solve the problem of traffic jam ##s in Moscow ? From year to year the transport situation in Moscow is getting worse . The main problem is obviously the problem of traffic congestion ##s . [SEP] How [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.617992 140552650831616 tf_logging.py:115] tokens: [CLS] [MASK] to solve the problem of traffic jam ##s in Moscow ? From year to year the transport situation in Moscow is getting worse . The main problem is obviously the problem of traffic congestion ##s . [SEP] How [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 103 1106 9474 1103 2463 1104 3404 17462 1116 1107 4116 136 1622 1214 1106 1214 1103 3936 2820 1107 4116 1110 2033 4146 119 1109 1514 2463 1110 5544 1103 2463 1104 3404 22860 1116 119 102 1731 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.619411 140552650831616 tf_logging.py:115] input_ids: 101 103 1106 9474 1103 2463 1104 3404 17462 1116 1107 4116 136 1622 1214 1106 1214 1103 3936 2820 1107 4116 1110 2033 4146 119 1109 1514 2463 1110 5544 1103 2463 1104 3404 22860 1116 119 102 1731 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.620893 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.622201 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.623613 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.625656 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.626888 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] How [MASK] solve the problem of traffic jam ##s in Moscow ? From year to year the transport situation in Moscow is getting worse . The main problem is obviously the problem of traffic congestion ##s . [SEP] to [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.628191 140552650831616 tf_logging.py:115] tokens: [CLS] How [MASK] solve the problem of traffic jam ##s in Moscow ? From year to year the transport situation in Moscow is getting worse . The main problem is obviously the problem of traffic congestion ##s . [SEP] to [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1731 103 9474 1103 2463 1104 3404 17462 1116 1107 4116 136 1622 1214 1106 1214 1103 3936 2820 1107 4116 1110 2033 4146 119 1109 1514 2463 1110 5544 1103 2463 1104 3404 22860 1116 119 102 1106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.629303 140552650831616 tf_logging.py:115] input_ids: 101 1731 103 9474 1103 2463 1104 3404 17462 1116 1107 4116 136 1622 1214 1106 1214 1103 3936 2820 1107 4116 1110 2033 4146 119 1109 1514 2463 1110 5544 1103 2463 1104 3404 22860 1116 119 102 1106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.630669 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.632062 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.633152 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.635353 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.636806 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] How to [MASK] the problem of traffic jam ##s in Moscow ? From year to year the transport situation in Moscow is getting worse . The main problem is obviously the problem of traffic congestion ##s . [SEP] solve [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.638073 140552650831616 tf_logging.py:115] tokens: [CLS] How to [MASK] the problem of traffic jam ##s in Moscow ? From year to year the transport situation in Moscow is getting worse . The main problem is obviously the problem of traffic congestion ##s . [SEP] solve [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1731 1106 103 1103 2463 1104 3404 17462 1116 1107 4116 136 1622 1214 1106 1214 1103 3936 2820 1107 4116 1110 2033 4146 119 1109 1514 2463 1110 5544 1103 2463 1104 3404 22860 1116 119 102 9474 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.639332 140552650831616 tf_logging.py:115] input_ids: 101 1731 1106 103 1103 2463 1104 3404 17462 1116 1107 4116 136 1622 1214 1106 1214 1103 3936 2820 1107 4116 1110 2033 4146 119 1109 1514 2463 1110 5544 1103 2463 1104 3404 22860 1116 119 102 9474 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.640670 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.642123 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.643524 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.645488 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.646863 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] How to solve [MASK] problem of traffic jam ##s in Moscow ? From year to year the transport situation in Moscow is getting worse . The main problem is obviously the problem of traffic congestion ##s . [SEP] the [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.648055 140552650831616 tf_logging.py:115] tokens: [CLS] How to solve [MASK] problem of traffic jam ##s in Moscow ? From year to year the transport situation in Moscow is getting worse . The main problem is obviously the problem of traffic congestion ##s . [SEP] the [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1731 1106 9474 103 2463 1104 3404 17462 1116 1107 4116 136 1622 1214 1106 1214 1103 3936 2820 1107 4116 1110 2033 4146 119 1109 1514 2463 1110 5544 1103 2463 1104 3404 22860 1116 119 102 1103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.649137 140552650831616 tf_logging.py:115] input_ids: 101 1731 1106 9474 103 2463 1104 3404 17462 1116 1107 4116 136 1622 1214 1106 1214 1103 3936 2820 1107 4116 1110 2033 4146 119 1109 1514 2463 1110 5544 1103 2463 1104 3404 22860 1116 119 102 1103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.650342 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.651650 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.652917 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.655660 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.656885 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] How to solve the [MASK] of traffic jam ##s in Moscow ? From year to year the transport situation in Moscow is getting worse . The main problem is obviously the problem of traffic congestion ##s . [SEP] problem [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.658152 140552650831616 tf_logging.py:115] tokens: [CLS] How to solve the [MASK] of traffic jam ##s in Moscow ? From year to year the transport situation in Moscow is getting worse . The main problem is obviously the problem of traffic congestion ##s . [SEP] problem [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1731 1106 9474 1103 103 1104 3404 17462 1116 1107 4116 136 1622 1214 1106 1214 1103 3936 2820 1107 4116 1110 2033 4146 119 1109 1514 2463 1110 5544 1103 2463 1104 3404 22860 1116 119 102 2463 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.659637 140552650831616 tf_logging.py:115] input_ids: 101 1731 1106 9474 1103 103 1104 3404 17462 1116 1107 4116 136 1622 1214 1106 1214 1103 3936 2820 1107 4116 1110 2033 4146 119 1109 1514 2463 1110 5544 1103 2463 1104 3404 22860 1116 119 102 2463 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.661088 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.662909 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.664477 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:00:58.909732 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:02.522119 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:02.675829 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:03.178385 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:03.183102 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:03.838953 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:03.902387 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotation took time  0:00:07.024731\n",
      "INFO:tensorflow:Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.084492 140552650831616 tf_logging.py:115] Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.088270 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.089821 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [MASK] tomorrow comes by Sidney Sheldon Review by De ##m ##kin ##a Dar ##ia \" If tomorrow comes \" was written in 1985 and its genre is crime fiction . This book na ##rra ##tes us a story of a woman who has become the victim of New Or ##lean Mafia ' s criminal acts and who has properly conceived a plan of revenge . The narration is third - person , on behalf of the author . [SEP] If [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.091289 140552650831616 tf_logging.py:115] tokens: [CLS] [MASK] tomorrow comes by Sidney Sheldon Review by De ##m ##kin ##a Dar ##ia \" If tomorrow comes \" was written in 1985 and its genre is crime fiction . This book na ##rra ##tes us a story of a woman who has become the victim of New Or ##lean Mafia ' s criminal acts and who has properly conceived a plan of revenge . The narration is third - person , on behalf of the author . [SEP] If [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 103 4911 2502 1118 11441 21084 4960 1118 3177 1306 4314 1161 23612 1465 107 1409 4911 2502 107 1108 1637 1107 2210 1105 1157 6453 1110 3755 4211 119 1188 1520 9468 10582 3052 1366 170 1642 1104 170 1590 1150 1144 1561 1103 6410 1104 1203 2926 21649 18070 112 188 4771 4096 1105 1150 1144 7513 10187 170 2197 1104 7972 119 1109 25008 1110 1503 118 1825 117 1113 6261 1104 1103 2351 119 102 1409 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.092831 140552650831616 tf_logging.py:115] input_ids: 101 103 4911 2502 1118 11441 21084 4960 1118 3177 1306 4314 1161 23612 1465 107 1409 4911 2502 107 1108 1637 1107 2210 1105 1157 6453 1110 3755 4211 119 1188 1520 9468 10582 3052 1366 170 1642 1104 170 1590 1150 1144 1561 1103 6410 1104 1203 2926 21649 18070 112 188 4771 4096 1105 1150 1144 7513 10187 170 2197 1104 7972 119 1109 25008 1110 1503 118 1825 117 1113 6261 1104 1103 2351 119 102 1409 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.094285 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.095775 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.097153 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.100647 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.102047 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] If [MASK] comes by Sidney Sheldon Review by De ##m ##kin ##a Dar ##ia \" If tomorrow comes \" was written in 1985 and its genre is crime fiction . This book na ##rra ##tes us a story of a woman who has become the victim of New Or ##lean Mafia ' s criminal acts and who has properly conceived a plan of revenge . The narration is third - person , on behalf of the author . [SEP] tomorrow [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.103579 140552650831616 tf_logging.py:115] tokens: [CLS] If [MASK] comes by Sidney Sheldon Review by De ##m ##kin ##a Dar ##ia \" If tomorrow comes \" was written in 1985 and its genre is crime fiction . This book na ##rra ##tes us a story of a woman who has become the victim of New Or ##lean Mafia ' s criminal acts and who has properly conceived a plan of revenge . The narration is third - person , on behalf of the author . [SEP] tomorrow [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1409 103 2502 1118 11441 21084 4960 1118 3177 1306 4314 1161 23612 1465 107 1409 4911 2502 107 1108 1637 1107 2210 1105 1157 6453 1110 3755 4211 119 1188 1520 9468 10582 3052 1366 170 1642 1104 170 1590 1150 1144 1561 1103 6410 1104 1203 2926 21649 18070 112 188 4771 4096 1105 1150 1144 7513 10187 170 2197 1104 7972 119 1109 25008 1110 1503 118 1825 117 1113 6261 1104 1103 2351 119 102 4911 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.105137 140552650831616 tf_logging.py:115] input_ids: 101 1409 103 2502 1118 11441 21084 4960 1118 3177 1306 4314 1161 23612 1465 107 1409 4911 2502 107 1108 1637 1107 2210 1105 1157 6453 1110 3755 4211 119 1188 1520 9468 10582 3052 1366 170 1642 1104 170 1590 1150 1144 1561 1103 6410 1104 1203 2926 21649 18070 112 188 4771 4096 1105 1150 1144 7513 10187 170 2197 1104 7972 119 1109 25008 1110 1503 118 1825 117 1113 6261 1104 1103 2351 119 102 4911 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.106561 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.108202 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.109665 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.113188 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.114762 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] If tomorrow [MASK] by Sidney Sheldon Review by De ##m ##kin ##a Dar ##ia \" If tomorrow comes \" was written in 1985 and its genre is crime fiction . This book na ##rra ##tes us a story of a woman who has become the victim of New Or ##lean Mafia ' s criminal acts and who has properly conceived a plan of revenge . The narration is third - person , on behalf of the author . [SEP] comes [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.116453 140552650831616 tf_logging.py:115] tokens: [CLS] If tomorrow [MASK] by Sidney Sheldon Review by De ##m ##kin ##a Dar ##ia \" If tomorrow comes \" was written in 1985 and its genre is crime fiction . This book na ##rra ##tes us a story of a woman who has become the victim of New Or ##lean Mafia ' s criminal acts and who has properly conceived a plan of revenge . The narration is third - person , on behalf of the author . [SEP] comes [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1409 4911 103 1118 11441 21084 4960 1118 3177 1306 4314 1161 23612 1465 107 1409 4911 2502 107 1108 1637 1107 2210 1105 1157 6453 1110 3755 4211 119 1188 1520 9468 10582 3052 1366 170 1642 1104 170 1590 1150 1144 1561 1103 6410 1104 1203 2926 21649 18070 112 188 4771 4096 1105 1150 1144 7513 10187 170 2197 1104 7972 119 1109 25008 1110 1503 118 1825 117 1113 6261 1104 1103 2351 119 102 2502 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.118029 140552650831616 tf_logging.py:115] input_ids: 101 1409 4911 103 1118 11441 21084 4960 1118 3177 1306 4314 1161 23612 1465 107 1409 4911 2502 107 1108 1637 1107 2210 1105 1157 6453 1110 3755 4211 119 1188 1520 9468 10582 3052 1366 170 1642 1104 170 1590 1150 1144 1561 1103 6410 1104 1203 2926 21649 18070 112 188 4771 4096 1105 1150 1144 7513 10187 170 2197 1104 7972 119 1109 25008 1110 1503 118 1825 117 1113 6261 1104 1103 2351 119 102 2502 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.119517 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.121074 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.122472 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.126096 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.127782 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] If tomorrow comes [MASK] Sidney Sheldon Review by De ##m ##kin ##a Dar ##ia \" If tomorrow comes \" was written in 1985 and its genre is crime fiction . This book na ##rra ##tes us a story of a woman who has become the victim of New Or ##lean Mafia ' s criminal acts and who has properly conceived a plan of revenge . The narration is third - person , on behalf of the author . [SEP] by [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.129125 140552650831616 tf_logging.py:115] tokens: [CLS] If tomorrow comes [MASK] Sidney Sheldon Review by De ##m ##kin ##a Dar ##ia \" If tomorrow comes \" was written in 1985 and its genre is crime fiction . This book na ##rra ##tes us a story of a woman who has become the victim of New Or ##lean Mafia ' s criminal acts and who has properly conceived a plan of revenge . The narration is third - person , on behalf of the author . [SEP] by [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1409 4911 2502 103 11441 21084 4960 1118 3177 1306 4314 1161 23612 1465 107 1409 4911 2502 107 1108 1637 1107 2210 1105 1157 6453 1110 3755 4211 119 1188 1520 9468 10582 3052 1366 170 1642 1104 170 1590 1150 1144 1561 1103 6410 1104 1203 2926 21649 18070 112 188 4771 4096 1105 1150 1144 7513 10187 170 2197 1104 7972 119 1109 25008 1110 1503 118 1825 117 1113 6261 1104 1103 2351 119 102 1118 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.130701 140552650831616 tf_logging.py:115] input_ids: 101 1409 4911 2502 103 11441 21084 4960 1118 3177 1306 4314 1161 23612 1465 107 1409 4911 2502 107 1108 1637 1107 2210 1105 1157 6453 1110 3755 4211 119 1188 1520 9468 10582 3052 1366 170 1642 1104 170 1590 1150 1144 1561 1103 6410 1104 1203 2926 21649 18070 112 188 4771 4096 1105 1150 1144 7513 10187 170 2197 1104 7972 119 1109 25008 1110 1503 118 1825 117 1113 6261 1104 1103 2351 119 102 1118 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.132154 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.133509 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.134980 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.138239 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.139617 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] If tomorrow comes by [MASK] Sheldon Review by De ##m ##kin ##a Dar ##ia \" If tomorrow comes \" was written in 1985 and its genre is crime fiction . This book na ##rra ##tes us a story of a woman who has become the victim of New Or ##lean Mafia ' s criminal acts and who has properly conceived a plan of revenge . The narration is third - person , on behalf of the author . [SEP] Sidney [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.141062 140552650831616 tf_logging.py:115] tokens: [CLS] If tomorrow comes by [MASK] Sheldon Review by De ##m ##kin ##a Dar ##ia \" If tomorrow comes \" was written in 1985 and its genre is crime fiction . This book na ##rra ##tes us a story of a woman who has become the victim of New Or ##lean Mafia ' s criminal acts and who has properly conceived a plan of revenge . The narration is third - person , on behalf of the author . [SEP] Sidney [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1409 4911 2502 1118 103 21084 4960 1118 3177 1306 4314 1161 23612 1465 107 1409 4911 2502 107 1108 1637 1107 2210 1105 1157 6453 1110 3755 4211 119 1188 1520 9468 10582 3052 1366 170 1642 1104 170 1590 1150 1144 1561 1103 6410 1104 1203 2926 21649 18070 112 188 4771 4096 1105 1150 1144 7513 10187 170 2197 1104 7972 119 1109 25008 1110 1503 118 1825 117 1113 6261 1104 1103 2351 119 102 11441 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.142667 140552650831616 tf_logging.py:115] input_ids: 101 1409 4911 2502 1118 103 21084 4960 1118 3177 1306 4314 1161 23612 1465 107 1409 4911 2502 107 1108 1637 1107 2210 1105 1157 6453 1110 3755 4211 119 1188 1520 9468 10582 3052 1366 170 1642 1104 170 1590 1150 1144 1561 1103 6410 1104 1203 2926 21649 18070 112 188 4771 4096 1105 1150 1144 7513 10187 170 2197 1104 7972 119 1109 25008 1110 1503 118 1825 117 1113 6261 1104 1103 2351 119 102 11441 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.144163 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.145531 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.146969 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:06.431843 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:10.127663 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:10.285531 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:10.786860 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:10.792634 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:11.512005 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:11.611253 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotation took time  0:00:07.765839\n",
      "INFO:tensorflow:Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.186102 140552650831616 tf_logging.py:115] Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.188899 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.190525 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [MASK] bi ##e charts illustrate the per ##sent ##age of ages of people in Yemen and Italy in 2000 and 205 ##0 . It is clearly seen that the biggest population are and will be people at 15 - 59 ages . One of the most obvious fact in charts that in Yemen in 205 ##0 there will be less children in 0 - 14 ages , than it was in 2000 . [SEP] The [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.191702 140552650831616 tf_logging.py:115] tokens: [CLS] [MASK] bi ##e charts illustrate the per ##sent ##age of ages of people in Yemen and Italy in 2000 and 205 ##0 . It is clearly seen that the biggest population are and will be people at 15 - 59 ages . One of the most obvious fact in charts that in Yemen in 205 ##0 there will be less children in 0 - 14 ages , than it was in 2000 . [SEP] The [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 103 16516 1162 5896 20873 1103 1679 27408 2553 1104 6776 1104 1234 1107 14466 1105 2413 1107 1539 1105 17342 1568 119 1135 1110 3817 1562 1115 1103 4583 1416 1132 1105 1209 1129 1234 1120 1405 118 4589 6776 119 1448 1104 1103 1211 5119 1864 1107 5896 1115 1107 14466 1107 17342 1568 1175 1209 1129 1750 1482 1107 121 118 1489 6776 117 1190 1122 1108 1107 1539 119 102 1109 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.193083 140552650831616 tf_logging.py:115] input_ids: 101 103 16516 1162 5896 20873 1103 1679 27408 2553 1104 6776 1104 1234 1107 14466 1105 2413 1107 1539 1105 17342 1568 119 1135 1110 3817 1562 1115 1103 4583 1416 1132 1105 1209 1129 1234 1120 1405 118 4589 6776 119 1448 1104 1103 1211 5119 1864 1107 5896 1115 1107 14466 1107 17342 1568 1175 1209 1129 1750 1482 1107 121 118 1489 6776 117 1190 1122 1108 1107 1539 119 102 1109 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.195183 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.196599 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.197763 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.200193 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.201530 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The [MASK] charts illustrate the per ##sent ##age of ages of people in Yemen and Italy in 2000 and 205 ##0 . It is clearly seen that the biggest population are and will be people at 15 - 59 ages . One of the most obvious fact in charts that in Yemen in 205 ##0 there will be less children in 0 - 14 ages , than it was in 2000 . [SEP] bi ##e [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.202928 140552650831616 tf_logging.py:115] tokens: [CLS] The [MASK] charts illustrate the per ##sent ##age of ages of people in Yemen and Italy in 2000 and 205 ##0 . It is clearly seen that the biggest population are and will be people at 15 - 59 ages . One of the most obvious fact in charts that in Yemen in 205 ##0 there will be less children in 0 - 14 ages , than it was in 2000 . [SEP] bi ##e [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 103 5896 20873 1103 1679 27408 2553 1104 6776 1104 1234 1107 14466 1105 2413 1107 1539 1105 17342 1568 119 1135 1110 3817 1562 1115 1103 4583 1416 1132 1105 1209 1129 1234 1120 1405 118 4589 6776 119 1448 1104 1103 1211 5119 1864 1107 5896 1115 1107 14466 1107 17342 1568 1175 1209 1129 1750 1482 1107 121 118 1489 6776 117 1190 1122 1108 1107 1539 119 102 16516 1162 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.204185 140552650831616 tf_logging.py:115] input_ids: 101 1109 103 5896 20873 1103 1679 27408 2553 1104 6776 1104 1234 1107 14466 1105 2413 1107 1539 1105 17342 1568 119 1135 1110 3817 1562 1115 1103 4583 1416 1132 1105 1209 1129 1234 1120 1405 118 4589 6776 119 1448 1104 1103 1211 5119 1864 1107 5896 1115 1107 14466 1107 17342 1568 1175 1209 1129 1750 1482 1107 121 118 1489 6776 117 1190 1122 1108 1107 1539 119 102 16516 1162 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.205487 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.207086 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.208557 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.210807 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.212102 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The bi ##e [MASK] illustrate the per ##sent ##age of ages of people in Yemen and Italy in 2000 and 205 ##0 . It is clearly seen that the biggest population are and will be people at 15 - 59 ages . One of the most obvious fact in charts that in Yemen in 205 ##0 there will be less children in 0 - 14 ages , than it was in 2000 . [SEP] charts [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.213240 140552650831616 tf_logging.py:115] tokens: [CLS] The bi ##e [MASK] illustrate the per ##sent ##age of ages of people in Yemen and Italy in 2000 and 205 ##0 . It is clearly seen that the biggest population are and will be people at 15 - 59 ages . One of the most obvious fact in charts that in Yemen in 205 ##0 there will be less children in 0 - 14 ages , than it was in 2000 . [SEP] charts [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 16516 1162 103 20873 1103 1679 27408 2553 1104 6776 1104 1234 1107 14466 1105 2413 1107 1539 1105 17342 1568 119 1135 1110 3817 1562 1115 1103 4583 1416 1132 1105 1209 1129 1234 1120 1405 118 4589 6776 119 1448 1104 1103 1211 5119 1864 1107 5896 1115 1107 14466 1107 17342 1568 1175 1209 1129 1750 1482 1107 121 118 1489 6776 117 1190 1122 1108 1107 1539 119 102 5896 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.214592 140552650831616 tf_logging.py:115] input_ids: 101 1109 16516 1162 103 20873 1103 1679 27408 2553 1104 6776 1104 1234 1107 14466 1105 2413 1107 1539 1105 17342 1568 119 1135 1110 3817 1562 1115 1103 4583 1416 1132 1105 1209 1129 1234 1120 1405 118 4589 6776 119 1448 1104 1103 1211 5119 1864 1107 5896 1115 1107 14466 1107 17342 1568 1175 1209 1129 1750 1482 1107 121 118 1489 6776 117 1190 1122 1108 1107 1539 119 102 5896 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.216532 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.218519 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.220304 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.223465 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.225331 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The bi ##e charts [MASK] the per ##sent ##age of ages of people in Yemen and Italy in 2000 and 205 ##0 . It is clearly seen that the biggest population are and will be people at 15 - 59 ages . One of the most obvious fact in charts that in Yemen in 205 ##0 there will be less children in 0 - 14 ages , than it was in 2000 . [SEP] illustrate [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.227299 140552650831616 tf_logging.py:115] tokens: [CLS] The bi ##e charts [MASK] the per ##sent ##age of ages of people in Yemen and Italy in 2000 and 205 ##0 . It is clearly seen that the biggest population are and will be people at 15 - 59 ages . One of the most obvious fact in charts that in Yemen in 205 ##0 there will be less children in 0 - 14 ages , than it was in 2000 . [SEP] illustrate [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 16516 1162 5896 103 1103 1679 27408 2553 1104 6776 1104 1234 1107 14466 1105 2413 1107 1539 1105 17342 1568 119 1135 1110 3817 1562 1115 1103 4583 1416 1132 1105 1209 1129 1234 1120 1405 118 4589 6776 119 1448 1104 1103 1211 5119 1864 1107 5896 1115 1107 14466 1107 17342 1568 1175 1209 1129 1750 1482 1107 121 118 1489 6776 117 1190 1122 1108 1107 1539 119 102 20873 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.229318 140552650831616 tf_logging.py:115] input_ids: 101 1109 16516 1162 5896 103 1103 1679 27408 2553 1104 6776 1104 1234 1107 14466 1105 2413 1107 1539 1105 17342 1568 119 1135 1110 3817 1562 1115 1103 4583 1416 1132 1105 1209 1129 1234 1120 1405 118 4589 6776 119 1448 1104 1103 1211 5119 1864 1107 5896 1115 1107 14466 1107 17342 1568 1175 1209 1129 1750 1482 1107 121 118 1489 6776 117 1190 1122 1108 1107 1539 119 102 20873 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.231410 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.233305 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.235092 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.237853 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.239651 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The bi ##e charts illustrate [MASK] per ##sent ##age of ages of people in Yemen and Italy in 2000 and 205 ##0 . It is clearly seen that the biggest population are and will be people at 15 - 59 ages . One of the most obvious fact in charts that in Yemen in 205 ##0 there will be less children in 0 - 14 ages , than it was in 2000 . [SEP] the [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.241598 140552650831616 tf_logging.py:115] tokens: [CLS] The bi ##e charts illustrate [MASK] per ##sent ##age of ages of people in Yemen and Italy in 2000 and 205 ##0 . It is clearly seen that the biggest population are and will be people at 15 - 59 ages . One of the most obvious fact in charts that in Yemen in 205 ##0 there will be less children in 0 - 14 ages , than it was in 2000 . [SEP] the [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 16516 1162 5896 20873 103 1679 27408 2553 1104 6776 1104 1234 1107 14466 1105 2413 1107 1539 1105 17342 1568 119 1135 1110 3817 1562 1115 1103 4583 1416 1132 1105 1209 1129 1234 1120 1405 118 4589 6776 119 1448 1104 1103 1211 5119 1864 1107 5896 1115 1107 14466 1107 17342 1568 1175 1209 1129 1750 1482 1107 121 118 1489 6776 117 1190 1122 1108 1107 1539 119 102 1103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.243644 140552650831616 tf_logging.py:115] input_ids: 101 1109 16516 1162 5896 20873 103 1679 27408 2553 1104 6776 1104 1234 1107 14466 1105 2413 1107 1539 1105 17342 1568 119 1135 1110 3817 1562 1115 1103 4583 1416 1132 1105 1209 1129 1234 1120 1405 118 4589 6776 119 1448 1104 1103 1211 5119 1864 1107 5896 1115 1107 14466 1107 17342 1568 1175 1209 1129 1750 1482 1107 121 118 1489 6776 117 1190 1122 1108 1107 1539 119 102 1103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.245818 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.247654 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.249799 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:13.491442 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:17.088143 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:17.230563 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:17.732389 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:17.737138 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:18.432680 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:18.525128 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotation took time  0:00:07.028127\n",
      "INFO:tensorflow:Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.148278 140552650831616 tf_logging.py:115] Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.151241 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.152527 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [MASK] graph provides information about the skill levels after school in Australia in 1999 and the correlation of males and females who had them . As can be seen from the graph the vast majority of skilled vocational diploma accounted for 90 % of males , while females not interested that . ( a mere 10 per cent ) . [SEP] The [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.153839 140552650831616 tf_logging.py:115] tokens: [CLS] [MASK] graph provides information about the skill levels after school in Australia in 1999 and the correlation of males and females who had them . As can be seen from the graph the vast majority of skilled vocational diploma accounted for 90 % of males , while females not interested that . ( a mere 10 per cent ) . [SEP] The [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 103 10873 2790 1869 1164 1103 7864 3001 1170 1278 1107 1754 1107 1729 1105 1103 18741 1104 3508 1105 3032 1150 1125 1172 119 1249 1169 1129 1562 1121 1103 10873 1103 6047 2656 1104 10715 18341 14985 15365 1111 3078 110 1104 3508 117 1229 3032 1136 3888 1115 119 113 170 8574 1275 1679 9848 114 119 102 1109 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.155068 140552650831616 tf_logging.py:115] input_ids: 101 103 10873 2790 1869 1164 1103 7864 3001 1170 1278 1107 1754 1107 1729 1105 1103 18741 1104 3508 1105 3032 1150 1125 1172 119 1249 1169 1129 1562 1121 1103 10873 1103 6047 2656 1104 10715 18341 14985 15365 1111 3078 110 1104 3508 117 1229 3032 1136 3888 1115 119 113 170 8574 1275 1679 9848 114 119 102 1109 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.156255 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.157497 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.159132 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.161581 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.163025 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The [MASK] provides information about the skill levels after school in Australia in 1999 and the correlation of males and females who had them . As can be seen from the graph the vast majority of skilled vocational diploma accounted for 90 % of males , while females not interested that . ( a mere 10 per cent ) . [SEP] graph [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.164179 140552650831616 tf_logging.py:115] tokens: [CLS] The [MASK] provides information about the skill levels after school in Australia in 1999 and the correlation of males and females who had them . As can be seen from the graph the vast majority of skilled vocational diploma accounted for 90 % of males , while females not interested that . ( a mere 10 per cent ) . [SEP] graph [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 103 2790 1869 1164 1103 7864 3001 1170 1278 1107 1754 1107 1729 1105 1103 18741 1104 3508 1105 3032 1150 1125 1172 119 1249 1169 1129 1562 1121 1103 10873 1103 6047 2656 1104 10715 18341 14985 15365 1111 3078 110 1104 3508 117 1229 3032 1136 3888 1115 119 113 170 8574 1275 1679 9848 114 119 102 10873 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.166133 140552650831616 tf_logging.py:115] input_ids: 101 1109 103 2790 1869 1164 1103 7864 3001 1170 1278 1107 1754 1107 1729 1105 1103 18741 1104 3508 1105 3032 1150 1125 1172 119 1249 1169 1129 1562 1121 1103 10873 1103 6047 2656 1104 10715 18341 14985 15365 1111 3078 110 1104 3508 117 1229 3032 1136 3888 1115 119 113 170 8574 1275 1679 9848 114 119 102 10873 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.167747 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.169057 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.170330 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.172897 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.174196 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The graph [MASK] information about the skill levels after school in Australia in 1999 and the correlation of males and females who had them . As can be seen from the graph the vast majority of skilled vocational diploma accounted for 90 % of males , while females not interested that . ( a mere 10 per cent ) . [SEP] provides [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.175466 140552650831616 tf_logging.py:115] tokens: [CLS] The graph [MASK] information about the skill levels after school in Australia in 1999 and the correlation of males and females who had them . As can be seen from the graph the vast majority of skilled vocational diploma accounted for 90 % of males , while females not interested that . ( a mere 10 per cent ) . [SEP] provides [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 10873 103 1869 1164 1103 7864 3001 1170 1278 1107 1754 1107 1729 1105 1103 18741 1104 3508 1105 3032 1150 1125 1172 119 1249 1169 1129 1562 1121 1103 10873 1103 6047 2656 1104 10715 18341 14985 15365 1111 3078 110 1104 3508 117 1229 3032 1136 3888 1115 119 113 170 8574 1275 1679 9848 114 119 102 2790 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.176694 140552650831616 tf_logging.py:115] input_ids: 101 1109 10873 103 1869 1164 1103 7864 3001 1170 1278 1107 1754 1107 1729 1105 1103 18741 1104 3508 1105 3032 1150 1125 1172 119 1249 1169 1129 1562 1121 1103 10873 1103 6047 2656 1104 10715 18341 14985 15365 1111 3078 110 1104 3508 117 1229 3032 1136 3888 1115 119 113 170 8574 1275 1679 9848 114 119 102 2790 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.178037 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.179455 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.180483 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.182858 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.184585 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The graph provides [MASK] about the skill levels after school in Australia in 1999 and the correlation of males and females who had them . As can be seen from the graph the vast majority of skilled vocational diploma accounted for 90 % of males , while females not interested that . ( a mere 10 per cent ) . [SEP] information [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.185916 140552650831616 tf_logging.py:115] tokens: [CLS] The graph provides [MASK] about the skill levels after school in Australia in 1999 and the correlation of males and females who had them . As can be seen from the graph the vast majority of skilled vocational diploma accounted for 90 % of males , while females not interested that . ( a mere 10 per cent ) . [SEP] information [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 10873 2790 103 1164 1103 7864 3001 1170 1278 1107 1754 1107 1729 1105 1103 18741 1104 3508 1105 3032 1150 1125 1172 119 1249 1169 1129 1562 1121 1103 10873 1103 6047 2656 1104 10715 18341 14985 15365 1111 3078 110 1104 3508 117 1229 3032 1136 3888 1115 119 113 170 8574 1275 1679 9848 114 119 102 1869 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.187256 140552650831616 tf_logging.py:115] input_ids: 101 1109 10873 2790 103 1164 1103 7864 3001 1170 1278 1107 1754 1107 1729 1105 1103 18741 1104 3508 1105 3032 1150 1125 1172 119 1249 1169 1129 1562 1121 1103 10873 1103 6047 2656 1104 10715 18341 14985 15365 1111 3078 110 1104 3508 117 1229 3032 1136 3888 1115 119 113 170 8574 1275 1679 9848 114 119 102 1869 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.188596 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.190093 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.191537 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.193887 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.195286 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The graph provides information [MASK] the skill levels after school in Australia in 1999 and the correlation of males and females who had them . As can be seen from the graph the vast majority of skilled vocational diploma accounted for 90 % of males , while females not interested that . ( a mere 10 per cent ) . [SEP] about [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.196640 140552650831616 tf_logging.py:115] tokens: [CLS] The graph provides information [MASK] the skill levels after school in Australia in 1999 and the correlation of males and females who had them . As can be seen from the graph the vast majority of skilled vocational diploma accounted for 90 % of males , while females not interested that . ( a mere 10 per cent ) . [SEP] about [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 10873 2790 1869 103 1103 7864 3001 1170 1278 1107 1754 1107 1729 1105 1103 18741 1104 3508 1105 3032 1150 1125 1172 119 1249 1169 1129 1562 1121 1103 10873 1103 6047 2656 1104 10715 18341 14985 15365 1111 3078 110 1104 3508 117 1229 3032 1136 3888 1115 119 113 170 8574 1275 1679 9848 114 119 102 1164 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.197842 140552650831616 tf_logging.py:115] input_ids: 101 1109 10873 2790 1869 103 1103 7864 3001 1170 1278 1107 1754 1107 1729 1105 1103 18741 1104 3508 1105 3032 1150 1125 1172 119 1249 1169 1129 1562 1121 1103 10873 1103 6047 2656 1104 10715 18341 14985 15365 1111 3078 110 1104 3508 117 1229 3032 1136 3888 1115 119 113 170 8574 1275 1679 9848 114 119 102 1164 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.199242 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.200633 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.201941 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:20.440602 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:24.157698 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:24.316603 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:24.812622 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:24.817879 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:25.494115 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:25.558971 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotation took time  0:00:06.940950\n",
      "INFO:tensorflow:Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.105587 140552650831616 tf_logging.py:115] Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.108914 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.110596 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [MASK] table indicates the number of people in different age groups working in sectors in UK such as building , education and other . First of all , we can see that people aged 18 - 25 years , 26 - 35 years and 36 - 45 years were most popular specialists by sector ##e of technology . For example , there were 45 ##43 ##75 workers in 2006 . [SEP] This [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.112058 140552650831616 tf_logging.py:115] tokens: [CLS] [MASK] table indicates the number of people in different age groups working in sectors in UK such as building , education and other . First of all , we can see that people aged 18 - 25 years , 26 - 35 years and 36 - 45 years were most popular specialists by sector ##e of technology . For example , there were 45 ##43 ##75 workers in 2006 . [SEP] This [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 103 1952 6653 1103 1295 1104 1234 1107 1472 1425 2114 1684 1107 11346 1107 1993 1216 1112 1459 117 1972 1105 1168 119 1752 1104 1155 117 1195 1169 1267 1115 1234 4079 1407 118 1512 1201 117 1744 118 2588 1201 1105 3164 118 2532 1201 1127 1211 1927 18137 1118 4291 1162 1104 2815 119 1370 1859 117 1175 1127 2532 25631 26253 3239 1107 1386 119 102 1188 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.113349 140552650831616 tf_logging.py:115] input_ids: 101 103 1952 6653 1103 1295 1104 1234 1107 1472 1425 2114 1684 1107 11346 1107 1993 1216 1112 1459 117 1972 1105 1168 119 1752 1104 1155 117 1195 1169 1267 1115 1234 4079 1407 118 1512 1201 117 1744 118 2588 1201 1105 3164 118 2532 1201 1127 1211 1927 18137 1118 4291 1162 1104 2815 119 1370 1859 117 1175 1127 2532 25631 26253 3239 1107 1386 119 102 1188 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.114644 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.116219 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.117669 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.120023 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.121308 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] This [MASK] indicates the number of people in different age groups working in sectors in UK such as building , education and other . First of all , we can see that people aged 18 - 25 years , 26 - 35 years and 36 - 45 years were most popular specialists by sector ##e of technology . For example , there were 45 ##43 ##75 workers in 2006 . [SEP] table [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.123919 140552650831616 tf_logging.py:115] tokens: [CLS] This [MASK] indicates the number of people in different age groups working in sectors in UK such as building , education and other . First of all , we can see that people aged 18 - 25 years , 26 - 35 years and 36 - 45 years were most popular specialists by sector ##e of technology . For example , there were 45 ##43 ##75 workers in 2006 . [SEP] table [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1188 103 6653 1103 1295 1104 1234 1107 1472 1425 2114 1684 1107 11346 1107 1993 1216 1112 1459 117 1972 1105 1168 119 1752 1104 1155 117 1195 1169 1267 1115 1234 4079 1407 118 1512 1201 117 1744 118 2588 1201 1105 3164 118 2532 1201 1127 1211 1927 18137 1118 4291 1162 1104 2815 119 1370 1859 117 1175 1127 2532 25631 26253 3239 1107 1386 119 102 1952 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.125618 140552650831616 tf_logging.py:115] input_ids: 101 1188 103 6653 1103 1295 1104 1234 1107 1472 1425 2114 1684 1107 11346 1107 1993 1216 1112 1459 117 1972 1105 1168 119 1752 1104 1155 117 1195 1169 1267 1115 1234 4079 1407 118 1512 1201 117 1744 118 2588 1201 1105 3164 118 2532 1201 1127 1211 1927 18137 1118 4291 1162 1104 2815 119 1370 1859 117 1175 1127 2532 25631 26253 3239 1107 1386 119 102 1952 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.127059 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.128450 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.129819 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.132222 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.133567 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] This table [MASK] the number of people in different age groups working in sectors in UK such as building , education and other . First of all , we can see that people aged 18 - 25 years , 26 - 35 years and 36 - 45 years were most popular specialists by sector ##e of technology . For example , there were 45 ##43 ##75 workers in 2006 . [SEP] indicates [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.134790 140552650831616 tf_logging.py:115] tokens: [CLS] This table [MASK] the number of people in different age groups working in sectors in UK such as building , education and other . First of all , we can see that people aged 18 - 25 years , 26 - 35 years and 36 - 45 years were most popular specialists by sector ##e of technology . For example , there were 45 ##43 ##75 workers in 2006 . [SEP] indicates [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1188 1952 103 1103 1295 1104 1234 1107 1472 1425 2114 1684 1107 11346 1107 1993 1216 1112 1459 117 1972 1105 1168 119 1752 1104 1155 117 1195 1169 1267 1115 1234 4079 1407 118 1512 1201 117 1744 118 2588 1201 1105 3164 118 2532 1201 1127 1211 1927 18137 1118 4291 1162 1104 2815 119 1370 1859 117 1175 1127 2532 25631 26253 3239 1107 1386 119 102 6653 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.136149 140552650831616 tf_logging.py:115] input_ids: 101 1188 1952 103 1103 1295 1104 1234 1107 1472 1425 2114 1684 1107 11346 1107 1993 1216 1112 1459 117 1972 1105 1168 119 1752 1104 1155 117 1195 1169 1267 1115 1234 4079 1407 118 1512 1201 117 1744 118 2588 1201 1105 3164 118 2532 1201 1127 1211 1927 18137 1118 4291 1162 1104 2815 119 1370 1859 117 1175 1127 2532 25631 26253 3239 1107 1386 119 102 6653 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.137437 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.138799 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.139923 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.142557 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.143901 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] This table indicates [MASK] number of people in different age groups working in sectors in UK such as building , education and other . First of all , we can see that people aged 18 - 25 years , 26 - 35 years and 36 - 45 years were most popular specialists by sector ##e of technology . For example , there were 45 ##43 ##75 workers in 2006 . [SEP] the [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.145195 140552650831616 tf_logging.py:115] tokens: [CLS] This table indicates [MASK] number of people in different age groups working in sectors in UK such as building , education and other . First of all , we can see that people aged 18 - 25 years , 26 - 35 years and 36 - 45 years were most popular specialists by sector ##e of technology . For example , there were 45 ##43 ##75 workers in 2006 . [SEP] the [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1188 1952 6653 103 1295 1104 1234 1107 1472 1425 2114 1684 1107 11346 1107 1993 1216 1112 1459 117 1972 1105 1168 119 1752 1104 1155 117 1195 1169 1267 1115 1234 4079 1407 118 1512 1201 117 1744 118 2588 1201 1105 3164 118 2532 1201 1127 1211 1927 18137 1118 4291 1162 1104 2815 119 1370 1859 117 1175 1127 2532 25631 26253 3239 1107 1386 119 102 1103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.146494 140552650831616 tf_logging.py:115] input_ids: 101 1188 1952 6653 103 1295 1104 1234 1107 1472 1425 2114 1684 1107 11346 1107 1993 1216 1112 1459 117 1972 1105 1168 119 1752 1104 1155 117 1195 1169 1267 1115 1234 4079 1407 118 1512 1201 117 1744 118 2588 1201 1105 3164 118 2532 1201 1127 1211 1927 18137 1118 4291 1162 1104 2815 119 1370 1859 117 1175 1127 2532 25631 26253 3239 1107 1386 119 102 1103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.147726 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.149067 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.150187 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.152490 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.153702 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] This table indicates the [MASK] of people in different age groups working in sectors in UK such as building , education and other . First of all , we can see that people aged 18 - 25 years , 26 - 35 years and 36 - 45 years were most popular specialists by sector ##e of technology . For example , there were 45 ##43 ##75 workers in 2006 . [SEP] number [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.154751 140552650831616 tf_logging.py:115] tokens: [CLS] This table indicates the [MASK] of people in different age groups working in sectors in UK such as building , education and other . First of all , we can see that people aged 18 - 25 years , 26 - 35 years and 36 - 45 years were most popular specialists by sector ##e of technology . For example , there were 45 ##43 ##75 workers in 2006 . [SEP] number [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1188 1952 6653 1103 103 1104 1234 1107 1472 1425 2114 1684 1107 11346 1107 1993 1216 1112 1459 117 1972 1105 1168 119 1752 1104 1155 117 1195 1169 1267 1115 1234 4079 1407 118 1512 1201 117 1744 118 2588 1201 1105 3164 118 2532 1201 1127 1211 1927 18137 1118 4291 1162 1104 2815 119 1370 1859 117 1175 1127 2532 25631 26253 3239 1107 1386 119 102 1295 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.155971 140552650831616 tf_logging.py:115] input_ids: 101 1188 1952 6653 1103 103 1104 1234 1107 1472 1425 2114 1684 1107 11346 1107 1993 1216 1112 1459 117 1972 1105 1168 119 1752 1104 1155 117 1195 1169 1267 1115 1234 4079 1407 118 1512 1201 117 1744 118 2588 1201 1105 3164 118 2532 1201 1127 1211 1927 18137 1118 4291 1162 1104 2815 119 1370 1859 117 1175 1127 2532 25631 26253 3239 1107 1386 119 102 1295 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.157182 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.158337 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.159595 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:27.403531 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:31.085283 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:31.267612 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:32.429273 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:32.435167 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:33.199676 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:33.259568 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotation took time  0:00:07.645127\n",
      "INFO:tensorflow:Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.733709 140552650831616 tf_logging.py:115] Writing example 0 of 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.736658 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.738140 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] [MASK] pie charts represent information about the ages of the population of Yemen and Italy in 2000 and pre ##duction ##s for 205 ##0 . In Yemen in 2000 more than half of population was 0 - 14 years in comparison with Italy where more than half of population was 15 - 59 years . The smallest proportion in Yemen was 60 + years , only 3 , 6 % . [SEP] The [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.739709 140552650831616 tf_logging.py:115] tokens: [CLS] [MASK] pie charts represent information about the ages of the population of Yemen and Italy in 2000 and pre ##duction ##s for 205 ##0 . In Yemen in 2000 more than half of population was 0 - 14 years in comparison with Italy where more than half of population was 15 - 59 years . The smallest proportion in Yemen was 60 + years , only 3 , 6 % . [SEP] The [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 103 16288 5896 4248 1869 1164 1103 6776 1104 1103 1416 1104 14466 1105 2413 1107 1539 1105 3073 11243 1116 1111 17342 1568 119 1130 14466 1107 1539 1167 1190 1544 1104 1416 1108 121 118 1489 1201 1107 7577 1114 2413 1187 1167 1190 1544 1104 1416 1108 1405 118 4589 1201 119 1109 10471 10807 1107 14466 1108 2539 116 1201 117 1178 124 117 127 110 119 102 1109 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.741079 140552650831616 tf_logging.py:115] input_ids: 101 103 16288 5896 4248 1869 1164 1103 6776 1104 1103 1416 1104 14466 1105 2413 1107 1539 1105 3073 11243 1116 1111 17342 1568 119 1130 14466 1107 1539 1167 1190 1544 1104 1416 1108 121 118 1489 1201 1107 7577 1114 2413 1187 1167 1190 1544 1104 1416 1108 1405 118 4589 1201 119 1109 10471 10807 1107 14466 1108 2539 116 1201 117 1178 124 117 127 110 119 102 1109 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.742304 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.743560 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.744766 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.747063 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.748162 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The [MASK] charts represent information about the ages of the population of Yemen and Italy in 2000 and pre ##duction ##s for 205 ##0 . In Yemen in 2000 more than half of population was 0 - 14 years in comparison with Italy where more than half of population was 15 - 59 years . The smallest proportion in Yemen was 60 + years , only 3 , 6 % . [SEP] pie [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.750663 140552650831616 tf_logging.py:115] tokens: [CLS] The [MASK] charts represent information about the ages of the population of Yemen and Italy in 2000 and pre ##duction ##s for 205 ##0 . In Yemen in 2000 more than half of population was 0 - 14 years in comparison with Italy where more than half of population was 15 - 59 years . The smallest proportion in Yemen was 60 + years , only 3 , 6 % . [SEP] pie [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 103 5896 4248 1869 1164 1103 6776 1104 1103 1416 1104 14466 1105 2413 1107 1539 1105 3073 11243 1116 1111 17342 1568 119 1130 14466 1107 1539 1167 1190 1544 1104 1416 1108 121 118 1489 1201 1107 7577 1114 2413 1187 1167 1190 1544 1104 1416 1108 1405 118 4589 1201 119 1109 10471 10807 1107 14466 1108 2539 116 1201 117 1178 124 117 127 110 119 102 16288 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.752304 140552650831616 tf_logging.py:115] input_ids: 101 1109 103 5896 4248 1869 1164 1103 6776 1104 1103 1416 1104 14466 1105 2413 1107 1539 1105 3073 11243 1116 1111 17342 1568 119 1130 14466 1107 1539 1167 1190 1544 1104 1416 1108 121 118 1489 1201 1107 7577 1114 2413 1187 1167 1190 1544 1104 1416 1108 1405 118 4589 1201 119 1109 10471 10807 1107 14466 1108 2539 116 1201 117 1178 124 117 127 110 119 102 16288 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.753775 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.755202 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.756483 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.758760 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.760052 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The pie [MASK] represent information about the ages of the population of Yemen and Italy in 2000 and pre ##duction ##s for 205 ##0 . In Yemen in 2000 more than half of population was 0 - 14 years in comparison with Italy where more than half of population was 15 - 59 years . The smallest proportion in Yemen was 60 + years , only 3 , 6 % . [SEP] charts [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.761417 140552650831616 tf_logging.py:115] tokens: [CLS] The pie [MASK] represent information about the ages of the population of Yemen and Italy in 2000 and pre ##duction ##s for 205 ##0 . In Yemen in 2000 more than half of population was 0 - 14 years in comparison with Italy where more than half of population was 15 - 59 years . The smallest proportion in Yemen was 60 + years , only 3 , 6 % . [SEP] charts [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 16288 103 4248 1869 1164 1103 6776 1104 1103 1416 1104 14466 1105 2413 1107 1539 1105 3073 11243 1116 1111 17342 1568 119 1130 14466 1107 1539 1167 1190 1544 1104 1416 1108 121 118 1489 1201 1107 7577 1114 2413 1187 1167 1190 1544 1104 1416 1108 1405 118 4589 1201 119 1109 10471 10807 1107 14466 1108 2539 116 1201 117 1178 124 117 127 110 119 102 5896 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.762838 140552650831616 tf_logging.py:115] input_ids: 101 1109 16288 103 4248 1869 1164 1103 6776 1104 1103 1416 1104 14466 1105 2413 1107 1539 1105 3073 11243 1116 1111 17342 1568 119 1130 14466 1107 1539 1167 1190 1544 1104 1416 1108 121 118 1489 1201 1107 7577 1114 2413 1187 1167 1190 1544 1104 1416 1108 1405 118 4589 1201 119 1109 10471 10807 1107 14466 1108 2539 116 1201 117 1178 124 117 127 110 119 102 5896 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.764282 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.765648 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.767326 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.769747 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.771482 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The pie charts [MASK] information about the ages of the population of Yemen and Italy in 2000 and pre ##duction ##s for 205 ##0 . In Yemen in 2000 more than half of population was 0 - 14 years in comparison with Italy where more than half of population was 15 - 59 years . The smallest proportion in Yemen was 60 + years , only 3 , 6 % . [SEP] represent [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.773268 140552650831616 tf_logging.py:115] tokens: [CLS] The pie charts [MASK] information about the ages of the population of Yemen and Italy in 2000 and pre ##duction ##s for 205 ##0 . In Yemen in 2000 more than half of population was 0 - 14 years in comparison with Italy where more than half of population was 15 - 59 years . The smallest proportion in Yemen was 60 + years , only 3 , 6 % . [SEP] represent [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 16288 5896 103 1869 1164 1103 6776 1104 1103 1416 1104 14466 1105 2413 1107 1539 1105 3073 11243 1116 1111 17342 1568 119 1130 14466 1107 1539 1167 1190 1544 1104 1416 1108 121 118 1489 1201 1107 7577 1114 2413 1187 1167 1190 1544 1104 1416 1108 1405 118 4589 1201 119 1109 10471 10807 1107 14466 1108 2539 116 1201 117 1178 124 117 127 110 119 102 4248 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.774633 140552650831616 tf_logging.py:115] input_ids: 101 1109 16288 5896 103 1869 1164 1103 6776 1104 1103 1416 1104 14466 1105 2413 1107 1539 1105 3073 11243 1116 1111 17342 1568 119 1130 14466 1107 1539 1167 1190 1544 1104 1416 1108 121 118 1489 1201 1107 7577 1114 2413 1187 1167 1190 1544 1104 1416 1108 1405 118 4589 1201 119 1109 10471 10807 1107 14466 1108 2539 116 1201 117 1178 124 117 127 110 119 102 4248 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.776082 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.777683 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.779010 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.781359 140552650831616 tf_logging.py:115] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.782565 140552650831616 tf_logging.py:115] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] The pie charts represent [MASK] about the ages of the population of Yemen and Italy in 2000 and pre ##duction ##s for 205 ##0 . In Yemen in 2000 more than half of population was 0 - 14 years in comparison with Italy where more than half of population was 15 - 59 years . The smallest proportion in Yemen was 60 + years , only 3 , 6 % . [SEP] information [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.783990 140552650831616 tf_logging.py:115] tokens: [CLS] The pie charts represent [MASK] about the ages of the population of Yemen and Italy in 2000 and pre ##duction ##s for 205 ##0 . In Yemen in 2000 more than half of population was 0 - 14 years in comparison with Italy where more than half of population was 15 - 59 years . The smallest proportion in Yemen was 60 + years , only 3 , 6 % . [SEP] information [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1109 16288 5896 4248 103 1164 1103 6776 1104 1103 1416 1104 14466 1105 2413 1107 1539 1105 3073 11243 1116 1111 17342 1568 119 1130 14466 1107 1539 1167 1190 1544 1104 1416 1108 121 118 1489 1201 1107 7577 1114 2413 1187 1167 1190 1544 1104 1416 1108 1405 118 4589 1201 119 1109 10471 10807 1107 14466 1108 2539 116 1201 117 1178 124 117 127 110 119 102 1869 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.785407 140552650831616 tf_logging.py:115] input_ids: 101 1109 16288 5896 4248 103 1164 1103 6776 1104 1103 1416 1104 14466 1105 2413 1107 1539 1105 3073 11243 1116 1111 17342 1568 119 1130 14466 1107 1539 1167 1190 1544 1104 1416 1108 121 118 1489 1201 1107 7577 1114 2413 1187 1167 1190 1544 1104 1416 1108 1405 118 4589 1201 119 1109 10471 10807 1107 14466 1108 2539 116 1201 117 1178 124 117 127 110 119 102 1869 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.786783 140552650831616 tf_logging.py:115] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.788298 140552650831616 tf_logging.py:115] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:34.789594 140552650831616 tf_logging.py:115] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:35.027429 140552650831616 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:38.257239 140552650831616 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:38.416056 140552650831616 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:39.428180 140552650831616 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:39.432648 140552650831616 tf_logging.py:115] Restoring parameters from bert_new_prepositions/model.ckpt-40540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:40.103366 140552650831616 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0509 07:01:40.165560 140552650831616 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotation took time  0:00:06.943692\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "curname = \"wsites_\" + modelname + \".json\"\n",
    "\n",
    "test_texts = {\"./data/exam/exam2014/AMe_8_1.txt\": \"The graph provides information about the skill levels after school in Australia in 1999 and the correlation of males and females who had them.\\n\\t As can be seen from the graph the vast majority of skilled vocational diploma accounted for 90% of males, while females not interested that. (a mere 10 per cent). In 1999 undergraduate diploma and postgraduate diploma was 70 per cent of females and males respectively. Whereas the undergraduate diploma accounted for only about 37 per cent for males and postgraduate was only 30 per cent.\\n\\tFurthermore the Bachelor\\u2019s degree was more popular for women (about 55 per cent) than for men was almost half. The percentages of master\\u2019s degree for female was 40 per cent in 1999 and the percentage of males to reach 60 per cent.\\n\\tOverall, the qualification after school in Australia in 1999 took a big part by males, than females.\\n\", \"./data/exam/exam2014/2012-2014_4/esl_00945.txt\": \"If tomorrow comes by Sidney Sheldon\\nReview by Demkina Daria\\n\\\"If tomorrow comes\\\" was written in 1985 and its genre is crime fiction. This book narrates us a story of a woman who has become the victim of New Orlean Mafia's criminal acts and who has properly conceived a plan of revenge. \\nThe narration is third-person, on behalf of the author. The book is set in the time of its writing, actions unfold all over the world, beginning in New Orlean.\\nThe main character is Tracy Whitney, an ordinary woman, who had exemplary fiance, lucrative job and settled life until her mother got in the way of serious Mafia's members in New Orlean in consequence of which she died. From that moment the life of Tracy had changed cardinally. Trying to revenge for her mother she was totally defeated by the top of criminal gang ruling in New Orlean: Joe Romano, Judge Lawrence, Orsatti and Perry Pope. This crushed woman lost everything she had, even an unborn child. She was sentenced to fifteen years in jail for a crime that she didn't commit. Being in prison she vowed herself to revenge to all those people who were related to her miseries. All in all she got free ahead of time and set about the plan's realization. Tracy Whitney had destroyed all her enemies and began defeat the most authoritative and prosperous members of the Mafia plunging into adventure, making acquaintances and robbing all of them in the great amount of money. Soon she became obsessed with such criminal tricks and could not stop anymore until she had met another smart robber as she was, Jeff Stevens, and fall in love with him.\\nI absolutely love this book and would recommend it to everyone.  It is a real page turner that can capture everyone by its gripping thought-provoking plot and moving characters. First of all it is an educative story that shows us how not to give up even in the most difficult and leading into deadlock situations. And how important to stay calm and rational in such extreme conditions to survive. On the other side we see how dangerous to plunge into such adventures, how important to stop in time and not become obsessed with revenge. \\nThe main idea of the book is following: all people's evil exploits will certainly be sooner or later repaid as it happened with those, who had made money illegally, destroying the lives of innocent people.\\nThroughout the narration we face to great characters that strike us by their incredible dispositions.\\nAnd after reading this fascinating book I decided to read others books of Sidney Sheldon.\\n\", \"./data/exam/exam2014/EPa_5_1.txt\": \"The bie charts illustrate the persentage of ages of people in Yemen and Italy in 2000 and 2050. It is clearly seen that the biggest population are and will be people at 15-59 ages.\\nOne of the most obvious fact in charts that in Yemen in 2050 there will be less children in 0-14 ages, than it was in 2000. There will be sharply decline from 50,1% to 37,0%. Furthermore, there is projection the persentage of older people at 60 and more years, will stay the same. As for Italy, it is seen that there is trend that persentage of older people will increase dramatically, almost 2 times greater than in 2000. There will be the peak at 42,3%.\\nComparing two countries, it is clearly seen that in 2000 there was different persentage of 0-14 years children. In Italy there was 14,3% that is almost 4 times less than in Yemen. But as for people at 15-59, there was almost the same persentage. In Italy there was 61,6%, which there is a bit more than 46,3% in Yemen.\\nTo sum up, in general case the ages of the population of Yemen and also of Italy in 2000 and 2050 will be the same.\\n\", \"./data/exam/exam2014/TSha_2_1.txt\": \"The linear graph demonstrates the development of number of senior citizens in three countries throughout a century. There are some interesting facts concerning the population of people aged 65 and over in Japan, Sweden and the USA in the period between 1940 and 2040.\\nThe overall trend in each country is upward, though there is one exception to this which occured in Japan and lasted from 1940 till the beginning of 21st century. After this modest deep the proportion of retirees roared dramatically and constituded over a quarter at the end of the period.\\nIt is obvious that in the beginning of the period the fraction of senior citizens was less then 10%, with the USA having the largest share and Japan \\u2013 the least.\\nIn the USA the number of people aged 65 and over fluctuated slightly and reached a plateau in the first 20 years of 21st century. Afterwards, there was a moderate increase with maximume of just under a quarter.\\nSimilar development may be observed in the proportion of senior citizens of Sweden. It is also worth pointing out that the number of this age group fluctuated throughout the whole period and reached a peak at approximately a quarter of the country\\u2019s population.\\n\", \"./data/exam/exam2014/2012-2014_2/esl_00380.txt\": \"Transport has already taken a great part of our living and in future its influence is only going to increase. Owning to fast pace of life most people spend great amount of their time on transportation. It might be one of the main reasons why some people are concerned with the purposes and usage of transport in future. In my essay I would like to share some of my considerations about the possible and desired changes in this sphere of humans' life. \\nTo begin with I would like to argue that transport in future should be more environmentally friendly. Almost all the cars today are drawing petrol or diesel fuel and produce carbon dioxide and other harmful substances to the atmosphere. Moreover, oil from which petrol and diesel fuel are obtained is a non-renewable recourse and soon it will certainly run out. It's common knowledge that new types of electric vehicle had already been invented, although they are too expensive and as a result not spread enough. \\nAnother big problem today is permanent traffic congestions in every big city. This issue can be solved in many different ways but I'm fancy of suggesting the idea of creating such means of transport that won't require a track to ride. As far as I remember one of the science-fiction writer presenting the idea of creating cars that will move due to the terrestrial magnetic field. It might settle simultaneously the problem of air pollution and traffic jams. \\nAs we are living in the age of information technologies speed of movement has a great significance. I'm convinced that transport in future will be able to transport people as fast as information, for instance e-mails of messages in Skype, now. \\nNobody knows what may happen tomorrow, in two weeks, in couple of years, we can predict, though, and we are vigorous enough to influence on our future and make it better. It refers as well to all spheres of our life and to every person in particular.\\n\", \"./data/2012-2014/esl_00330.txt\": \"How to solve the problem of traffic jams in Moscow?\\nFrom year to year the transport situation in Moscow is getting worse. The main problem is obviously the problem of traffic congestions. Considerable social and financial resources are sent (are put? I'm not sure what verb I should use here: \\u043d\\u0430\\u043f\\u0440a\\u0432\\u043b\\u0435\\u043d\\u044b) on solving this problem. I would like to make some proposals which may make our transport better.\\nFirst of all, we know that lack of parking spaces is a real headache for drivers. That's why there should be intercept parkings close to subway stations, which are located near Ring Road (\\u044f \\u0438\\u043c\\u0435\\u044e \\u0432 \\u0432\\u0438\\u0434\\u0443 \\u041c\\u041a\\u0410\\u0414, \\u043d\\u0435 \\u0443\\u0432\\u0435\\u0440\\u0435\\u043d\\u0430, \\u0442\\u0430\\u043a \\u043b\\u0438 \\u043e\\u043d \\u043f\\u0435\\u0440\\u0435\\u0432\\u043e\\u0434\\u0438\\u0442\\u0441\\u044f \\u043d\\u0430 \\u0430\\u043d\\u0433\\u043b\\u0438\\u0439\\u0441\\u043a\\u0438\\u0439). For instance, near such stations as Domodedovo, Teply stan, where there is a lot of space. The other thing we have to mention is that there are a great large of lawns in Moscow. They occupy large spaces, which surely could be used as parkings. Also, at the expense of these lawns we could widen our roads. (I'm not talking about trees, just lawns). Because of the fact that Moscow is a capital, there is a great deal of government institutions of federal and regional subordination. As a consequence, lots of people go to the centre every morning. This is another cause of traffic congestion (not ordinary people but those with flashing lights on the roof of the car). The possible solution can be moving these institutions to the suburbs. However, before doing it we should pave the road to avoid traffic jams there. Furthermore, we can pave several chords in Moscow, because now the whole traffic is based on the principle of rings and radii.\\nIn conclusion I would like to add that there is no doubt that we can find many more solutions to the problem. But the main thing is just to start doing something, because here, in Moscow this problem has come to unthinkable extent.\\n\", \"./data/old IELTS/IELTS2016/JSl_95_1.txt\": \"The bar chart below reports the amount of financial supply into renewable energy in period from 2006 to 2013.it can be seen that investments are made by developed and developing countries and the investment of the whole world as well and that over tendency is to rise up the amount of supply. The supply of developed countries had fluctuated between almost 70 bn dollars and 100 bn dollars in the period from 2006 to 2009 while the investment of developing countries had permanently move up to 60 bn in 2009 from 2010 to 2013 the developed countries investment had hit the highest point in 2011 and moderately reduce in 2013. Meanwhile developing countries had go up to 100 bn in 2011 and decline in 2013 had slowly grow to 171 bn in 2008. After a short stagnation it had jumped up to 279 bn in 2011. Afterward it plummeted to 214 bn in 2013. \\n\", \"./data/old IELTS/IELTS2015/ADe_18_1.txt\": \"This table indicates the number of people in different age groups working in sectors in UK such as building, education and other.\\nFirst of all, we can see that people aged 18-25 years, 26-35 years and 36-45 years were most popular specialists by sectore of technology. For example, there were 454375 workers in 2006. Also in comparison with 1998 number of people from all groups were dramatically risen. We can see the same tendention by sector of education. \\nIn contrast to these sectors the number of people from all groups left the sector of building. There were 112565 specialists in age group 18-25 years old in 1998 year and it has fallen to 86430 workers. The same tendention was in all age groups.\\nTo summ up it all, we can say that people from all age groups prefer to go and work in sectors such as education and technology because the number of people by these sectors grew up.\\n\", \"./data/2012-2014/esl_00107.txt\": \"Nowadays there are a lot of different magazines newspapers and others sources of various information from politics to culture. All pieces of news appear due to the work of journalists. Today there are a lot of opinions about the jobs in journalism: is it a good profession to make a living or not?\\nFrom my point of view, journalism is a good profession. First of all, it is a very important kind of job for all people. Due to journalists we get information from all over the world. They make it accessible through the Internet,  TV,  magazines or newspapers, or  radio. They sometimes have to go very far away from their home to make a report from some places where something interesting or even dangerous is happening.  Just imagine how little we would know about what is happening around if there were no journalists. It also should be mentioned that due to rating wars journalists from different media try to never miss a deadline. That is why we also get the latest news in a timely manner. Secondly, journalism is a very interesting profession. Working as a correspondent you often have to go to very unusual places, sometimes even to dangerous areas. Using the skills of getting the required information, you make a good report for people and in addition you learn a lot of new things, see new places, meet people and, what is more important, improve journalistic skills. Journalists should provide the quality material. That is why they have to understand theater, art, politics, which makes their life bright and rich. Furthermore, journalism is a useful profession for the person who works in this sphere. People wanting to become a good journalist in getting their higher education degree learn how to write clear and concise sentences, how to process the required information. Moreover, it is important to be able to deal with different people. So being a journalist you develop personal qualities such as trust, patience, perseverance, tact and tolerance, and communicative skills. All these qualities help people to be successful at work. For example,  author and presenter of the TV program \\\"Top Secret\\\" Stanislav Kucher demonstrates \\\"creative hearing\\\". Free, quiet manner of conversation, respect, unbiased attitude allow the journalist to discuss even the most sensitive issues without using manipulative techniques.\\nHowever, some people are confident that journalism is a \\\"dirty\\\" job because they often make money on other people's mistakes or misfortunes. People suppose that journalist will do almost everything for a scoop or to break a story. I do not agree with this statement. If you are a well educated person you know all libel laws and follow them. Moreover, respectable press companies do everything to maintain their reputation. So they keep an open mind and always check the sources of information before providing a story, and they always respect the privacy of public people. What is  important  there are companies whose work is aimed at monitoring  media. For example, PR News is a specialized agency to analyze PR-campaigns and media monitoring in Moscow and other regions of Russia and Western Europe. The company uses two ways of tracking press services. The first one is the audit of the press service for the period of time. The second method is based on feedback from journalists and other media: editors, major bloggers and so on. Skilled, precise, correct survey of journalist's work helps diagnose the problem and prevent its negative effects. Two described methods help determine how precise and objective information of a certain press-service .\\nTo summarize, there are some arguments about the profession of journalist. But there is no doubt that this vocation brings a lot of good to people from all over the world as well as to journalists themselves in a way of developing a lot of human skills.\\n\", \"./data/exam/exam2017/EGe_220_1.txt\": \"The pay chart give information about the transportation of goods between countries in Eastern Europe.\\nAs it is evidence from the chart there were two types goods transported: by rail and by road. The largest number of goods transported by rail were metals. The number of these goods were 35 percent.The lowest number were non-metallic minerals. Unfortunatelly there were not information about number of percent.Chemicals and food product transported like machinery. It is about 11-12 percent.\\nThe transportation of goods by road shows that the food products jumped. The number of percent are 30. But machinery are far less from transporte by rail, roughly 2 percent.Non-metallic minerals are the same of metals about 11-13 percent.\\nIn conclusion the transportation of goods in Eastern Europe in 2008 was very good. Metals were the best transported by rail and food products people from Europe gave by road. The best way of manufactured goods were by road. Machinery were not popularity in Eastern Europe in 2008. The number decrease by rail and road.\", \"./data/exam/exam2016/JSl_140_2.txt\": \"In the modern world plenty of international companies believe that it is the good idea to change location of their businesses. So poorer developing countries with their local workers become the most brilliant place for it. First of all, if companies employ local workers for their businesses, they will economy a lot of money on salaries. In developing countries the average income is noticeable lower than in developed countries. Secondly, there are not a lot companies in developing countries. So there is a terrific place for new ideas and start-ups. Moreover, it is quite unexpensive to move your company to such country. For example, pays for place, which company orders, will be much cheaper like an other different pays. On the other hand, such businesses may have some disadvantages too. Firstly, there is no guaranty that company will reach a success. For example, if the company choose the wrong country for their business  they will not find their consumers and then they will lose their money. Lso the economy in developing countries is not safe enough for expensive businesses. We can see the example by situation in breece. They have a big problems with money so some businesses, which was moved there probably had to close. In conclusion, the advantages can outweigh the disadvantages. But it depends in some factors such as country economy, interests of consumers, type of business, etc. this companies help particular countries to develop their economy. \\n\", \"./data/exam/exam2014/MTsy_34_2.txt\": \"In our world there are a lot of global problems and one of them is the worse public health. Someone believes that a good decision of this will be an increase of the amount of sports facilities, but others have another point of view.\\nAnyway, a rise of sport centres, swimming pools, gems, etc. is a good way of solving this problem. First of all, it means that sport facilities will be near people's houses and consequantly they will not make spend too much time on just a road. Moreover, the huge number of fitness centres can impact on people's mind and help them to understand the importance of doing exercises.\\nNevertheless, an easy access to sport facilities can not be the best variant in improving public health. Some people simply have not any desire to do sport and do not want to think about how it is useful. Besides, nowadays adults and expesially youngsters prefer spent their time playing computer games or chatting with friends in social networks and are not interesting in their helth.\\nAs for me, I am not strongly sure that the vast amount of sports facilities may ensure the improving of population health. In my opinion the first step must be a significant drop in production of junk food, because it is a reason of bad health in the last decades in almost all countries in the world.\\nTo sum up, I want to stress that the best way of improving health is a produsing less harmful food and creating better environmental facilities, not sports ones.\\n\", \"./data/old IELTS/IELTS2015/EEm_24_2.txt\": \"It is strongly believed that some subject in universities are hard explain and understand for female students and there should be more boys to study specific areas of science. However, some people believe that women can benefit to various subjects in many ways.\\n\\nOn the one hand, the number of male students is very important for universities. First of all, male concentrate on subjects, whereas women distract boys and themselves on feelings and may do not pay appropriate attention to the process of studying. In addition, a man should build his life and find an excellent job in order to accomplish independence and confidence, and education is the main key to starting up a self-made project and following dreams.\\n\\nOn the other hand, female students should accepted to every subject at university. To start with, they are good business-women and more responsible for their job than man. It means that a well-quallified female worker in the different field of studies is welcomed. Besides, women have different point of views on specific subjects and sometimes with the various outlooks they help to make a scientific discovery.\\n\\nAlthough some subjects may seem difficult for understanding for women, I strongly believe that the number of them should be equal with the male students. It makes the pocess of studying more interesting. More than that, women may find some interesting details in the research which have been neglected by men. All in all, despite being difficult for studying female students may give a fresh look to the scients, which is why the should have similar right with male students to study different subjects.\\n\", \"./data/exam/exam2014/EPa_6_1.txt\": \"The pie charts represent information about the ages of the population of Yemen and Italy in 2000 and preductions for 2050.\\nIn Yemen in 2000 more than half of population was 0-14 years in comparison with Italy where more than half of population was 15-59 years. The smallest proportion in Yemen was 60+ years, only 3,6%. In Italy the smallest proportion was 0-14 years. In Yemen there will be substantial decrease in children population. In Italy in 2050 will be sharp growth of 60+ years population from 24,1% to 42,3%. Compare with Yemen where growth will be from 3,6% to 5,7%. Yemen`s 15-59 years population will increase to 57,3% compare with Italy, where this population will have big declination from 61,6% to 46,2%.\\nTo sum up, in 2000 poputation in Yemen was elder than in Italy. In 2050 population in Italy will be older, because proportion of 60+ years rise and proportion of 15-59 years population decrease.\\n\", \"./data/exam/exam2017_6/OBy_103_2.txt\": \"It is clear that musicians and film producers lose a gradually value of their money from illegal pirate copies every year. But often people can\\u2019t buy a disk, because they have a little money, and disks can crash after some times of using. So I think that it\\u2019s nor very well, but it\\u2019s true a way for this people. And I agree with them.\\n\\nBut! People downloads copies of films in their computers, but the can often go to the cinema, because there are many films look like so good and cool on the big (\\u044d\\u043a\\u0440\\u0430\\u043d?). And often a lot of money comes to the cassa, and they a piese of this money go to the authors of this films. And people often buy disks, if they have special.\\n\"}\n",
    "outie = [print_annotated_webpage(annotate(test_texts[tt]), tt) for tt in test_texts]\n",
    "with open(curname, 'w', encoding=\"utf-8\") as w:\n",
    "  json.dump(outie, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipython',\n",
       " '.cache',\n",
       " '.ipynb_checkpoints',\n",
       " 'bert_prepositions',\n",
       " 'delete.json',\n",
       " '.jupyter',\n",
       " '.bashrc-anaconda3.bak',\n",
       " '.config',\n",
       " 'REALEC_AutoAnnotator_BERT_pipeline Often_confused.ipynb',\n",
       " 'Prepositions_test.json',\n",
       " 'wsites_OftenConfused_ToFifteen.json',\n",
       " 'Often_confused_test.json',\n",
       " 'Often_confused.json',\n",
       " 'anaconda3',\n",
       " 'Anaconda3-4.0.0-Linux-x86_64.sh',\n",
       " 'download_google_drive',\n",
       " '.nano',\n",
       " '.bash_history',\n",
       " 'wsites_Prepositions_ToFifteen.json',\n",
       " 'Capitalisation.json',\n",
       " 'Prepositions.json',\n",
       " 'gdrive-linux-x64',\n",
       " '.keras',\n",
       " 'delete_test.json',\n",
       " '.python_history',\n",
       " 'nltk_data',\n",
       " 'wsites_delete_ToFifteen.json',\n",
       " 'wsites_Capitalisation_ToFifteen.json',\n",
       " 'Datasets',\n",
       " '.local',\n",
       " 'wsites_lex_item_choice_AugmentedRatio.json',\n",
       " 'REALEC_AutoAnnotator_BERT_pipeline Capitalisation.ipynb',\n",
       " 'jupyter-drive',\n",
       " 'cuda-repo-ubuntu1604_9.0.176-1_amd64.deb',\n",
       " '.continuum',\n",
       " '.conda',\n",
       " '.bashrc',\n",
       " '.nv',\n",
       " 'REALEC_AutoAnnotator_BERT_pipeline Prepositions.ipynb',\n",
       " 'bert_output',\n",
       " 'Capitalisation_test.json',\n",
       " 'cuda-repo-ubuntu1604_8.0.61-1_amd64.deb',\n",
       " '.gnupg',\n",
       " 'REALEC_AutoAnnotator_Generic_BERT_pipeline Delete.ipynb',\n",
       " 'bert_delete',\n",
       " '.gdrive',\n",
       " 'lex_item_choice_test.json',\n",
       " '.profile',\n",
       " '.wget-hsts',\n",
       " 'REALEC_AutoAnnotator_Generic_BERT_pipeline_Instance_2.ipynb',\n",
       " '.bash_logout',\n",
       " '.ssh',\n",
       " 'lex_item_choice.json']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n<head>\\n<title>./data/exam/exam2014/MTsy_34_2.txt</title>\\n<meta charset=\"utf-8\">\\n<style type=\"text/css\">\\n.blue {\\n\\tbackground: #a8d1ff;\\n\\tdisplay: inline-block;\\n}\\n</style>\\n</head>\\n<body>In our world there are a lot of global problems and one of them is the worse public health. Someone believes that a good decision of this will be an increase of the amount of sports facilities, but others have another point of view. Anyway, a rise of sport centres, swimming pools, gems, etc. is a good way of solving this problem. First of all, it means that sport facilities will be near people\\'s houses and consequantly they will not make spend too much time on just a road. Moreover, the huge number of fitness centres can impact on people\\'s mind and help them to understand the importance of doing exercises. Nevertheless, an easy access to sport facilities can not be the best variant in improving public health. Some people simply have not any desire to do sport and do not want to think about how it is useful. Besides, nowadays adults and expesially youngsters prefer spent their time playing computer games or chatting with friends in social networks and are not interesting in their helth. As for me, I am not strongly sure that the vast amount of sports facilities may ensure the improving of population health. In my opinion the first step must be a significant drop in production of junk food, because it is a reason of bad health in the last decades in almost all countries in the world. To sum up, I want to stress that the best way of improving health is a produsing less harmful food and creating better environmental facilities, not sports ones.</body>\\n</html>'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outie[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading wsites_Prepositions_ToFifteen.json\n",
      "Uploaded 1JKEI0vABre_Rj3wd6dCAT7GkSpZtWItN at 18.8 KB/s, total 27.0 KB\n"
     ]
    }
   ],
   "source": [
    "!./gdrive-linux-x64 upload wsites_Prepositions_ToFifteen.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7.2G\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov  274 May  8 20:31 checkpoint\r\n",
      "drwxr-xr-x 2 ivantorubarov ivantorubarov 4.0K May  8 20:38 eval\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov 339M May  8 20:31 events.out.tfevents.1557343592.instance-2\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov 322M May  8 19:27 graph.pbtxt\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov 1.3G May  8 20:30 model.ckpt-10000.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov  23K May  8 20:30 model.ckpt-10000.index\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov  86M May  8 20:30 model.ckpt-10000.meta\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov 1.3G May  8 20:31 model.ckpt-10134.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov  23K May  8 20:31 model.ckpt-10134.index\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov  86M May  8 20:31 model.ckpt-10134.meta\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov 1.3G May  8 20:21 model.ckpt-8500.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov  23K May  8 20:21 model.ckpt-8500.index\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov  86M May  8 20:21 model.ckpt-8500.meta\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov 1.3G May  8 20:24 model.ckpt-9000.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov  23K May  8 20:24 model.ckpt-9000.index\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov  86M May  8 20:24 model.ckpt-9000.meta\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov 1.3G May  8 20:27 model.ckpt-9500.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov  23K May  8 20:27 model.ckpt-9500.index\r\n",
      "-rw-rw-r-- 1 ivantorubarov ivantorubarov  86M May  8 20:27 model.ckpt-9500.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lAh ./bert_prepositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ./bert_output/model.ckpt-2396.data-00000-of-00001\n",
      "234.9 MB/1.3 GB, Rate: 41.1 MB/s                  "
     ]
    }
   ],
   "source": [
    "!./gdrive-linux-x64 upload ./bert_output/model.ckpt-2396.data-00000-of-00001\n",
    "!./gdrive-linux-x64 upload ./bert_output/model.ckpt-2396.index\n",
    "!./gdrive-linux-x64 upload ./bert_output/model.ckpt-2396.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf ./bert_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3w4nJBGMOuz5",
    "outputId": "e865f978-f267-4b71-aaa4-029572d260e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 16_pmUKOHS5lKXM2o-1QyVcPQohalCRZd\n"
     ]
    }
   ],
   "source": [
    "# Create & upload a file.\n",
    "uploaded = drive.CreateFile({'title': curname})\n",
    "uploaded.SetContentFile('./'+curname)\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zk7zf0Qu3Bp8"
   },
   "source": [
    "# Preparing existing model for REALEC production"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "REALEC AutoAnnotator Generic BERT pipeline Instance 2",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
